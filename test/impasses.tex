\pdfobjcompresslevel 0
\documentclass[10pt, a4paper, parskip=full, twoside, twocolumn]{report}

% --- PREAMBULE ---
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{amsmath, amssymb, amsthm, amsfonts}
\usepackage[top=1cm,bottom=2cm,left=1cm,right=1cm]{geometry}
\usepackage{graphicx}
\usepackage{stmaryrd}
\usepackage{xcolor}
\usepackage{framed}
\usepackage{enumitem}
\usepackage{titlesec}
\usepackage{aliascnt}
\usepackage{quiver}
\usepackage{algpseudocode}
\usepackage{tcolorbox} % The main package for creating the colored box
\tcbuselibrary{breakable}

% Define a custom color (optional, but good practice)
\definecolor{mygreen}{rgb}{0.2, 0.7, 0.2}
\definecolor{myblue}{rgb}{0.0, 0.2, 0.7}
\definecolor{myred}{rgb}{0.7, 0.2, 0.2}
\definecolor{paragraphtext}{rgb}{0.4, 0.3, 0.9}
\definecolor{developpement}{RGB}{255, 255, 224}

% Apply the color to the subsection title
\titleformat{\section}
  {\normalfont\large\bfseries\color{myred}} % The format for the whole line
  {\thesection}                           % The subsection number
  {1em}                                      % Separation between number and title
  {}                                         % Code before the title text (empty for now)

% Apply the color to the subsection title
\titleformat{\subsection}
  {\normalfont\large\bfseries\color{mygreen}} % The format for the whole line
  {\thesubsection}                           % The subsection number
  {1em}                                      % Separation between number and title
  {}                                         % Code before the title text (empty for now)
  
\newtheorem{definition}{Définition}
\newtheorem{methode}[definition]{Méthode}
\newtheorem{theorem}[definition]{Théorème}
\newtheorem{theorem_def}[definition]{Théorème/Définition}
\newtheorem{proposition}[definition]{Proposition}
\newtheorem{proposition_def}[definition]{Proposition/Définition}
\newtheorem{properties}[definition]{Propriétés}
\newtheorem{property}[definition]{Propriété}
\newtheorem{lemma}[definition]{Lemme}
\newtheorem{lemma_def}[definition]{Lemme/Définition}
\newtheorem{corollary}[definition]{Corollaire}
\newtheorem{corollary_def}[definition]{Corollaire/Définition}
\newtheorem{example}[definition]{Exemple}
\newtheorem{cexample}[definition]{Contre-exemple}
\newtheorem{remark}[definition]{Remarque}
\newtheorem{application}[definition]{Application}
\newtheorem{reference}[definition]{Référence}
\newtheorem{algorithm}[definition]{Algorithme}
\newtheorem{conjecture}[definition]{Conjecture}
\newtheorem{notation}[definition]{Notation}
\newtheorem*{notation*}{Notation}
\newtheorem*{example*}{Exemple}
\newtheorem*{application*}{Application}

\newcommand{\IN}{\mathbb{N}}
\newcommand{\IZ}{\mathbb{Z}}
\newcommand{\IU}{\mathbb{U}}
\newcommand{\IK}{\mathbb{K}}
\newcommand{\IP}{\mathbb{P}}
\newcommand{\IE}{\mathbb{E}}
\newcommand{\IV}{\mathbb{V}}
\newcommand{\IZnZ}{\mathbb{Z}/n\mathbb{Z}}
\newcommand{\IZpZ}{\mathbb{Z}/p\mathbb{Z}}
\newcommand{\IQ}{\mathbb{Q}}
\newcommand{\IC}{\mathbb{C}}
\newcommand{\IF}{\mathbb{F}}
\newcommand{\IR}{\mathbb{R}}
\newcommand{\IRn}{\mathbb{R}^n}
\newcommand{\IRd}{\mathbb{R}^d}
\newcommand{\IRm}{\mathbb{R}^m}
\newcommand{\IRp}{\mathbb{R}^p}
\newcommand{\IRnm}{\mathbb{R}^{n\times m}}
\newcommand{\IRmn}{\mathbb{R}^{m\times n}}
\newcommand{\IRpn}{\mathbb{R}^{p\times n}}
\newcommand{\IRnp}{\mathbb{R}^{n\times p}}
\newcommand{\IRpm}{\mathbb{R}^{p\times m}}
\newcommand{\IRmp}{\mathbb{R}^{m\times p}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\actson}{\circlearrowleft}
\newcommand{\ps}[2]{\langle #1\mid #2\rangle}

\DeclareMathOperator{\im}{Im}
% \DeclareMathOperator{\Im}{Im}
\DeclareMathOperator{\Jac}{Jac}
\DeclareMathOperator{\pgcd}{pgcd}
\DeclareMathOperator{\ppcm}{ppcm}
\DeclareMathOperator{\rg}{rg}
\DeclareMathOperator{\rang}{rang}
\DeclareMathOperator{\card}{Card}
\DeclareMathOperator{\Is}{Is}
\DeclareMathOperator{\Orb}{Orb}
\DeclareMathOperator{\Stab}{Stab}
\DeclareMathOperator{\Fix}{Fix}
\DeclareMathOperator{\Supp}{Supp}
\DeclareMathOperator{\ord}{ord}
\DeclareMathOperator{\Ker}{Ker}
\DeclareMathOperator{\Syl}{Syl}
\DeclareMathOperator{\Mat}{Mat}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\car}{car}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\Aut}{Aut}
\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\Div}{Div}
\DeclareMathOperator{\Frac}{Frac}
\DeclareMathOperator{\Vect}{Vect}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\Com}{Com}
\DeclareMathOperator{\Sp}{Sp}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Hess}{Hess}
\DeclareMathOperator{\eval}{eval}
\DeclareMathOperator{\Pass}{Pass}

\titleformat{\chapter}[display]
  {\normalfont\bfseries}{}{0pt}{\LARGE}
\titlespacing*{\chapter}{0pt}{0pt}{\baselineskip}

\newcommand{\vertiii}[1]{{\left\vert\kern-0.25ex\left\vert\kern-0.25ex\left\vert #1 
    \right\vert\kern-0.25ex\right\vert\kern-0.25ex\right\vert}}

\title{Leçons d'oral de l'Agrégation}
\author{Gautier Laisné}
\date{}


\begin{document}
% \maketitle
% \tableofcontents

\chapter{101 : Groupe opérant sur un ensemble. Exemples d'applications.}
Dans cette leçon, $G$ désigne un groupe de neutre $1$, et $X$ désigne un ensemble.
\section*{I. Action d'un groupe sur un ensemble}
\subsection*{A. Définitions et premiers exemples}
\begin{definition}[\textnormal{[R] 19, [U] 27}]
	Une \emph{action} de $G$ sur $X$ est une application $G\times X\to X$ définie par 
	$(g,x)\mapsto g\cdot x$ vérifiant
	\begin{enumerate}
		\item $\forall\, (g,g')\in G^2,\, \forall\, x\in X,\, g'\cdot (g\cdot x) = (g'g)\cdot x$
		\item $\forall\, x\in X,\, 1\cdot x = x$
	\end{enumerate}
	Pour signigier que $G$ agit sur $X$, on note $G\actson X$.
\end{definition}

\begin{example}[\textnormal{[R] 19, [U] 28}]
	\begin{itemize}
		\item $\mathfrak{S}(X) \actson X$ par $\sigma\cdot x = \sigma(x)$
		\item Si $E$ est un espace vectoriel, alors $GL(E)\actson E$ par $\varphi\cdot x = \varphi(x)$
		\item $(g,x)\mapsto x$ est une action de $G$ sur $X$, appelée \emph{action triviale}.
	\end{itemize}
\end{example}

\begin{proposition}[\textnormal{[R] 19, [U] 28}]
	La donnée d'une action $(g,x)\mapsto g\cdot x$ de $G$ sur $X$ équivaut à la donnée d'un morphisme $\varphi\,\colon G\to \mathfrak{S}(X)$, $g\mapsto \left[x\mapsto g\cdot x\right]$, appelé \emph{morphisme associé à l'action de $G$ sur $X$}.
\end{proposition}

\begin{definition}[\textnormal{[R] 19/21, [U] 29}]
	Soit $x\in X$. Alors :
	\begin{itemize}
		\item L'\emph{orbite} de $x$ est l'ensemble $\Orb(x) = \left\{g\cdot x \mid g\in G\right\}$ (aussi noté $G\cdot x$) ;
		\item Le \emph{stabilisateur} de $x$ est l'ensemble $\Stab(x) = \left\{g\in G \mid g\cdot x = x\right\}$.
	\end{itemize}
\end{definition}

\begin{proposition}[\textnormal{[U] 34/37}]
	\begin{enumerate}
		\item $G\actson G$ par $g\cdot h=ghg^{-1}$ (on l'appelle \emph{action par conjugaison}). Le stabilisateur de $h\in G$ est appelé \emph{centralisateur} de $h$, et est noté $C(h)$.
		\item $G$ agit sur l'ensemble de ses sous-groupes par $g\cdot H = gHg^{-1}$ (action par conjugaison). Le stabilisateur de $H\leq G$ est appelé \emph{normalisateur} de $H$, et est noté $N(H)$.
	\end{enumerate}
\end{proposition}

\begin{definition}[\textnormal{[R] 20, [U] 29/31}]
	On dit que l'action de $G$ sur $X$ est \emph{transitive} si elle n'a qu'une seule orbite, \emph{i.e.} si $\forall\,(x,y)\in X^2,\, \exists\, g\in G\,\colon g=g\cdot x$.

	On dit que l'action de $G$ sur $X$ est \emph{fidèle} si $\varphi$ est injective.
\end{definition}

\begin{example}[\textnormal{[U] 31}]
	\begin{itemize}
		\item $\mathfrak{S}_n\actson \llbracket 1,n\rrbracket$ transitivement par $\sigma\cdot i=\sigma(i)$
		\item $G\actson G$ fidèlement par $g\cdot h = gh$ (on l'appelle \emph{action par translation à gauche})
		\item Soit $H$ un sous-groupe de $G$. L"'action de $G$ sur $G/H$ définie par $g\cdot xH = gxH$, appelée \emph{action par translation à gauche}, est transitive.
	\end{itemize}
\end{example}

\begin{proposition}[\textnormal{[R] 21}]
	Pour tout $x\in X$, $\Stab(x)$ est un sous-groupe de $G$.
\end{proposition}

\begin{proposition}[\textnormal{[U] 30}]
	$x\mathcal{R}y \iff \exists\, g\in G\,\colon g=g\cdot x$ définit 
	une relation d'équivalence sur $X$ dont les classes sont les orbites de l'action de $G$ sur $X$.
\end{proposition}

\begin{corollary}[\textnormal{[U] 30}]
	Les orbites partitionnent $X$.
\end{corollary}

\begin{example}[\textnormal{[U] 41}]
	Soit $\sigma\in\mathfrak{S}_n$. Le groupe $\langle\sigma\rangle$ agit sur $\llbracket 1,n\rrbracket$ par $\sigma^k\cdot i = \sigma^k(i)$.
	Les orbites non ponctuelles sont les supports des cylckes dans la décomposition en produit de cycles à supports disjoints de $\sigma$.
\end{example}

\subsection*{B. Cas d'un groupe et d'un ensemble finis}
Dans ce paragraphe, on suppose $G$ et $X$ finis. On pose $n = \card(G)$.
\begin{theorem}[de Caylay - \textnormal{[R] 21, [U] 31}]
	$G$ s'identifie à un sous-groupe de $\mathfrak{S}_n$.
\end{theorem}
\begin{proposition}[\textnormal{[R] ?, [U] ?}]
	$\forall\, (x,y)\in X^2,\, y\in \Orb(x)\implies \exists\, g\in G\,\colon \Stab(y) = g\Stab(x)g^{-1}$.
\end{proposition}

\begin{theorem}[Relation orbite-stabilisateur - \textnormal{[R] 21}]
	Pour tout $x\in X$, $G/\Stab(x)$ et $\Orb(x)$ sont équipotents (cela reste vrai si $G$ est infini).
	Par conséquent,
	$$\card(G) = \card(\Stab(x))\card(\Orb(x))$$
\end{theorem}

\begin{theorem}[Équation aux classes - \textnormal{[R] 21}]Soit $\left\{x_1,\dots,x_r\right\}$ un système de représentants pour les orbites. Alors,
	$$\card X = \sum_{i=1}^{r} \card(\Orb(x_i)) = \sum_{i=1}^{r} \frac{\card G}{\card(\Stab(x_i))}$$
\end{theorem}

\begin{example}[\textnormal{[R] 22}]
	Si $\card G$ est une puissance d'un nombre premier, alors son centre $Z(G) := \left\{g\in G\mid \forall\, h\in G,\,ghg^{-1}=h\right\}$ n'est pas réduit à $\left\{1\right\}$.

	Corrolaire \textnormal{([R] 23)}: tout groupe d'ordre $p^2$ avec $p$ premier est abélien.
\end{example}


\begin{theorem}[Formule de Burnside - \textnormal{[R] 35}]
	L'action de $G$ sur $X$ possède $\frac{1}{\card G}\sum_{g\in G} \card(\Fix(g))$
	orbites, où $\Fix(g) = \left\{x\in X \mid g\cdot x = x\right\}$.
\end{theorem}

\begin{example}[\textnormal{[C] 132}]
	En moyenne, une permutation de $\llbracket 1,n\rrbracket$ tirée aléatoirement a $1$ point fixe.
\end{example}
\begin{example}[\textnormal{[C] 132}]
	Si $G$ n'est pas abélien, alors la probabilité de tirer simultanément deux éléments qui commutent vaut $\frac{k}{n}$, avec $k$ le nombre de classes de conjugaison de $G$.
\end{example}

\begin{theorem}[de Cauchy - \textnormal{[R] 23}]
	Soit $p$ un nombre premier. Si $p\mid \card G$, alors $G$ admet un élément d'ordre $p$.
\end{theorem}

\section*{II. Applications}
\subsection*{A. En géométrie : les isométries des polytopes}
\begin{theorem}[\textnormal{[R] 94}]
	L'ensemble des isométries du plan conservant un triangle équilatéral est un groupe isomorphe à $\mathfrak{S}_3$.
\end{theorem}

\begin{proposition}[\textnormal{[R] 82}]
	Soit $\mathcal{C}$ un cube. L'ensemble des isométries de l'espace conservant $\mathcal{C}$ est un groupe, noté $\text{Is}(\mathcal{C})$.
	On note $\text{Is}^+(\mathcal{C})$ le sous-groupe de $\mathcal{C}$ formé de rotations.
\end{proposition}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[\textnormal{[R] 85}]
	\label{dev1}
	$\text{Is}^+(\mathcal{C})\cong \mathfrak{S}_4$ et $\text{Is}(\mathcal{C})\cong \mathfrak{S}_4\times \IZ/2\IZ$.
\end{theorem}
\end{tcolorbox}

\begin{theorem}[\textnormal{[R] 95}]
	En notant $\mathcal{T}$ le tétraèdre régulier, on a $\text{Is}^+(\mathcal{T})\cong \mathcal{A}_4$ et $\text{Is}(\mathcal{T})\cong \mathfrak{S}_4$.
\end{theorem}

\subsection*{B. Du côté des matrices}
Dans ce paragraphe, $K$ désigne un corps. On fixe $(n,m)\in \left(\IN^*\right)^2$.

\begin{proposition}[\textnormal{[R] 184/185/199/195/206}]
	Les applications suivantes sont des actions :
	\begin{enumerate}
		\item Translation à gauche : $GL_n(K)\times \M_{n,m}(K)\to\M_{n,m}(K)$, $(P,A)\mapsto PA$
		\item Translation à droite : $GL_n(K)\times \M_{n,m}(K)\to\M_{n,m}(K)$, $(P,A)\mapsto AP^{-1}$
		\item Similitude (ou conjugaison) : $GL_n(K)\times \M_{n}(K)\to\M_{n}(K)$, $(P,A)\mapsto PAP^{-1}$
		\item Équivalence (ou \emph{action de Steiniz}) : $\left(GL_n(K)\times GL_m(K)\right)\times \M_{n,m}(K)\to\M_{n,m}(K)$, $\left(\left(P, Q\right), A\right) \mapsto PAQ^{-1}$
		\item Congruence : $GL_n(K)\times \M_{n}(K)\to\M_{n}(K)$, $(P,A)\to {}^tPAP$
	\end{enumerate}
\end{proposition}

\begin{proposition}[\textnormal{[R] 184/185/?/195/207}]
	Dans l'ordre de la proposition précédente, les orbites sont caractérisées par :
	\begin{enumerate}
		\item le noyau de $A$
		\item l'image de $A$
		\item les molynômes minimal et caractéristique de $A$
		\item Ça dépend de $K$...
	\end{enumerate}
\end{proposition}

\begin{example}
	$\text{Diag}(1,2,2)$ et $\text{Diag}(1,1,2)$ ont même polynôme minimal mais ne sont pas semblables : il faut donc bien les deux informations !
\end{example}

\subsection*{C. Théorèmes de Sylow}
Dans ce paragraphe, on se donne $p$ premier, et on note $\card G = p^{\alpha}m$, $m\wedge p = 1$.

\begin{definition}[\textnormal{[U] 85}]
	Un $p$-Sylow de $G$ est un sous-groupe de $G$ de cardinal $p^{\alpha}$.

	$\Syl_p(G)$ désigne l'ensemble des $p$-Sylow de $G$, et $n_p := \card(\Syl_p(G))$.
\end{definition}

\begin{theorem}[de Sylow - \textnormal{[U] 87}]Soit $G$ un groupe d'ordre $p^{\alpha}m$, $m\wedge p = 1$. Alors,
	\begin{enumerate}
		\item $\Syl_p(G)\neq \empty$
		\item $G$ agit transitivement sur $\Syl_p(G)$ par conjugaison
		\item $n_p\equiv 1\, [p]$
	\end{enumerate}
\end{theorem}

\begin{definition}
	On dit que $G$ est \emph{simple} si les seuls sous-groupes de $G$ distingués (\emph{i.e.} fixe par l'action par conjugaison de $G$)
	sont $\left\{1\right\}$ et $G$.
\end{definition}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[\textnormal{[S] 277}]\label{dev2}
	Si $G$ est simple et d'ordre $60$, alors 
	$G\cong \mathcal{A}_5$.
\end{theorem}
\end{tcolorbox}

\section*{Développements}
\begin{itemize}
	\item Développement 1 : Théorème \ref{dev1}
	\item Développement 2 : Théorème \ref{dev2}
\end{itemize}

\section*{Références}
\begin{itemize}
	\item[U] \emph{Théorie des groupes}, Félix Ulmer
	\item[R] \emph{Mathématiques pour l'agrégation - Algèbre et géométrie}, Jean-Étienne Rombaldi, 2e édition
	\item[S] \emph{Algèbre pour la licence 3}, Szpirglas
	\item[C] \emph{Carnets de voyage en Algébrie}, Caldero
\end{itemize}

\begin{figure}[!htb]
	\centering
	\includegraphics[trim={0 0 0 0},clip,width=1\linewidth]{img/101.pdf}
\end{figure}


\chapter*{105 : Groupe des permutations d'un ensemble fini. Applications.}
\setcounter{definition}{0}
\section*{I. Permutations d'un ensemble fini}
\subsection*{A. Introduction}
\begin{definition}[\textnormal{[R] 37}]
	Soit $E$ un ensemble. On note $\mathfrak{S}(E)$
	l'ensemble des bijections de $E$ dans $E$. On l'appelle \emph{groupe symétrique} de $E$.
	On notera plus simplement $\mathfrak{S}_n = \mathfrak{S}(\llbracket 1, n\rrbracket)$.
	On appelle \emph{permutation} de $E$ un élément de $\mathfrak{S}(E)$.
\end{definition}

\begin{proposition}
	$\mathfrak{S}(E)$ est un groupe pour la composition, de neutre l'identité de $E$.
\end{proposition}

\begin{proposition}[\textnormal{[R] 39}]
	Si $E$ et $F$ sont deux ensembles équipotents, alors $\mathfrak{S}(E)$ et $\mathfrak{S}(F)$ sont isomorphes (en tant que groupes).
\end{proposition}

\begin{proposition}[\textnormal{[R] 39}]
	Pour $n\geq 3$, $\mathfrak{S}_3$ n'est pas commutatif.
\end{proposition}

Dans toute la suite, on étudiera $\mathfrak{S}_n$ pour $n\geq 3$.

\begin{proposition}[\textnormal{[R] 40}]
	$\#\mathfrak{S}_n = n!$
\end{proposition}

\begin{notation*}[\textnormal{[U] 41}]
	Soit $\sigma\in\mathfrak{S}_n$. On représentera $\sigma$ par la matrice $2\times n$ :
	\begin{align*}
		\sigma = \left(\begin{smallmatrix} 
			1 & 2 & \cdots & n\\
			\sigma(1) & \sigma(2) & \cdots & \sigma(n)
		\end{smallmatrix}\right)
	\end{align*}
\end{notation*}

\subsection*{B. Action naturelle de $\mathfrak{S}_n$ sur $\llbracket 1,n\rrbracket$, conséquences}

\begin{proposition}[\textnormal{[U] 41}]
		$\mathfrak{S}_n$ agit naturellement sur $\llbracket 1,n\rrbracket$ par $\sigma \cdot i = \sigma(i)$.
		Le morphisme associé est l'identité de $\mathfrak{S}_n$.
\end{proposition}

\begin{definition}[\textnormal{[U] 42}]
	On note $\Fix(\sigma)$ l'ensemble des points fixes de $\sigma\in\mathfrak{S}_n$.
	Son complémentaire dans $\llbracket 1,n\rrbracket$ est appelé \emph{support} de $\sigma$, et est noté $\Supp(\sigma)$.
\end{definition}

\begin{proposition}[\textnormal{[U] 43}]
	Soit $\sigma \in \mathfrak{S}_n$. Le sous-groupe $\langle\sigma\rangle$ agit sur $\llbracket 1,n\rrbracket$ par restriction
	de l'action de $\mathfrak{S}_n$. Les orbites de cette action sont appelées \emph{$\sigma$-orbites}.
	La réunion des $\sigma$-orbites ponctuelles est $\Fix(\sigma)$. Les $\sigma$-orbites non ponctuelles partitionnent $\Supp(\sigma)$.
\end{proposition}

\begin{example}
	Soit $\sigma = \left(\begin{smallmatrix} 
			1 & 2 & 3 & 4 & 5 \\
			2 & 1 & 3 & 5 & 4
		\end{smallmatrix}\right)$.
	On a $\Supp(\sigma)=\left\{1,2\right\}\sqcup \left\{4,5\right\}=\langle\sigma\rangle\cdot \left\{1\right\}\sqcup \langle\sigma\rangle\cdot\left\{4\right\}$.
\end{example}

\begin{definition}[\textnormal{[U] 43}]
	Un \emph{$k$-cycle} ($2\leq k \leq n$) est une permutation n'ayant qu'une seule $\sigma$-orbite non ponctuelle $\left\{i_1,\dots,i_k\right\}$.
	On la note $\sigma = (i_1,\dots,i_k)$ pour signifier que 
	$\forall j\notin \left\{i_1,\dots,i_k\right\}$, $\sigma(j)=j$ et $\sigma(i_j)=i_{j+1}$ en regardant les indices modulo $k$.

	Un $2$-cycle est appelé \emph{transposition}.
\end{definition}

\begin{proposition}[\textnormal{[U] 43}]
	$(i_1,i_2,\dots,i_k) = (i_2,i_3,\dots,i_k,i_1)=\dots=(i_k,i_1,i_2,\dots,i_{k-1})$
\end{proposition}

\begin{proposition}
	Un $k$-cycle est d'ordre $k$.
\end{proposition}

\subsection*{C. Décomposition d'une permutation, conséquences}

\begin{proposition}[\textnormal{[U] 42}]
	Deux permutations à supports disjoints commutent.
\end{proposition}

\begin{theorem}[\textnormal{[U] 43}]
	Toute permutation se décompose de manière unique (à l'ordre des facteurs près) comme produit de cycles à supports disjoints.
\end{theorem}

\begin{algorithm}[\textnormal{[U] 43}]
	Pour trouver une telle décomposition, il suffit de trouver les $r$-orbites.
	\begin{enumerate}
		\item On calcule $\sigma(1), \sigma^2(1),\dots$ justqu'à trouver $\sigma^{k_1}(1)=1$ (NB : $k_1\leq n$) ;
		\item On pose $i_2 = \min \llbracket 1,n\rrbracket \setminus (\langle\sigma\rangle\cdot\left\{1\right\})$, et de même on calcule $\sigma(i_2),\sigma^2(i_2),\dots$ jusqu'à trouver $\sigma^{k_2}(i_2)=i_2$ ;
		\item On itère jusqu'à épuiser $\llbracket 1,n\rrbracket$.
	\end{enumerate}
	On a alors $\sigma = (1,\sigma(1),\dots,\sigma^{k_1-1}(1))\circ (i_2, \sigma(i_2),\dots,\sigma^{k_2-1}(i_2))\circ \dots \circ(i_j, \sigma(i_j),\dots,\sigma^{k_j-1}(i_j))$
\end{algorithm}

\begin{example}
	$\sigma = \left(\begin{smallmatrix} 
			1 & 2 & 3 & 4 & 5 & 6 \\
			3 & 2 & 4 & 1 & 6 & 5
		\end{smallmatrix}\right) = (1,3,4)(5,6)$
\end{example}

\begin{proposition}[\textnormal{[R] 44}]
		$(i_1,\dots,i_k) = (i_1,i_2)(i_2,i_3)\dots(i_{k-1},i_k)$
\end{proposition}
\begin{corollary}[\textnormal{[R] 44}]
	Les transpositions engendrent $\mathfrak{S}_n$.
\end{corollary}
\begin{proposition}[\textnormal{[R] 45}]
	$\mathfrak{S}_n = \langle(i,i+1),\, 1\leq i\leq n\rangle = \langle (1,i), \, 2\leq i \leq n\rangle = \langle(1,2),\, (1,2,\dots, n) \rangle$
\end{proposition}

\begin{definition}[\textnormal{[U] 45}]
	On appelle \emph{type} de $\sigma\in\mathfrak{S}_n$ la liste croissante des cardinaux des $\sigma$-orbites.
\end{definition}

\begin{example}
	Le type de $(1,2,5)(3,4)(7,8)\in\mathfrak{S}_8$ est la liste $\left[1,2,2,3\right]$.
\end{example}

\begin{proposition}[\textnormal{[U] 46}]
	Deux permutations sont conjuguées dans $\mathfrak{S}_n$ si, et seulement si, elles ont le même type.
	Cela décrit donc les classes de conjugaison de $\mathfrak{S}_n$.
\end{proposition}

\begin{proposition}[\textnormal{[U] 45}]
	Si $\sigma$ est du type $\left[l_1,\dots,l_k\right]$, alors $\ord(\sigma) = l_1 \vee \dots \vee l_k$.
\end{proposition}

\subsection*{D. Signature dune permutation, groupe alterné}

\begin{proposition}[\textnormal{[R] 47}]
	Il existe un unique morphisme $\varepsilon\,\colon \mathfrak{S}_n \to \left\{\pm 1\right\}$ qui envoie
	les transpositions sur $-1$. On appelle \emph{signature} de $\sigma$ la quantité $\varepsilon(\sigma)$.
\end{proposition}

\begin{corollary}
	La signature d'un $k$-cycle est $(-1)^{k+1}$.
\end{corollary}

\begin{proposition}[\textnormal{[R] 48}]
	$\forall\sigma\in\mathfrak{S}_n$, 
	$$\varepsilon(\sigma) = \prod_{1\leq i\leq j\leq n}\frac{\sigma(j) - \sigma(i)}{j-i}$$
	En particulier, la signature mesure le nombre d'inversions.
\end{proposition}

\begin{definition}[\textnormal{[R] 48}]
	On appelle \emph{$n$-ième groupe alterné} le sous-groupe $\mathcal{A}_n = \Ker(\varepsilon)$.
	C'est l'ensemble des permutations dîtes \emph{paires}.
\end{definition}

\begin{example}
	$\mathcal{A}_3 = \left\{\textnormal{id},\, (1,2,3),\, (1,3,2)\right\}$.
\end{example}

\begin{proposition}
	$\#\mathcal{A}_n = \frac{n!}{2}$
\end{proposition}

\begin{theorem}[\textnormal{[R] 49}]
	Pour $n\geq 3$, les $3$-cycles engendrent $\mathcal{A}_n$, et y sont conjugués.
\end{theorem}

\begin{theorem}[\textnormal{[R] 50}]
	Pour $n\geq 5$, $\mathcal{A}_n$ n'admet pas de sous-groupe distingué non trivial.
\end{theorem}

\section*{II. Quelques applications du groupe symétrique}
\subsection*{A. En géométrie : les isométries des polytopes}

\begin{theorem}[\textnormal{[R] 94}]
	L'ensemble des isométries du plan conservant un triangle équilatéral est un groupe isomorphe à $\mathfrak{S}_3$.
\end{theorem}

\begin{proposition}[\textnormal{[R] 82}]
	Soit $\mathcal{C}$ un cube. L'ensemble des isométries de l'espace conservant $\mathcal{C}$ est un groupe, noté $\Is(\mathcal{C})$.
	On note $\Is^+(\mathcal{C})$ le sous-groupe de $\Is(\mathcal{C})$ formé des rotations.
\end{proposition}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[\textnormal{[R] 85}]
	\label{105dev1}
	$\Is^+(\mathcal{C}) \cong \mathfrak{S}_4$ et $\Is(\mathcal{C})\cong \mathfrak{S}_4\times \IZ/2\IZ$.
\end{theorem}
\end{tcolorbox}

\begin{theorem}[\textnormal{[R] 95}]
	En notant $\mathcal{T}$ le tétraèdre régulier, on a :
	$\Is(\mathcal{T})\cong \mathfrak{S}_4$ et $\Is^+(\mathcal{T})\cong \mathcal{A}_4$.
\end{theorem}

\subsection*{Chez les (actions de) groupes}
\begin{theorem}[de Cayley - \textnormal{[R] 53}]
	Tout groupe fini d'ordre $n$ est isomorphe à un sous-groupe de $\mathfrak{S}_n$.
\end{theorem}
\begin{proposition}
	Comme pout tout corps (commutatif) $K$, $\mathfrak{S}_n\actson GL_n(K)$, tout groupe de garde $n$ 
	est isomorphe à un sous-groupe de $GL_n(K)$.
\end{proposition}

\begin{example}
	Soit $D_{2\times 4}$ le groupe des isométries du carré. Comme $\#D_{2\times 4} = 8$, $D_{2\times 4}$ est isomorphe à un sous-groupe de $\mathfrak{S}_8$. Noton $\varphi$ un tel isomorphisme.
	Comme $D_{2\times 4} = \langle r, s\rangle$ où $\ord(r) = 4$, $\ord(s) = 2$ et $\ord(rs) = 2$, on a $\varepsilon\circ \varphi(s)=\varepsilon\circ \varphi(rs) = -1$, donc $\varepsilon\circ \varphi(r) = 1$.
\end{example}

\subsection*{C. Polynômes symétriques}
\begin{definition}[\textnormal{[R] 55}]
	Un \emph{polynôme symétrique} est un polynôme $P\in K[X_1,\dots,X_n]$
	tel que $\forall\sigma\in\mathfrak{S}_n$, $P(X_{\sigma(1)},\dots,X_{\sigma(n)}) = P(X_1,\dots,X_n)$.
\end{definition}

\begin{definition}[\textnormal{[R] 55}]
	Les \emph{polynômes symétriques élémentaires} sont les 
	\begin{align*}
		\Sigma_{k,n} = \sum_{1\leq i_1\leq\dots\leq i_k\leq n} X_{i_1}\dots X_{i_k}\in K[X_1,\dots,X_n]
	\end{align*}
\end{definition}

\begin{theorem}[ADMIS - \textnormal{[R] 55}]
	Pour tout polynôme symétrique $P\in K[X_1,\dots,X_n]$, il
	existe un unique polynôme $Q\in K[X_1,\dots,X_n]$ tel que 
	$P(X_1,\dots,X_n) = Q(\Sigma_{1,n},\dots,\Sigma_{n,n})$.
\end{theorem}

\subsection*{D. En algèbre (multi-)linéaire}
Dans ce paragraphe, $E$ est un $\mathbb{K}$-espace vectoriel de dimension finie $n$.
On fixe une base $\mathcal{B} = (e_1,\dots,e_n)$ de $E$.
\begin{definition}[\textnormal{[R] 545}]
	Une \emph{forme $k$-linéaire} sur $E$ est une application $\varphi \,\colon E^k\to \mathbb{K}$ telle que pour tout $i\in\llbracket 1,n\rrbracket$, pour tout $(x_1,\dots, x_k)\in E^k$,
	$\varphi(x_1,\dots,x_{i-1}, \cdot, x_{i+1}, \dots, x_k)$ est linéaire.

	On note $\bigotimes^k E^*$ l'ensemble des formes $k$-linéaires sur $E$.
\end{definition}

\begin{proposition}[\textnormal{[R] 546}]
	$\left(e_{i_1}^*\otimes\dots\otimes e_{i_k}^*\right)_{1\leq i_1<\dots < i_k\leq n}$ est une base de $\bigotimes^kE^*$,
	où pour $(x_1,\dots, x_k)\in E^k$, $e_{i_1}^*\otimes\dots\otimes e_{i_k}^*(x_1,\dots, x_k) = e_{i_1}^*(x_1)\dots e_{i_k}^*(x_k)$.
\end{proposition}

\begin{definition}[\textnormal{[R] 546}]
	Une forme $k$-linéaire \emph{alternée} est une forme $k$-linéaire $\varphi\in\bigotimes^kE^*$
	telle que $\forall\sigma\in\mathfrak{S}_k$, $\forall(x_1,\dots, x_k)\in E^k$, $\varphi(x_{\sigma(1)},\dots, x_{\sigma(k)}) = \varepsilon(\sigma)\varphi(x_1,\dots, x_k)$.

	On note $\bigwedge^k E^*$ l'espace des formes $k$-linéaires alternées sur $E$.
\end{definition}

\begin{proposition}
	$\left(e_{i_1}^*\wedge \dots \wedge e_{i_k}^*\right)_{1\leq i_1 < \dots < i_k\leq n}$ est une base de $\bigwedge^kE^*$, où pour $(x_1,\dots,x_k)\in E^k$,
	$e_{i_1}^*\wedge \dots \wedge e_{i_k}^*(x_1,\dots,x_k) = \sum_{\sigma\in\mathfrak{S}_k} \varepsilon(\sigma) e_{i_1}^*(x_{\sigma(1)}) \dots e_{i_k}^*(x_{\sigma(k)})$.
\end{proposition}

\begin{corollary}
	On a $\dim\left(\bigwedge^kE^*\right) = {n \choose k}$.
\end{corollary}

\begin{definition}
	On appelle \emph{déterminant dans la base $\mathcal{B}$} l'unique forme $n$-linéaire alternée $\det_{\mathcal{B}}$ sur $E$ vérifiant
	$\det_{\mathcal{B}}(\mathcal{B}) = 1$. (La fammille $\left(\det_{\mathcal{B}}\right)$ est une base de $\bigwedge^n E^*$.)
\end{definition}

\begin{proposition}[\textnormal{[R] 547}]
	$\forall(x_1,\dots, x_n)\in E^n$, $\det_{\mathcal{B}}(x_1,\dots,x_n) = \sum_{\sigma\in\mathfrak{S}_n} \varepsilon(\sigma)e_1^*(x_{\sigma(1)})\dots e_n^*(x_{\sigma(n)})$.
\end{proposition}

\subsection*{E. Résultats en probabilités}

\begin{definition}[\textnormal{[R] 51}]
	On appelle \emph{dérangement} une permutation sans point fixes.
\end{definition}

\begin{proposition}
	Notons $d_n$ le nombre de dérangements de $\llbracket 1,n\rrbracket$.
	Alors $d_n = n!\sum_{k=0}^{n}\frac{(-1)^k}{k!}$. En particulier, la probabilité
	de choisir un dérangement en tiant au hasard une permutation de $\llbracket 1,n\rrbracket$ tend vers $\frac{1}{e}$ quand $n\to +\infty$.
\end{proposition}

\begin{proposition}[\textnormal{[C]}]
	Soit $X$ la variable aléatoire qui compte le nombre de points fixes d'une permutation aléatoirement choisie dans $\mathfrak{S}_n$.
	Alors $\mathbb{E}[X] = \mathbb{V}[X] = 1$.
\end{proposition}

\subsection*{F. Groupes simples d'ordre 60}
Dans ce paragraphe, on se donne $p$ premier, et on note $\#G = p^{\alpha}m$, $m\wedge p = 1$.

\begin{definition}[\textnormal{[U] 85}]
	Un \emph{$p$-Sylow} de $G$ est un sous-groupe de $G$ de cardinal $p^{\alpha}$.
\end{definition}

\begin{notation*}
	$\Syl_p(G)$ désigne l'ensemble des $p$-Sylow de $G$, et $n_p =\#\Syl_p(G)$.
\end{notation*}

\begin{theorem}[de Sylow - \textnormal{[U] 87}]
	Soit $G$ un groupe d'ordre $p^{\alpha}m$, $p$ premier et $m\wedge p = 1$.
	\begin{enumerate}
		\item $\Syl_p(G)\neq \emptyset$
		\item $G$ agit transitivement sur $\Syl_p(G)$ par conjugaison
		\item $n_p \equiv 1\,[p]$ (donc $n_p\mid m$).
	\end{enumerate}
\end{theorem}

\begin{definition}
	On dit que $G$ est \emph{simple} si les seuls sous-groupes de $G$ distingués (\emph{i.e.} fixe par l'action par conjugaison de G) sont $\left\{1\right\}$ et $G$.
\end{definition}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[\textnormal{[S] - 277}]
	\label{105dev2}
	Si $G$ est simple et d'ordre $60$, alors $G\cong \mathcal{A}_5$.
\end{theorem}
\end{tcolorbox}

\section*{Développements}
\begin{itemize}
	\item Développement 1 : Théorème \ref{105dev1}
	\item Développement 2 : Théorème \ref{105dev2}
\end{itemize}

\section*{Références}
\begin{itemize}
	\item[R] \emph{Mathématiques pour l'agrégation - Algèbre et géométrie}, Jean-Étienne Rombaldi, 2e édition
	\item[U] \emph{Théorie des groupes}, Félix Ulmer
	\item[S] \emph{Algèbre pour la licence 3}, Szpirglas
	\item[C] \emph{Carnets de voyage en Algébrie}, Caldero
\end{itemize}

\begin{figure}[!htb]
	\centering
	\includegraphics[trim={0 0 0 0},clip,width=1\linewidth]{img/101.pdf}
	\caption{Isométries du cube}
\end{figure}

\chapter*{106 : Groupe linéaire d'un espace vectoriel de dimension finie E, sous-groupes de $GL(E)$. Applications}
\setcounter{definition}{0}

Dans cette leçon, $K$ est un corps commutatif, et $E$ est un $K$-espace vectoriel de dimension finie $n\geq 1$.
\section*{I. Endomorphismes inversibles d'un espace vectoriel}
\subsection*{A. Introduction au groupe linéaire}
\begin{theorem}[\textnormal{[Rb] 139}]
	\begin{itemize}
		\item L'ensemble $\mathcal{L}(E)$ des endomorphismes de $E$ est un anneau pour $+$ et $\circ$, dont le groupe des inversibles est noté $GL(E)$, et est appelé \emph{groupe linéaire} de $E$.
		\item Similairement, l'ensemble $\M_n(K)$ des matrices carrées de taille $n\times n$ est un anneau pour $+$ et $\times$, dont le groupe des inversibles est noté $GL_n(K)$, appelé \emph{groupe linéaire d'ordre $n$ sur $K$}.
	\end{itemize}
\end{theorem}

\begin{remark}[\textnormal{[Rb] 140}]
	Étant donnée une base $\mathcal{B}$, l'application $u\mapsto \Mat_{\mathcal{B}}(u)$ induit un isomorphisme entre $GL(E)$ et $GL_n(K)$.
\end{remark}

\begin{definition}[\textnormal{[Rb] 141}]
	On note $SL(E)$ (resp. $SL_n(K)$) le noyau du morphisme $\det$ de $GL(E)$ (resp. $GL_n(K)$) dans $K^{\times}$.
	On l'appelle \emph{groupe spécial linéaire de $E$} (resp. \emph{groupe spécial linéaire d'ordre $n$ sur $K$}).
\end{definition}

\begin{theorem}[\textnormal{[Rb] 140}]
	Soit $u\in\mathcal{L}(E)$. Comme $\dim E < +\infty$, sont équivalentes :
	\begin{enumerate}
		\item $u\in GL(E)$
		\item {\begin{enumerate}
			\item $u$ est injectif
			\item $\Ker u = \left\{0\right\}$
			\item $\exists v\in \mathcal{L}(E)\,\colon v\circ u = \id_E$
		\end{enumerate}}
		\item {\begin{enumerate}
			\item $u$ est surjectif
			\item $\im u = E$
			\item $\exists v\in \mathcal{L}(E)\,\colon u\circ v = \id_E$
		\end{enumerate}}
		\item L'image par $u$ d'une base de $E$ est une base de $E$
		\item $\det(u) \neq 0$
	\end{enumerate}
\end{theorem}

\begin{remark}
	Un matrice $A$ est inversible si, et seulement si, ses colonnes forment une base de $K^n$, et si, et seulement si, ses lignes forment une base de $K^n$.
\end{remark}

\begin{definition}
	On dit que $u\in\mathcal{L}(E)$ est une \emph{homothétie de rapport $\lambda\in K^{\times}$} si $\forall x\in E$, $u(x) = \lambda x$.
\end{definition}

\begin{proposition}
	Une homothétie de rapport $\lambda\in K^{\times}$ est inversible, d'inverse l'homothétie de rapport $1/\lambda$.
\end{proposition}

\begin{proposition}[\textnormal{[Rb] e168}]
	Les homothéties sont les seuls endomorphismes à stabiliser toute droite.
\end{proposition}

\subsection*{B. Opérations élémentaires}
Soit $A\in\M_n(K)$. On note $L_1, \dots, L_p$ les lignes de $A$, et $C_1,\dots,C_n$ ses colonnes.
\begin{definition}[\textnormal{[Bu] 315-317}]
	Soient $\alpha \in K^{\times}$, $(i,j)\in\llbracket 1,n\rrbracket^2$ tel que $i\neq j$ et $\sigma\in\mathfrak{S}_n$. On définit les matrices suivantes :
	\begin{itemize}
		\item Matrice de \emph{dilatation} $D_i(\alpha) = \diag(1,\dots, 1, \alpha,1,\dots, 1)\in GL_n(K)$ ($\alpha$ est à la $i$-ième position)
		\item Matrice de \emph{transvection} $T_{i,j}(\alpha) = I_n + \alpha E_{i,j}\in GL_n(K)$
		\item Matrice de \emph{permutation} $P_{\sigma} = \left(\delta_{i,\sigma(j)}\right)_{1\leq i,j\leq n}\in GL_n(K)$
	\end{itemize}
\end{definition}

\begin{definition}
	On définit les \emph{opérations élémentaires} sur les colonnes :
	\begin{itemize}
		\item $C_i \longleftarrow \alpha C_i$ : on remplace $C_i$ par $\alpha C_i$
		\item $C_i \longleftarrow C_i + \alpha C_j$ : on remplace $C_i$ par $\alpha C_i+\alpha C_j$
		\item $C_i \longleftrightarrow C_j$ : on échange $C_i$ et $C_j$
	\end{itemize}
\end{definition}

\begin{theorem}[\textnormal{[Bu] 315-318}]
	On a les correspondances suivantes entre opérations élémentaires et multiplication matricielle :
	\begin{itemize}
		\item $D_i(\alpha)A\iff L_i \longleftarrow \alpha L_i$
		\item $T_{i,j}(\alpha)A\iff L_i \longleftarrow L_i \alpha L_j$
		\item $P_{(i,j)}A\iff L_i \longleftrightarrow L_j$
	\end{itemize}
	et 
	\begin{itemize}
		\item $A D_i(\alpha)\iff C_i \longleftarrow \alpha C_i$
		\item $AT_{i,j}(\alpha)\iff C_{\textcolor{red}{j}} \longleftarrow C_{\textcolor{red}{j}} + \alpha C_{\textcolor{red}{i}}$		
		\item $AP_{(i,j)}\iff C_i \longleftrightarrow C_j$
	\end{itemize}
\end{theorem}

\begin{proposition}
	$\sigma\mapsto P_{\sigma}$ est un morphisme de groupes injectif de $\mathfrak{S}_n$ dans $GL_n(K)$.
\end{proposition}

\section*{II. Structure de $GL(E)$, sous-groupe orthogonal}
\subsection*{A. Structure de groupe}

\begin{theorem}[Pivot de Gauss - \textnormal{[Rb] 191}]
	Pour toute matrice de rang $r$, il existe une suite d'opérations élémentaires qui transforme cette matrice en la matrice $J_{n,r} = \diag(I_r, O_{n-r})$.
	Plus précisément, si $\rg A = n$, alors il existe $\sigma\in\mathfrak{S}_n$ et des matrices de transvection $T_1, \dots, T_p$ telles que $A = P_{\sigma}T_1\dots T_p D_{\alpha}$ où $D_{\alpha}$ est la matrice de dilatation $D_{\alpha}$ de rapport $\alpha = \det A$.
\end{theorem}

\begin{corollary}[\textnormal{[Rb] 154, 153}]
	\begin{itemize}
		\item Les matrices de transvection et de dilatation engendrent $GL_n(K)$ ;
		\item Les matrices de transvection engendrent $SL_n(K)$.
	\end{itemize}
\end{corollary}

\begin{corollary}[\textnormal{[Rb] 141}]
	$GL(E) / SL(E) \cong K^{\times}$
\end{corollary}

\begin{corollary}[\textnormal{[Rb] 141}]
	\begin{itemize}
		\item $Z(GL(E)) = K^{\times}\id_E$ (c'est l'ensemble des homothéties) ;
		\item $Z(SL(E)) = \mathbb{U}_n(K)\id_E$, où $\mathbb{U}_n(K)  \left\{\lambda\in K^{\times} \mid \lambda^n = 1\right\}$.
	\end{itemize}
\end{corollary}

\subsection*{B. Le groupe spécial orthogonal}
Soit $q$ une forme quadratique sur $E$, de forme polaire $\varphi$. Supposons $\car K \neq 2$.

\begin{definition}[\textnormal{[P] 123-124}]
	\begin{itemize}
		\item Le \emph{groupe orthogonal} de $(E,q)$ est $O(q) = \left\{u\in\mathcal{L}(E)\mid q\circ u = q\right\}$
		\item Le \emph{groupe spécial orthogonal} de $(E,q)$ est $SO(q) = \left\{u\in O(q)\mid \det u = 1\right\}$
		\item Lorsque $\varphi$ est le produit scalaire canonique relativement à une base donnée, on note $O(E)=O(q)=\left\{u\in\mathcal{L}(E)\mid {}^tu\circ u = \id_E\right\}$ et $SO(E)=SO(q)=\left\{u\in O(E)\mid \det u = 1\right\}$.
		\item On note également $O_n(K) = \left\{M\in\M_n(K)\mid {}^tMM=I_n\right\}$ et $SO_n(K)  \left\{M\in O_n(K)\mid \det M = 1\right\}$.
	\end{itemize}
\end{definition}

\begin{proposition}[\textnormal{[Rb] 722}]
	Si $\mathcal{B}$ est une base orthonormale de $E$, alors $u\in O(E)\iff \Mat_{\mathcal{B}}(u)\in O_n(K)$.
\end{proposition}

\begin{theorem}[de réduction des isométries - \textnormal{[Rb] 727}]
	Soit $u\in O(\IRn)$. Il existe une base orthonormale $\mathcal{B}$ de $\IRn$ telle que $\Mat_{\mathcal{B}}(u)=\diag(R(\theta_1),\dots,R(\theta_r),\varepsilon_1,\dots,\varepsilon_p)$
	où $R(\theta_i) = \begin{pmatrix}
		\cos \theta_i & -\sin \theta_i \\
		\sin \theta_i & \cos \theta_i
	\end{pmatrix}$ et $\varepsilon_i = \pm 1$.
\end{theorem}

\begin{remark}[\textnormal{[P] 146}]
	$SO_2(\IR) = \left\{R(\theta)\mid \theta\in\IR\right\}\cong \IR/2\pi\IZ$.
\end{remark}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[\textnormal{[C] 50}]
	\label{106dev1}
	Soient $p$ premier, $r\geq 1$ et $q = p^r$.
	\begin{align*}
		SO_2(\IF_q) \cong \begin{cases}
			\IZ/(q-1)\IZ\quad\text{si $-1$ est un carré mod $q$} \\
			\IZ/(q+1)\IZ\quad \text{sinon}
		\end{cases}
	\end{align*}
\end{theorem}
\end{tcolorbox}

\begin{definition}[\textnormal{[P] 125}]
	Soit $u\in O(q)$ telle que $u^2 = \id_E$.
	
	On dit que $u$ est une \emph{réflexion} si $\dim(\Ker(u+\id_E)) = 1$, \emph{i.e.} si $u$ est une symétrie par rapport à un hyperplan.
	
	On dit que $u$ est une \emph{renversement} si $\dim(\Ker(u+\id_E)) = 2$, \emph{i.e.} si $u$ est une symétrie par rapport à un plan.
\end{definition}


\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
On suppose désormais que $E$ est un $\IR$-espace vectoriel de dimension finie $n\geq 1$, et que $q$ est définie positive.
\begin{theorem}[\textnormal{[P] 143}]
	\label{106dev21}
	Tout élément de $O(q)$ est produit d'au plus $n$ réflexions.
\end{theorem}
\begin{lemma}
	\label{106dev22}
	Si $n\geq 3$, alors pour toutes réflexions $\tau_1$ et $\tau_2$, il existe deux renversements $\sigma_1$ et $\sigma_2$ tels que $\tau_1\tau_2 = \sigma_1\sigma_2$.
\end{lemma}
\begin{theorem}
	\label{106dev23}
	Pour $n\geq 3$, tout élément de $SO(q)$ est produit d'au plus $n$ renversements.
\end{theorem}
\end{tcolorbox}

\begin{remark}
	Ces théorèmes restent vrais si $E$ est un espace vectoriel de dimension finie sur un corps $K$ de caractéristique $\neq 2$, et si $q$ est non dégénérée (Cartan, Dieudonné).
\end{remark}

\section*{III. Topologie dans $GL(E)$}
Dans ce paragraphe, $K$ désigne $\IR$ ou $\IC$.

\begin{proposition}[\textnormal{[Rb] 160-161}]
	$GL(E)$ est ouvert dans $(\mathcal{L}(E), \vertiii\cdot)$ et $u\mapsto u^{-1}$ est continue.
\end{proposition}

\begin{proposition}
	\begin{itemize}
		\item $GL_n(\IC)$ et $SL_n(K)$ sont connexes ;
		\item $GL_n(\IR)$ a deux composantes connexes.
	\end{itemize}
\end{proposition}

\begin{proposition}
	$O_n(\IR)$ et $SO_n(\IR)$ sont compacts.
\end{proposition}

\begin{theorem}[Décomposition polaire - \textnormal{[Rb] 740}]
		\begin{align*}
			O_n(\IR)\times S_n^{++}(\IR) &\to GL_n(\IR) \\
			(H,S) &\mapsto HS
		\end{align*}
		est un homéomorphisme.
\end{theorem}

\section*{Développements}
\begin{itemize}
	\item Développement 1 : Théorème \ref{106dev1}
	\item Développement 2 : Théorème \ref{106dev21}, Lemme \ref{106dev22} et Théorème \ref{106dev23}
\end{itemize}

\section*{Références}
\begin{itemize}
	\item[Rb] \emph{Mathématiques pour l'agrégation - Algèbre et géométrie}, Jean-Étienne Rombaldi, 2e édition
	\item[P] \emph{Cours d'algèbre}, Perrin
	\item[B] \emph{Algèbre et géométrie: CAPES et Agrégation}, Pierre Burg
	\item[C] \emph{Nouvelles histoires hédonistes de groupes et géométries}, P. Caldero, J. Germoni
\end{itemize}

\chapter*{108 : Exemples de parties génératrices d'un groupe. Applications.}
\setcounter{definition}{0}
\textcolor{paragraphtext}{Soit $(G,\cdot)$ un groupe.}

\section*{0. Introduction}
\begin{lemma}[\textnormal{[R] 10}]
	Une intersection (quelconque) de sous-groupes de $G$ est un sous-groupe de $G$.
\end{lemma}

\begin{definition}[\textnormal{[R] 11}]
	Soit $X$ une partie de $G$. On appelle \emph{sous-groupe engendre par $X$}, et on note $\langle X\rangle$,
	le plus petit sous-groupe de $G$ contenant $X$. C'est l'intersection des sous-groupes de $G$ contenant $X$.

	Lorsque $X = \left\{x_1,\dots, x_n\right\}$, on note plus simple $\langle X\rangle = \langle x_1,\dots, x_n\rangle$.
\end{definition}

\begin{proposition}[\textnormal{[R] 11}]
	Soit $X$ une partie de $G$. Posont $X^{-1} = \left\{x^{-1}\mid x\in X\right\}$.
	Alors :
	$$\langle X \rangle = \left\{x_1,\dots,x_n\mid n\in\IN^*,\, (x_1,\dots, x_n)\in\left(X\cup X^{-1}\right)^n\right\}$$
\end{proposition}

\begin{definition}[\textnormal{[R] 11}]
	Une \emph{partie génératrice de $G$} est un sous-ensemble $X\subseteq G$ tel que $G = \langle X\rangle$.
\end{definition}

\begin{example}[\textnormal{[R] 12}]
	On pose $D(G) := \langle\left\{[a,b] = aba^{-1}b^{-1}\mid (a,b)\in G^2\right\}\rangle$.
	On l'appelle \emph{groupe dérivé de $G$}, c'est le plus grand sous-groupe de $G$ tel que $G/D(G)$ est abélien.
\end{example}

\section*{I. Groupes monogènes, groupes cycliques}

\begin{definition}[\textnormal{[R] 13}]
	On dit que $G$ est \emph{monogène} s'il existe $g\in G$ tel que $G = \langle g \rangle$.
	On dit que $G$ est \emph{cyclique} si $G$ est monogène et fini.
\end{definition}

\begin{theorem}[\textnormal{[R] 14}]
	Si $G$ est monogène infi, alors $G\cong \IZ$. Si $G$ est cyclique, alors il existe $n\in \IN^*$ tel que $G\cong \IZnZ$.
\end{theorem}

\begin{proposition}
	L'ensemble des générateurs de $\IZ$ est $\IZ^{\times} = \left\{\pm 1\right\}$.

	L'ensemble des générateurs de $\IZnZ$ est $\left(\IZnZ\right)^{\times} = \left\{\overline{k}\in \IZnZ\mid \exists \overline{l}\in\IZnZ\,\colon \overline{k}\overline{l} = \overline{1}\right\} = \left\{\overline{k}\in\IZnZ \mid k\wedge n = 1\right\}$.
\end{proposition}

\begin{corollary}[\textnormal{[R] 14}]
	Si $G=\langle g\rangle$, alors l'ensemble des générateurs de $G$ est $\left\{g^k\mid k\wedge \# G = 1\right\}$.
\end{corollary}

\begin{proposition_def}
	L'\emph{ordre} d'un élément $g\in G$ est le plus petit entier $k$ (ou $+\infty$) tel que $g^k = 1$. C'est aussi l'ordre de $\langle g\rangle$.
\end{proposition_def}

\begin{proposition}
	$G$ est cyclique si, et seulement si, $G$ admet un élément d'ordre $\# G$.
\end{proposition}

\begin{corollary}[\textnormal{[R] 14}]
	Tout groupe d'ordre premier est cyclique, tous ses éléments sauf $1_G$ en sont les générateurs.
\end{corollary}


\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[\textnormal{[R] 292}]
	\label{108dev1}
	Pour tous $p\geq 3$ et $\alpha\geq 1$, $\left(\IZ/p^{\alpha}\IZ\right)^{\times}$ est cyclique.
\end{theorem}
\end{tcolorbox}

\begin{theorem}[ADMIS - \textnormal{[R] 294}]
	$\left(\IZnZ\right)^{\times}$ est cyclique si, et seulement si, $n\in\left\{2,4,p^{\alpha},2p^{\alpha}\,\colon p\geq 3\text{ premier},\,\alpha\geq 1\right\}$.
\end{theorem}

\section*{II. Groupes symétriques}
\textcolor{paragraphtext}{Soit $n\geq 3$.}

\begin{definition}[\textnormal{[U] 43}]
	Le \emph{$n$-ième groupe symétrique $\mathfrak{S}_n$} est l'ensemble des bijections de $\left\{1,\dots, n\right\}$ dans $\left\{1,\dots, n\right\}$.
	Les éléments $\sigma\in\mathfrak{S}_n$ sont appelés \emph{permutations}.
\end{definition}

\begin{proposition_def}
	Soit $\sigma\in\mathfrak{S}_n$. Le sous-groupe $\langle \sigma\rangle$ agit sur $\llbracket 1,n\rrbracket$ par restriction de l'action de $\mathfrak{S}_n$.
	Les orbites de cette action sont appelées $\sigma$-orbites.
\end{proposition_def}

\begin{definition}[\textnormal{[U] 43}]
	Un $k$-cycle ($2\leq k\leq n$) est une permutation $\sigma$ n'ayrant qu'une seule $\sigma$-orbite non ponctuelle $\left\{i_1,\dots, i_k\right\}$.
	On la note $\sigma = (i_1,\dots, i_k)$ pour signifier que $\forall j\notin\left\{i_1,\dots, i_k\right\},\,\sigma(j)=j$, et $\sigma(i_j) = i_{j+1}$ en regardant les indices modulo $k$.

	Un $2$-cycle est appelé \emph{transposition}.
\end{definition}

\begin{theorem}[\textnormal{[U] 43}]
	Toute permutation se décompose de manièr eunique (à l'ordre des facteurs près) comme produit de cycles à supports disjoints.
\end{theorem}

\begin{proposition}[\textnormal{[R] 44}]
	$(i_1,\dots,i_k) = (i_1,i_2)(i_2,i_3)\cdots (i_{k-1},i_k)$
\end{proposition}

\begin{corollary}[\textnormal{[R] 44}]
	Les transpositions engendrent $\mathfrak{S}_n$.
\end{corollary}

\begin{proposition}[\textnormal{[R] 44-45}]
	$\mathfrak{S}_n = \langle (i,i+1),\, 1\leq i\leq n\rangle = \langle (1,i),\,2\leq i\leq n\rangle = \langle (1,2), (1,2,\dots,n)\rangle$.
\end{proposition}

\begin{proposition_def}[\textnormal{[R] 47}]
	Il existe un unique morphisme $\varepsilon\,\colon \mathfrak{S}_n\to\left\{\pm 1\right\}$ qui envoie les transposition sur $-1$.
	On appelle \emph{signature de $\sigma$} la quantité $\varepsilon(\sigma)$.
\end{proposition_def}

\begin{definition}[\textnormal{[R] 49}]
	On appelle \emph{$n$-ième groupe alterné} le sous-groupe $\A_n =\Ker \varepsilon$. C'est l'ensemble des permutations dites \emph{paires}.
\end{definition}

\begin{theorem}[\textnormal{[R] 49}]
	Pour $n\geq 3$, les $3$-cyles engendrent $\A_n$, et y sont conjugués.
\end{theorem}

\begin{theorem}[\textnormal{[R] 50}]
	Pour $n\geq 5$, $\A_n$ est simple.
\end{theorem}

\section*{III. Groupes linéaires, groupes orthogonaux}
\textcolor{paragraphtext}{Soient $K$ un corps et $n\geq 2$.}

\subsection*{A. Groupes linéaires et pivot de \textsc{Gauss}}

\begin{definition}[\textnormal{[R] 139}]
	L'ensembe $\M_n(K)$ des matrices carrées de taille $n\times n$ est un anneau pour $+$ et $\times$, dont le groupe des inversibles est noté $GL_n(K)$, appelé \emph{groupe linéaire d'ordre $n$ sur $K$}.
\end{definition}

\begin{definition}
	On note $SL_n(K)$ le noyau du morphisme $\det$ de $GL_n(K)$ dans $K^{\times}$.
	On l'appelle \emph{groupe spécial linéaire d'ordre $n$ sur $K$}.
\end{definition}

\textcolor{paragraphtext}{Soit $A\in\M_n(K)$. On note $L_1,\dots, L_p$ les lignes de $A$, et $C_1,\dots, C_n$ ses colonnes.}

\begin{definition}[\textnormal{[Bu] 315-317}]
	Soient $\alpha \in K^{\times}$, $(i,j)\in\llbracket 1,n\rrbracket^2$ tel que $i\neq j$ et $\sigma\in\mathfrak{S}_n$. On définit les matrices suivantes :
	\begin{itemize}
		\item Matrice de \emph{dilatation} $D_i(\alpha) = \diag(1,\dots, 1, \alpha,1,\dots, 1)\in GL_n(K)$ ($\alpha$ est à la $i$-ième position)
		\item Matrice de \emph{transvection} $T_{i,j}(\alpha) = I_n + \alpha E_{i,j}\in GL_n(K)$
		\item Matrice de \emph{permutation} $P_{\sigma} = \left(\delta_{i,\sigma(j)}\right)_{1\leq i,j\leq n}\in GL_n(K)$
	\end{itemize}
\end{definition}

\begin{definition}
	On définit les \emph{opérations élémentaires} sur les colonnes :
	\begin{itemize}
		\item $C_i \longleftarrow \alpha C_i$ : on remplace $C_i$ par $\alpha C_i$
		\item $C_i \longleftarrow C_i + \alpha C_j$ : on remplace $C_i$ par $\alpha C_i+\alpha C_j$
		\item $C_i \longleftrightarrow C_j$ : on échange $C_i$ et $C_j$
	\end{itemize}
\end{definition}

\begin{theorem}[\textnormal{[Bu] 315-318}]
	On a les correspondances suivantes entre opérations élémentaires et multiplication matricielle :
	\begin{itemize}
		\item $D_i(\alpha)A\iff L_i \longleftarrow \alpha L_i$
		\item $T_{i,j}(\alpha)A\iff L_i \longleftarrow L_i \alpha L_j$
		\item $P_{(i,j)}A\iff L_i \longleftrightarrow L_j$
	\end{itemize}
	et 
	\begin{itemize}
		\item $A D_i(\alpha)\iff C_i \longleftarrow \alpha C_i$
		\item $AT_{i,j}(\alpha)\iff C_{\textcolor{red}{j}} \longleftarrow C_{\textcolor{red}{j}} + \alpha C_{\textcolor{red}{i}}$
		\item $AP_{(i,j)}\iff C_i \longleftrightarrow C_j$
	\end{itemize}
\end{theorem}

\begin{theorem}[Pivot de Gauss - \textnormal{[Rb] 191}]
	Pour toute matrice de rang $r$, il existe une suite d'opérations élémentaires qui transforme cette matrice en la matrice $J_{n,r} = \diag(I_r, O_{n-r})$.
	Plus précisément, si $\rg A = n$, alors il existe $\sigma\in\mathfrak{S}_n$ et des matrices de transvection $T_1, \dots, T_p$ telles que $A = P_{\sigma}T_1\dots T_p D_{\alpha}$ où $D_{\alpha}$ est la matrice de dilatation $D_{\alpha}$ de rapport $\alpha = \det A$.
\end{theorem}

\begin{corollary}[\textnormal{[Rb] 154, 153}]
	\begin{itemize}
		\item Les matrices de transvection et de dilatation engendrent $GL_n(K)$ ;
		\item Les matrices de transvection engendrent $SL_n(K)$.
	\end{itemize}
\end{corollary}

\subsection*{B. Groupe orthogonal d'un espace quadratique}
\textcolor{paragraphtext}{Soit $(E,q)$ un espace quadratique sur $K$, de forme polaire $\varphi$. Supposons $\car K \neq 2$.}
\begin{definition}[\textnormal{[P] 123-124}]
	On définit les éléments suivants :
	\begin{itemize}
		\item Le \emph{groupe orthogonal de $(E,q)$} est $O(q) = \left(u\in\mathcal{L}(E)\mid q\circ u=q\right)$
		\item Le \emph{groupe spécial orthogonal de $(E,q)$} est $SO(q) = \left\{u\in O(q)\mid \det u = 1\right\}$.
		\item Lorsque $\varphi$ est le produit scalaire canonique relativement à une base donnée, note $O(E) = O(q)=\left\{u\in\mathcal{L}(E)\mid {}^tu\circ u =\id_E\right\}$ et $SO(E)=SO(q)=\left\{u\in O(E)\mid \det u = 1 \right\}$
		\item No note également $\mathcal{O}_n(K) =\left\{M\in\M_n(K)\mid {}^tMM=I_n\right\}$ et $\mathcal{SO}_n(K)=\left\{M\in\mathcal{O}_n(K)\mid \det M = 1 \right\}$.
	\end{itemize}
\end{definition}

\begin{proposition}[\textnormal{[R] e723}]
	Si $\B$ est une base orthonormale de $E$, alors $u\in O(E)\iff\Mat_{\B}(u)\in\mathcal{O}_n(K)$.
\end{proposition}

\begin{theorem}[de réduction des isométries - \textnormal{[R] 746}]
	Soit $u\in O(\IRn)$. Il existe une base orthonormale $\mathcal{B}$ de $\IRn$ telle que $\Mat_{\mathcal{B}}(u)=\diag(R(\theta_1),\dots,R(\theta_r),\varepsilon_1,\dots,\varepsilon_p)$
	où $R(\theta_i) = \begin{pmatrix}
		\cos \theta_i & -\sin \theta_i \\
		\sin \theta_i & \cos \theta_i
	\end{pmatrix}$ et $\varepsilon_i = \pm 1$.
\end{theorem}

\begin{definition}[\textnormal{[P] 125}]
	Soit $u\in O(q)$ telle que $u^2 = \id_E$.
	
	On dit que $u$ est une \emph{réflexion} si $\dim(\Ker(u+\id_E)) = 1$, \emph{i.e.} si $u$ est une symétrie par rapport à un hyperplan.
	
	On dit que $u$ est une \emph{renversement} si $\dim(\Ker(u+\id_E)) = 2$, \emph{i.e.} si $u$ est une symétrie par rapport à un plan.
\end{definition}


\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\textcolor{paragraphtext}{On suppose désormais que $E$ est un $\IR$-espace vectoriel de dimension finie $n\geq 1$, et que $q$ est définie positive.}
\begin{theorem}[\textnormal{[P] 143}]
	\label{108dev21}
	Tout élément de $O(q)$ est produit d'au plus $n$ réflexions.
\end{theorem}

\begin{lemma}[\textnormal{[P] 143}]
	\label{108dev22}
	Si $n\geq 3$, alors pour toutes réflexions $\tau_1$ et $\tau_2$, il existe deux renversements $\sigma_1$ et $\sigma_2$ tels que $\tau_1\tau_2 = \sigma_1\sigma_2$.
\end{lemma}

\begin{theorem}[\textnormal{[P] 143}]
	\label{109dev23}
	Pour $n\geq 3$, tout élément de $SO(q)$ est produit d'au plus $n$ renversements.
\end{theorem}
\end{tcolorbox}

\section*{Développements}
\begin{itemize}
	\item Développement 1 : Théorème \ref{108dev1}
	\item Développement 2 : Lemme \ref{108dev21} et Théorèmes \ref{108dev22} et \ref{108dev23}
\end{itemize}

\section*{Références}
\begin{itemize}
	\item[R] \emph{Mathématiques pour l'agrégation - Algèbre et géométrie}, Jean-Étienne Rombaldi, 2e édition
	\item[P] \emph{Cours d'algèbre}, Perrin
	\item[B] \emph{Algèbre et géométrie: CAPES et Agrégation}, Pierre Burg
	\item[U] \emph{Théorie des groupes}, Félix Ulmer
\end{itemize}


\chapter*{120 : Anneaux $\IZnZ$. Applications.}
Dans toute la leçon, $n\in\IN\setminus\left\{0,1\right\}$ et $p$ est un nombre premier.
\setcounter{definition}{0}
\section*{I. L'anneau $\IZnZ$}
\subsection*{A. Rappels d'arithmétique des entiers}
\begin{theorem}[division euclidienne - \textnormal{[R] 279}]
	$\forall (a,b)\in\IZ^2,\,\exists ! (q,r)\in\IZ^2 \,\colon$
	\begin{align*}
		\begin{cases}
			a=bq+r \\
			0\leq r< |b|
		\end{cases}
	\end{align*}
\end{theorem}

\begin{definition}[\textnormal{[R] 279}]
	Soit $(a,b)\in\IZ^2$. On dit que $a$ est \emph{congru à} $b$ modulo $n$,
	et on note $a\equiv b \, [n]$ si $n$ divise $b-a$.
\end{definition}

\begin{proposition}[\textnormal{[R] 280}]
	Soit $(a,b,c,d)\in\IZ^4$ tel que $a\equiv b\,[n]$ et $c\equiv d\,[n]$.
	Alors $a+c\equiv b+d\,[n]$ et $ac\equiv bd \,[n]$.
\end{proposition}

\subsection*{B. Construction}
\begin{lemma}
	Tout idéal de $\IZ$ est principal, et admet un unique générateur positif.
\end{lemma}

\begin{definition}[\textnormal{[R] 280}]
	Le quotient de l'anneau $(\IZ, +,\times)$ par son idéal $n\IZ$ est l'anneau noté $\IZnZ$. On note $\overline{a}$ l'image de $a\in\IZ$ dans $\IZnZ$.
\end{definition}

\begin{remark}
	$\overline{a} = \overline{b} \iff a\equiv b\,[n]$
\end{remark}

\begin{proposition}[\textnormal{[R] 280}]
	$\IZnZ = \left\{\overline{0},\overline{1},\dots,\overline{n-1}\right\}$, et les lois sont données par Prop 3 et Rq 6.
\end{proposition}

\begin{example}
	$\IZ/3\IZ = \left\{\overline{0},\overline{1},\overline{2}\right\} =\left\{\overline{9},\overline{64},\overline{-7}\right\}$,
	et on a $\overline{1}+\overline{2}=\overline{1+2}=\overline{3}=\overline{0}$, mais aussi $\overline{1}\times\overline{2} = \overline{1\times 2}=\overline{2}$.
\end{example}

\subsection*{C. Structure d'anneau}
\begin{proposition}[\textnormal{[R] 283}]
	L'ensemble des inversibles $\IZnZ$ est :
	$$\left(\IZnZ\right)^{\times} = \left\{\overline{k}\in\IZnZ\mid k\wedge n = 1\right\}$$

	L'ensemble des diviseurs de $O$ de $\IZnZ$ est :
	$$D_0\left(\IZnZ\right) = \IZnZ \setminus \left[\left(\IZnZ\right)^{\times}\cup \left\{0\right\}\right]$$
\end{proposition}

\begin{example}
	$\left(\IZ/8\IZ\right)^{\times} = \left\{\overline{1},\overline{3},\overline{5},\overline{7}\right\}$, et 
	$D_0\left(\IZ/8\IZ\right) = \left\{\overline{2},\overline{4},\overline{6}\right\}$.
\end{example}

\begin{proposition}[\textnormal{[R] 241 et 281}]
	Les idéaux propres de $\IZnZ$ sont les $d\IZnZ$ avec $d\mid n$, $d\notin \left\{1,n\right\}$.
	De plus, $\left(d\IZnZ, +\right)\cong \left(\IZ/\frac{n}{d}\IZ, +\right)$.
\end{proposition}

\begin{corollary}
	$\IZnZ$ est principal.
\end{corollary}

\begin{corollary}
	L'ensemble des générateurs de $\IZnZ$ est $\left(\IZnZ\right)^{\times}$.
\end{corollary}

\begin{example}
	Les idéaux propres de $\IZ/6\IZ$ sont $2\IZ/6\IZ$ et $3\IZ/6\IZ$, respectivement isomorphes à $\IZ/3\IZ$ et $\IZ/2\IZ$.
\end{example}

\begin{proposition}[\textnormal{[R] 295-282}]
	$\forall n,m\geq 2$, 
	$$\Hom_{gr}(\IZnZ, \IZ/m\IZ)\cong \IZ/(n\wedge m)\IZ,$$
	$$\Aut(\IZnZ)\cong \left(\IZnZ\right)^{\times},$$
	$$\Hom_{Ann}(\IZnZ, \IZ/m\IZ)\cong  \begin{cases}
		\left\{k\text{ mod } n \mapsto k \text{ mod } m\right\} \quad\text{si } m\mid n \\
		\emptyset\quad\text{sinon}
	\end{cases}$$
\end{proposition}

\subsection*{D. Le corps $\IZ/p\IZ$}
\begin{theorem}
	Les assertions suivantes sont équivalentes :
	\begin{enumerate}
		\item $\IZnZ$ est un corps ;
		\item $\IZnZ$ est intègre ;
		\item $n$ est premier.
	\end{enumerate}
\end{theorem}

\begin{corollary}[\textnormal{[R] 292}]
	$\left(\IZ/p\IZ\right)^{\times} \cong \IZ/(p-1)\IZ$.
\end{corollary}

\begin{cexample}
	C'est très faux pour $n$ non premier !
	$\left(\IZ/8\IZ\right)^{\times} = \left\{\overline{1},\overline{3},\overline{5},\overline{7}\right\}$ n'a même pas $7$ éléments !
\end{cexample}

\section*{II. Structure de $\left(\IZnZ\right)^{\times}$}
\subsection*{A. Préambule : le théorème des restes chinois}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[des restes chinois - \textnormal{[R] 285}]
	\label{120dev1}
	Soit $(a_1,\dots, a_d)\in \left(\IN\setminus \left\{0,1\right\}\right)^d$.
	Les entiers, $a_1,\dots, a_d$ sont deux à deux premiers si, et seulement si, les anneaux 
	$\IZ/a_1\dots a_d\IZ$ et $\IZ/a_1\IZ \times \dots \times \IZ/a_d\IZ$ sont isomorphes.

	Le cas échéant, il existe $(u_1,\dots,u_d)\in\IZ^d$ tel que $\sum_{i=1}^{d} a_ib_i =1$, où 
	$b_i = \frac{a_1\dots a_d}{a_i}$. L'application :

	\begin{align*}
		\overline{\varphi} \,\colon \IZ/a_1\dots a_d\IZ &\to \IZ/a_1\IZ \times \dots \times \IZ/a_d\IZ \\
		x\,mod\,a_1\dots a_d &\mapsto (x\,mod\,a_1,\dots, x\, mod\, a_d)
	\end{align*}
	est un isomorphisme d'anneaux, de réciproque :
	\begin{align*}
		\overline{\varphi}^{-1}\,\colon (x_1\,mod\,a_1,\dots, x_d\, mod\, a_d) \mapsto \sum_{i=1}^{d} x_i a_i b_i\, mod\, a_1\dots a_d
	\end{align*}
\end{theorem}
\end{tcolorbox}

\subsection*{B. Fonction indicatrice d'Euler}
\begin{definition}[\textnormal{[R] 283}]
	\emph{L'indicatrice d'Euler} est :
	$\varphi\,\colon n \mapsto \#\left(\IZnZ\right)^{\times} = \#\left\{k\in\llbracket 1,n\rrbracket \mid k\wedge n = 1\right\}$.
\end{definition}

\begin{example}
	$\varphi(8) = 4$ d'après Exemple 10.
\end{example}

\begin{proposition}[\textnormal{[R] 288}]
	Si $a\wedge b=1$, alors $\varphi(ab)=\varphi(a)\varphi(b)$.
	Pour tout $\alpha \in \IN^*$, $\varphi(p^{\alpha}) = p^{\alpha - 1}(p-1)$.
\end{proposition}

\begin{corollary}[\textnormal{[R] 288}]
	Si $n=p_1^{\alpha_1}\dots p_r^{\alpha_r}$ est la décomposition de $n$ en produit de facteurs premiers,
	alors :
	$$\varphi(n) = \prod_{i=1}^{r} p^{\alpha_i - 1}(p-1) = n\prod_{i=1}^{r}\left(1 - \frac{1}{p_i}\right)$$
\end{corollary}

\begin{example}
	$\varphi(90) = \varphi(3^2)\varphi(2)\varphi(5) = 3(3-1)(2-1)(5-1) = 24$
\end{example}

\begin{theorem}[d'Euler - \textnormal{[R] 283}]
	Si $a\wedge n = 1$, alors $a^{\varphi(n)} \equiv 1\,[n]$.
\end{theorem}

\begin{theorem}[de Fermat - \textnormal{[R] 284}]
	Si $a\wedge p = 1$, alors $a^{p-1} = 1\, [p]$.
	De manière générale, $a^p\equiv a\,[p]$.
\end{theorem}

\begin{proposition}[\textnormal{[R] 284}]
	$$n = \sum_{d\mid n} \varphi(d)$$
\end{proposition}


\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[\textnormal{[R] 292}]
	\label{120dev2}
	Si $p\geq 3$, alors $\forall \alpha \geq 1$, $\left(\IZ/p^{\alpha}\IZ\right)^{\times}$ est cyclique.
\end{theorem}
\end{tcolorbox}

\begin{theorem}[ADMIS - \textnormal{[R] 294}]
	$\left(\IZnZ\right)^{\times}$ est cyclique si, et seulement si, $n\in \left\{2,4,p^{\alpha}, 2p^{\alpha}\right\}$ avec $p\geq 3$ (premier) et $\alpha\geq 1$.
\end{theorem}

\section*{III. Applications}
\subsection*{A. Résolution de systèmes de congruence}
\begin{theorem}[\textnormal{[R] 290}]
	L'équation $ax\equiv b\,[n]$ d'inconnue $x\in\IZ$ admet des solutions si, et seulement si, $a\wedge n \mid b$.

	Le cas échéant, $S(ax\equiv b\,[n]) = \frac{b}{a\wedge n}x_0 + \frac{n}{a\wedge n}\IZ$, où $x_0$ est une solution particulière de l'équation.
\end{theorem}

\begin{remark}
	Le théorème des restes chinois permet de résoudre des systèmes de congruences.
\end{remark}


\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{example}[\textnormal{[R] 291}]
	\label{120dev12}
	$S\left(\begin{cases}
		x\equiv 2\,[4] \\
		x\equiv 3\,[5] \\
		x\equiv 1\,[9]
	\end{cases}\right) = 118 + 180\IZ$
\end{example}
\end{tcolorbox}

\begin{remark}[\textnormal{[R] 291}]
	$S\left(\begin{cases}
		x\equiv x_1\,[a_1] \\
		x\equiv x_2\,[a_2]
	\end{cases}\right) =\begin{cases}
		\emptyset\quad\text{si } a_1\wedge a_2 \nmid x_1-x_2 \\
		x_0 + (a_1\vee a_2)\IZ\quad\text{sinon}
	\end{cases}$
\end{remark}

\subsection*{B. Carrés de $\IZ/p\IZ$}
Soit $c\,\colon \overline{x}\in\IZ/p\IZ \mapsto \overline{x}^2$.
On s'intéresse à $\im c$.

\begin{proposition}
	Tous les éléments de $\IZ/2\IZ$ sont des carrés.
\end{proposition}
On supposera désormais $p\geq 3$.

\begin{proposition}[\textnormal{[R] 426}]
	Soit $l\,\colon \overline{x}\in\IZ/p\IZ \mapsto \overline{x}^{\frac{p-1}{2}}$.
	\begin{itemize}
		\item $\forall \overline{x}\in\IZ/p\IZ$, $c\circ l(\overline{x}) = l\circ c(\overline{x}) = \overline{1}$
		\item $\Ker c = \im l =\left\{\pm 1\right\}$ et $\im c = \Ker l$.
	\end{itemize}
\end{proposition}

\begin{corollary}
	Il y a $\frac{p+1}{2}$ carrés dans $\IZ/p\IZ$.
\end{corollary}

\begin{theorem}[de Wilson - \textnormal{[R] 325}]
	$n$ est premier $\iff (n-1)! \equiv -1\, [n]$
\end{theorem}

\begin{proposition}[\textnormal{[P] 75}]
	$-1$ est un carré modulo $p$ si, et seulement si, $p\equiv 1\,[4]$. Le cas échéant $-1\equiv (2\times 3\times\dots\times \frac{p-1}{2})^2\,[p]$.
\end{proposition}

\begin{theorem}[des deux carrés de Fermat - \textnormal{[P] 56}]
	$p$ s'écrit comme somme de deux carrés d'entiers si, et seulement si, $p=2$ ou $p \equiv 1\,[4]$.
\end{theorem}

\subsection*{C. Algorithme de chiffrement RSA}

\begin{algorithm}[\textnormal{[G] 37}]
	Alice veut envoyer à Bob un message représenté par un nombre 
entier $m$, en tout sécurité.
\begin{itemize}
	\item Bob choisit en secret deux nombres premiers distincts $p$ et $q$ et calcule leur produit $n=pq$.
	\item Il choisit ensuite un entier $c<\varphi(n)=(p-1)(q-1)$ premier à $\varphi(n)$.
	\item Il trouve ensuite un entier $d$ tel que $cd \equiv 1\,[\varphi(n)]$.
	\item La clé publique de Bob est $(n,c)$, qu'il donne à Alice, et sa clé privée est $(n,d)$, qu'il garde secrète.
	\item Alice envoie à Bob le message $m^c$ mod $n$.
	\item Pour décoder le message, Bob calcule $\left(m^c\right)^d\equiv m\,[n]$.
\end{itemize}
\end{algorithm}

\section*{Développements}
\begin{itemize}
	\item Développement 1 : Théorème \ref{120dev1} (restes chinois) et exemple \ref{120dev12}
	\item Développement 2 : Théorème \ref{120dev2} (cyclicité des inversibles de $\IZ/p^{\alpha}\IZ$)
\end{itemize}

\section*{Références}
\begin{itemize}
	\item[Rb] \emph{Mathématiques pour l'agrégation - Algèbre et géométrie}, Jean-Étienne Rombaldi, 2e édition
	\item[P] \emph{Cours d'algèbre}, Perrin
	\item[G] \emph{Les maths en tête - Algèbre et probabilités}, Xavier Gourdon, 3e édition
\end{itemize}

\chapter*{121 : Nombres premiers. Applications.}
\setcounter{definition}{0}
Pour un entier $n$, $\Div(n)$ désigne l'ensemble des diviseurs positifs de $n$.	

\section*{I. Résultats fondamentaux sur les nombres premiers}
\subsection*{A. Notion de nombre premier, propriétés élémentaires}

\begin{definition}[\textnormal{[R] 303}]
	On dit que $p\in\IN$ est \emph{premier} si $\Div(p)=\left\{1,p\right\}$.
	On dit que $n$ est \emph{composé} si $n\neq 0$ et si $\exists a\in\IN\setminus\left\{1,n\right\}\,\colon a\mid n$.
\end{definition}

Dans la suite, $\mathcal{P}$ désignera l'ensemble des nombres premiers.

\begin{lemma}[d'Euclide]
	$\forall(a,b)\in\IN^2$, $\forall p\in\mathcal{P}$, $p\mid ab \implies (p\mid a)$ ou $(p\mid b)$.
\end{lemma}

\begin{lemma}[\textnormal{[R] 303}]
	$\forall n\geq 2,\, \exists p\in\mathcal{P}\,\colon p\mid n$
\end{lemma}

\begin{proposition}[\textnormal{[R] 304}]
	Tout entier composé $n$ admet un facteur premier entre $2$ et $\sqrt{n}$.
\end{proposition}

\begin{theorem}[fondamental de l'Arithmétique - \textnormal{[R] 306}]
	$\forall n\in\IN^*,\,\exists ! \left(v_p(n)\right)_{p\in\mathcal{P}}\in\IN^{\mathcal{P}} \,\colon$ 
	$$n = \prod_{p\in\mathcal{P}} p^{v_p(n)}$$
	Cette écriture est appelée \emph{"(la) décomposition en produit de facteurs premieres de $n$"}.
\end{theorem}

\begin{definition}[\textnormal{[R] 306}]
	Dans la décomposition en produit de facteurs premiers de $n$, l'entier $v_p(n)$ ($p\in\mathcal{P}$) est appelé \emph{valuation $p$-adique de $n$}.
\end{definition}

\begin{proposition}[\textnormal{[R] 307}]
	$\forall(a,b)\in\left(\IN^*\right)^2,\, a\mid b\iff \forall p\in\mathcal{P},\, v_p(a)\leq v_p(b)$
\end{proposition}

\begin{proposition}[\textnormal{[R] 319}]
	$\forall(a,b)\in\left(\IN^*\right)^2,\, v_p(ab) = v_p(a)+v_p(b)$
\end{proposition}

\begin{proposition}[\textnormal{[R] 307}]
	$\forall(a,b)\in\left(\IN^*\right)^2,\,\forall p\in\mathcal{P},$
	\begin{align*}
		v_p(a\vee b) &= \max (v_p(a),v_p(b)) \\
		v_p(a\wedge b) &= \min (v_p(a),v_p(b))
	\end{align*}
\end{proposition}

\subsection*{B. Répartition des nombres premiers}
\begin{theorem}[Euclide - \textnormal{[R] 305}]
	Il existe une infinité de nombres premiers.
\end{theorem}

\begin{theorem}[de la progression arithmétique, Dirichlet, ADMIS]
	Pour tout $(a,b)\in\left(\IN^*\right)^2$ tel que $a\wedge b = 1$, il existe une infinité de nombres premiers congrus à $a$ modulo $b$.
\end{theorem}

\begin{conjecture}[des nombres premiers jumaux]
	Il existe une infinité de nombres premiers $p$ tels que $p+2$ est premier.
\end{conjecture}

\begin{proposition}
	Il existe des intervalles de longueur arbitrairement grande ne contenant aucun nombre premier.
\end{proposition}

\begin{theorem}[Bertrand - ADMIS - \textnormal{[R] 325}]
	Il existe toujours un nombre premier compris entre n'importe quel entier naturel non nul et son double.
\end{theorem}

\begin{theorem}[des nombres premiers - ADMIS - \textnormal{[R] 308}]
	$$\#\mathcal{P}\cap \llbracket 1,n\rrbracket \sim_{x\to +\infty} \frac{n}{\ln n}$$
\end{theorem}

\section*{II. Tests de primalité}

\begin{proposition}[Crible d'Ératosthène - ANNEXE]
	Le procédé suivant permet de trouver la liste croissante des nombres premiers : on part de la liste des entiers plus grands que $2$. À chaque itération,
	on garde le plus petit nombre, et on supprime tous ses multiples.
\end{proposition}

\begin{proposition}
	$n$ est premier si, et seulement si, $\forall d\leq \lfloor\sqrt{n}\rfloor$, $d\nmid n$.
	La complexité au pire de ce test est donc en $O(\sqrt{n})$.
\end{proposition}

\begin{theorem}[de Fermat]
	Si $p$ est premier, alors $\forall a\in \IN$, $a\wedge p=1\implies a^{p-1} \equiv 1\,[p]$.
\end{theorem}

\begin{remark}
	On en déduit donc un test de non primalité.
\end{remark}

\begin{definition}[\textnormal{[R] 329}]
	Un nombre $n$ composé satisfaisant le test du théorème de Fermat est appelé \emph{nombre de Carmichaël}.
\end{definition}

\begin{example}[\textnormal{[R] 329}]
	$561$ est un nombre de Carmichaël.
\end{example}

\begin{theorem}[de Korselt - \textnormal{[R] 330}]
	$n$ est un nombre de Carmichaël si, et seulement si, pour tout diviseur premier $p$ de $n$, $(p-1)\mid(n-1)$ et $p^2\nmid n$.
\end{theorem}

\begin{theorem}[de Wilson - \textnormal{[R] 326}]
	$n$ est premier si, et seulement si, $(n-1)!\equiv -1\,[n]$.
	C'est un test de primalité qui requiert $n-1$ multiplications dans $\IZnZ$.
\end{theorem}

\section*{III. Applications des nombres premiers}
\subsection*{A. Fonctions spéciales}

\begin{definition}[\textnormal{[R] 283}]
	\emph{L'indicatrice d'Euler} est :
	$\varphi\,\colon n \mapsto \#\left(\IZnZ\right)^{\times} = \#\left\{k\in\llbracket 1,n\rrbracket \mid k\wedge n = 1\right\}$.
\end{definition}

\begin{proposition}[\textnormal{[R] 288}]
	$\forall(a,b)\in\left(\IN^*\right)^2$, $a\wedge b=1$, alors $\varphi(ab)=\varphi(a)\varphi(b)$.
	Pour tout $\alpha \in \IN^*$, $\varphi(p^{\alpha}) = p^{\alpha - 1}(p-1)$.
\end{proposition}

\begin{corollary}[\textnormal{[R] 288}]
	$\forall n\in\IN^*$,
	$$\varphi(n) = \prod_{\substack{p\in\mathcal{P}\\v_p(n)\geq 1}} p^{v_p(n)-1}(p-1) = n\prod_{\substack{p\in\mathcal{P}\\v_p(n)\geq 1}} \left(1 - \frac{1}{p}\right)$$	
\end{corollary}

\begin{definition}
	La \emph{fonction $\zeta$ de Riemann} est définie par :
	\begin{align*}
		\zeta\,\colon \left\{z\in\IC\mid \Re(z)> 1\right\} &\to \IC \\
		s &\mapsto \sum_{n=0}^{+\infty} \frac{1}{n^s}
	\end{align*}
\end{definition}

\begin{proposition}[\textnormal{[KG] 461}]
	On a :
	$$\zeta(s) = \prod_{p\in\mathcal{P}}\frac{1}{1 - \frac{1}{p^s}}$$
	Cette écriture est appelé \emph{"produit eulérien"}.
\end{proposition}

\begin{theorem}[\textnormal{[KG] 461, [R] 343}]
	$\sum_{p\in\mathcal{P}}\frac{1}{p} = +\infty$
\end{theorem}

\begin{definition}[\textnormal{[R] 331}]
	La \emph{fonction de Moëbius} est définie par :
	\begin{align*}
		\mu\,\colon n\in\IN^* \mapsto \begin{cases}
			1\quad \text{si } n =1 \\
			(-1)^r\quad \text{si } n=p_1\dots p_r,\text{ avec $p_1,\dots,p_r$ distincts} \\
			0\quad\text{sinon}
		\end{cases}
	\end{align*}
\end{definition}

\begin{theorem}[Cesàro - ADMIS \textnormal{[R] 334}]
	La probabilité de choisir au hasard $r\geq 2$ entiers entre $1$ et $n$ qui sont premiers entre eux vaut $\frac{1}{\zeta(r)}$.
\end{theorem}

\subsection*{B. Algorithme de chiffrement RSA}

\begin{theorem}[d'Euler - \textnormal{[R] 283}]
	$\forall (a,b)\in\left(\IN^*\right)^2$, si $a\wedge n = 1$, alors $a^{\varphi(n)} \equiv 1\,[n]$.
\end{theorem}

De la complexité des tests de primalité découle la grande difficulté de la recherche de la décomposition en produit de facteurs premiers d'un entier donné.
Ce principe est à la base de la sécurité de l'algorithme de chiffrement RSA, détaillé ci-dessous :

\begin{algorithm}[\textnormal{[G] 37}]
	Alice veut envoyer à Bob un message représenté par un nombre 
entier $m$, en tout sécurité.
\begin{itemize}
	\item Bob choisit en secret deux nombres premiers distincts $p$ et $q$ et calcule leur produit $n=pq$.
	\item Il choisit ensuite un entier $c<\varphi(n)=(p-1)(q-1)$ premier à $\varphi(n)$.
	\item Il trouve ensuite un entier $d$ tel que $cd \equiv 1\,[\varphi(n)]$.
	\item La clé publique de Bob est $(n,c)$, qu'il donne à Alice, et sa clé privée est $(n,d)$, qu'il garde secrète.
	\item Alice envoie à Bob le message $m^c$ mod $n$.
	\item Pour décoder le message, Bob calcule $\left(m^c\right)^d\equiv m\,[n]$.
\end{itemize}
\end{algorithm}

\subsection*{C. Corps finis}
\begin{definition}[\textnormal{[R] 415}]
	La \emph{caractéristique} d'un anneau $A$ est l'unique générateur positif du noyau du morphisme $\varphi\,\colon\IZ\to A$, $n\mapsto n1_A$.
\end{definition}

\begin{lemma}[\textnormal{[R] 415}]
	La caractéristique d'un corps est nulle ou première.
\end{lemma}

\begin{example}
	$\IZpZ$ est un corps de caractéristique $p$.
\end{example}

\begin{theorem}[\textnormal{[R] 421}]
	Il existe un corps fini de cardinal $q$ si, et seulement si, $q$ est une puissance d'un nombre premier. 
	Le cas échéant, un tel corps est unique à isomorphisme près, et on note $\IF_q$ le corps fini à $q$ éléments.
	Par ailleurs, $p = \car \IF_q$ est un nombre premier, et $q$ est une puissance de $p$.
\end{theorem}

\subsection*{D. Le théorème des deux carrés de Fermat}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{lemma}[\textnormal{[P] 75}]
	\label{121dev11}
	$-1$ est un carré dans $\IF_p$ si, et seulement si, $p\equiv 1\,[4]$.
\end{lemma}

\begin{theorem}[des deux carrés de Fermat - \textnormal{[P] 56}]
	\label{121dev12}
	Soit $E = \left\{n\in\IN^* \mid \exists (a,b)\in\IN^2\,\colon n = a^2 + b^2 \right\}$
	Alors, $n\in E \iff \forall p\in\mathcal{P},\, p\equiv 3\,[4] \implies v_p(n)$ est pair.
\end{theorem}
\end{tcolorbox}

\subsection*{E. En théorie des groupes}
\begin{definition}[\textnormal{[R] 22}]
	Un $p$-groupe est un groupe de cardinal une puissance de $p$.
\end{definition}

\begin{proposition}[\textnormal{[R] 22}]
	Si un $p$-groupe $G$ agit sur un ensemble fini $X$, alors $\# X \equiv \#X^G\,[p]$
	où $X^G$ est l'ensemble des éléments de $X$ fixes par l'action de $G$.
\end{proposition}

\begin{corollary}[\textnormal{[R] 23}]
	Le centre d'un $p$-groupe n'est pas trivial.
\end{corollary}

\begin{definition}[\textnormal{[U] 85}]
	Soit $G$ un groupe fini de cardinal $p^{\alpha}m$, $m\wedge p=1$. Un $p$-Sylow de $G$
	est un sous-$p$-groupe de $G$ de cardinal $p^{\alpha}$.
\end{definition}

\begin{theorem}[de Sylow - ADMIS \textnormal{[U] 87}]Soit $G$ un groupe d'ordre $p^{\alpha}m$, $m\wedge p = 1$. Alors,
	\begin{enumerate}
		\item $\Syl_p(G)\neq \empty$
		\item $G$ agit transitivement sur $\Syl_p(G)$ par conjugaison
		\item $n_p\equiv 1\, [p]$
	\end{enumerate}
\end{theorem}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[\textnormal{[R] 292}]
	\label{121dev2}
	Si $p\geq 3$, alors $\forall \alpha \geq 1$, $\left(\IZ/p^{\alpha}\IZ\right)^{\times}$ est cyclique.
\end{theorem}
\end{tcolorbox}

\begin{proposition}[\textnormal{[R] 23}]
	Tout groupe d'ordre $p^2$ est abélien.
\end{proposition}

\section*{Développements}
\begin{itemize}
	\item Développement 1 : Lemme \ref{121dev11}, et théorème \ref{121dev12}
	\item Développement 2 : Théorème \ref{121dev2} (cyclicité des inversibles de $\IZ/p^{\alpha}\IZ$)
\end{itemize}

\section*{Références}
\begin{itemize}
	\item[Rb] \emph{Mathématiques pour l'agrégation - Algèbre et géométrie}, Jean-Étienne Rombaldi, 2e édition
	\item[U] \emph{Théorie des groupes}, Félix Ulmer
	\item[G] \emph{Les maths en tête - Algèbre et probabilités}, Xavier Gourdon, 3e édition
	\item[KG] \emph{De l'intégration aux probabilités}, Olivier Garet, Aline Kurtzmann, 2e édition augmentée
\end{itemize}
\begin{figure}[!htb]
	\centering
	\includegraphics[trim={0 0 0 0},clip,width=1\linewidth]{img/eratosthene.pdf}
	\caption{Crible d'Eratosthène}
\end{figure}



\chapter*{123 : Corps finis. Applications.}
\setcounter{definition}{0}
\section*{I. Des corps finis}
\subsection*{A. Prérequis sur les extensions de corps}

\textcolor{paragraphtext}{Soit $L/M/K$ une tour d'extensions de corps (commutatifs).}

\begin{proposition_def}[\textnormal{[P] 65}]
	$L$ est un $K$-espace vectoriel, sa dimension est appelée \emph{degré de $L/K$}, et est notée $\left[L:K\right]$.
\end{proposition_def}

\begin{theorem}[de la base téléscopique - \textnormal{[P] 65}]
	Soient $\left(e_i\right)_{i\in I}$ une base $K$-base de $M$ et $\left(f_j\right)_{j\in K}$ une $M$-base de $L$,
	alors $\left(e_if_j\right)_{(i,j)\in I\times J}$ est une $K$-base de $L$.
	En particulier, $[L:K] = [L:M]\times [M:K]$ (dans $\IN\cup \left\{+\infty\right\})$.
\end{theorem}

\begin{definition}[\textnormal{[P] 70}]
	Soit $P\in K[X]$ non constant.
	Supposons $P$ irréductible sur $K$. On dit que $L$ est un \emph{corps de rupture} (CDR) de $P$ sur $K$ s'il existe $\alpha\in L$ tel que $P(\alpha) = 0$ et $L=K(\alpha)$.
	
	On dit que $L$ est un \emph{corps de décomposition} (CDD) de $P$ sur $K$ s'il existe $(\alpha_1,\dots,\alpha_n)\in L^n$ tel que $L = K(\alpha_1,\dots,\alpha_n)$ et $P$ est scindé sur $L$.
\end{definition}

\begin{theorem}[\textnormal{[P] 70-71}]
	$P$ admet un unique corps de rupture à $K$-isomorphisme près.
	Plus précisément, $K[X]/\langle P \rangle$ est un corps de rupture de $P$ sur $K$.

	$P$ admet un unique corps de décomposition $D$ à $K$-isomorphisme près. Celui-ci vérifie $[D:K]\leq \deg(P)!$.
\end{theorem}

\subsection*{B. Construction des corps finis : existence et unicité}

\textcolor{paragraphtext}{Dans ce paragraphe $K$ désigne un corps fini commutatif.}

\begin{example}
	Soit $p$ un nombre premier. L'anneau $(\IZpZ, +,\times )$ est un corps fini commutatif. On le note $\IF_p$.
\end{example}

\begin{theorem_def}[\textnormal{[P] 72}]
	Il existe un nombre premier $p$ rendant le diagramme suivant commutatif :
		$$\begin{tikzcd}
			{\mathbb{Z}} && K \\
			& {\mathbb{Z}/p\mathbb{Z}}
			\arrow["{n\mapsto n\cdot 1_K}", from=1-1, to=1-3]
			\arrow[two heads, from=1-1, to=2-2]
			\arrow[hook, from=2-2, to=1-3]
		\end{tikzcd}$$
	L'entier $p$ est appelé \emph{caractéristique} de $K$ notée $\car K$ et $\IF_p$ est appelé \emph{sous-corps premier de $K$}.
	C'est le plus petit sous-corps de $K$.
\end{theorem_def}

\textcolor{paragraphtext}{On notera $p$ la caractéristique de $K$.}

\begin{corollary}[\textnormal{[P] 72}]
	$\#K = p^{\left[K\,\colon \IF_p\right]}$
\end{corollary}
\begin{remark}
	Il n'existe pas de corps fini commutatif à $6$ éléments !
\end{remark}

\begin{lemma_def}[\textnormal{[P] 73}]
	$\textnormal{Fr}\,\colon K\to K$, $x\mapsto x^p$ est un morphisme de corps, appelé \emph{morphisme de Fröbenius}.
\end{lemma_def}

\begin{theorem}[\textnormal{[P] 73}]
	Soient $r\in \IN^*$, $p$ premier et $q=p^r$. Il existe un corps fini commutatif à $q$ éléments.
	Un tel corps est un CDD de $X^q - X$. En particulier, les classes d'isomorphisme de corps finis commutatifs sont caractérisées par le cardinal de ces derniers.
	On note $\IF_q$ un représentant de la classe d'isomorphisme des corps finis commutatifs à $q$ éléments.
\end{theorem}

\begin{theorem}[de Wedderburn - \textnormal{[P] 82}]
	Tout corps fini est commutatif.
\end{theorem}

\begin{example}
	$\IF_4 = \IF_2[X] / \langle X^2+X+1\rangle = \left\{0, 1, \overline{X}, 1 + \overline{X}\right\}$.

	$\IF_9 = \IF_3[X] / \langle X^3 + X^2 + X +1\rangle$.
\end{example}

\subsection*{C. Proprriétés des corps finis}

\textcolor{paragraphtext}{Soient $p$ un nombre premier, $r\in \IN^*$ et $q=p^r$.}

\begin{proposition}[\textcolor{myred}{FIG. 1}]
	$\forall (m,n)\in\left(\IN^*\right)^2$, $\IF_{p^n}\subseteq \IF^{p^m} \iff n\mid m$.
\end{proposition}

\begin{proposition}[\textnormal{[P] e73}]
	\begin{itemize}
		\item $\overline{\IF_p} = \bigcup_{n\in\IN^*}\IF_{p^n}$ est une clôture algébrique de $\IF_p$.
		\item Si $K$ est une extension de $\IF_q$, alors $\IF_q=\left\{x\in K \mid x^q = x\right\}$. En particulier, $\IF_q$ est l'unique sous-corps de $\overline{\IF_p}$ de cardinal $q$.
	\end{itemize}
\end{proposition}

\begin{theorem}[\textnormal{[P] 74}]
	$\IF_q^{\times}$ est cyclique.
\end{theorem}

\begin{proposition}[\textnormal{[P] 73}]
	$\textnormal{Fr}$ est un automorphisme de $\IF_q$.
\end{proposition}

\begin{theorem}[\textnormal{[R] 425}]
	Le groupe des automorphismes de $\IF_q$ est cyclique d'ordre $r$, engendré par $\textnormal{Fr}$.
\end{theorem}

\begin{remark}
	Pour tout $\theta\in\IF_q$, il existe $d\in\IN^*$ tel que $\textnormal{Fr}^d(\theta) = \theta^{dp} = \theta$.
	Le polynôme minimal de $\theta$ sur $\IF_p$ est $\prod_{k=1}^{d}\left(X-\textnormal{Fr}^k(\theta)\right)$.
\end{remark}

\begin{example}
	Soit $\beta = \overline{X}^2 + \overline{X} \in \IF_2[X]/\langle X^4 + X + 1\rangle$. On a $P_{\beta, \IF_2} = X^2 + X + 1$.
\end{example}

\section*{II. Carrés dans un corps fini}

\textcolor{paragraphtext}{
	Soient $p$ un nombre premier \emph{impair}, 
	$r\in\IN^*$ et $q = p^r$. 
	On pose $c\,\colon\IF_q\to\IF_q$, $x\mapsto x^2$ 
	et $l\,\colon \IF_q\to\IF_q$, $x\mapsto x^{\frac{q-1}{2}}$.}

\begin{proposition}
	$\im l = \Ker c = \left\{\pm 1\right\}$ et $\Ker l = \im c = \left\{x^2\mid x\in \IF_q^{\times}\right\}$.
\end{proposition}

\begin{corollary}[Critère d'Euler - \textnormal{[P] 75}]
	$x\in\IF_q^{\times}$ est un carré si, et seulement si $x^{\frac{q+1}{2}}=1$.
\end{corollary}

\begin{corollary}[\textnormal{[P] 74}]
	Il y a $\frac{q-1}{2}$ carrés inversibles dans $\IF_q$ (et $\frac{q+1}{2}$ carrés).
\end{corollary}

\begin{proposition}[\textnormal{[P] 74}]
	Tous les éléments de $\IF_{2^r}$ sont des carrés.
\end{proposition}

\begin{proposition}[\textnormal{[P] 75}]
	$-1$ est un carré dans $\IF_p$ si, et seulement si, $p\equiv 1\,[4]$.
\end{proposition}

\begin{application}[\textnormal{[P] 56}]
$p$ est la somme de deux carrés si, et seulement si, $p=2$ ou $p\equiv 1\,[4]$.
\end{application}

\begin{definition}[\textnormal{[R] 428}]
	Le \emph{symbole de Legendre de $a\in\IZ$ modulo $p$} est défini par :
	\begin{align*}
		\left(\frac{a}{b}\right) = \begin{cases}
			0\quad \text{si } a\in p\IZ \\
			1\quad \text{si $a$ est un carré inversible modulo $p$} \\
			-1\quad \text{sinon}
		\end{cases}
	\end{align*}
\end{definition}

\begin{proposition}[\textnormal{[R] 428}]
	$\forall a\in\IZ$, $\left(\frac{a}{p}\right)\equiv a^{\frac{p-1}{2}}$.
	En particulier, $\left(\frac{\cdot}{p}\right)$ est un morphisme du groupe $\IF_p^{\times}$.
\end{proposition}



\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{proposition}[\textnormal{[R] 431-434}]
	\label{123dev11}
	Soit $a\in\IF_p^{\times}$. L'équation de $ax^2 = 1$ a $1+\left(\frac{a}{p}\right)$ solutions dans $\IF^p$.
\end{proposition}
\begin{theorem}[Loi de réciprocité quadratique - \textnormal{[R] 431-434}]
	\label{123dev12}
	Soient $p$ et $q$ deux nombres premiers impairs distincts.

	\begin{align*}
		\left(\frac{p}{q}\right)\left(\frac{q}{p}\right) = \left(-1\right)^{\frac{p-1}{2}\frac{q-1}{2}}
	\end{align*}
\end{theorem}
\end{tcolorbox}

\begin{application}
	$\left(\frac{11}{23}\right) = \left(\frac{23}{11}\right)\left(-1\right)^{11\cdot 5} = -\left(\frac{1}{11}\right) = -1$ donc $11$ n'est pas un carré modulo $23$.
\end{application}

\begin{proposition}[\textnormal{[R] e438, [C] 307}]
	$\left(\frac{2}{p}\right) = \left(-1\right)^{\frac{p^2 - 1}{8}}$
\end{proposition}

\begin{proposition}
	Soit $(a,b,c)\in\IF_q^3$ avec $a \neq 0$. L'équation $ax^2 + bx + C = 0$ dans $\IF_q$ 
	possède des solutions si, et seulement si, $b^2-4ac$ est un carré dans $\IF_q$. Le cas échéant, si $\delta\in/IF_p$ vérifie $\delta^2 = b^2-4ac$, alors 
	les solutions de cette équation sont $\frac{-b\pm \delta}{2a}$.
\end{proposition}

\begin{remark}
	Dans $\IF_{2r}$, l'équation $ax^2+bx+c=0$ est bien plus difficile à résoudre, en dehors des cas triviaux !
\end{remark}

\section*{III. Algèbre (bi)linéaire sur les corps finis}

\textcolor{paragraphtext}{Soient $p$ un nombre premier impair, $r\in\IN^*$, $q = p^r$ et $n\in\IN$.}

\begin{proposition}[\textnormal{[R] 155}]
	\begin{itemize}
		\item $\# GL_n(\IF_q) = (q^n-1)(q_n - q)\dots (q^n-q^{n-1}) = q^{\frac{n(n-1)}{2}}\prod_{k=1}^{n}(q^k-1)$
		\item $\# SL_n(\IF_q) = \#GL_n(\IF_q)/(q-1)$
	\end{itemize}
\end{proposition}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[\textnormal{[C] 50}]
	\label{123dev2}
	\begin{align*}
		SO_2(\IF_q)\cong \begin{cases}
			\IZ/(q-1)\IZ\quad\text{si $-1$ est un carré mod $q$} \\
			\IZ/(q+1)\IZ\quad\text{sinon}
		\end{cases}
	\end{align*}
\end{theorem}
\end{tcolorbox}

\begin{remark}
	$SO_2(\IF_{2^r}) = \begin{pmatrix}
		0 & 1 \\
		1 & 0
	\end{pmatrix} + \IF_{2^r}\begin{pmatrix}
		1 & 1 \\ 1 & 1
	\end{pmatrix}$, puis $SO_2(\IF_{2^r})\cong \left(\IZ/2\IZ\right)^r$.
\end{remark}

\textcolor{paragraphtext}{Soit $E$ un $\IF_q$-espace vectoriel de dimension finie.}

\begin{definition}[\textnormal{[R] 463}]
	Le \emph{discriminant} d'une forme quadratique $f$ sur $E$ est l'image de son déterminant dans une base quelconque modulo les carrés de $\IF_q^{\times}$.
\end{definition}

\begin{theorem}[\textnormal{[R] e482}]
	Il y a deux classes d'équivalence de formes quadratiques non-dégénérées sur $E$.
	Plus précisément, soient $\alpha\in\IF_q^{\times}$ qui n'est pas un carré, et $f$ une forme 
	quadratique sur, de matrice $M$ dans la base canonique.

	\begin{itemize}
		\item Si $\det M$ est un carré dans $\IF_p^{\times}$, alors $M$ est congruente à la matrice $\diag(1,1,\dots, 1,1)$.
		\item Sinon, $M$ est congruente à $\diag(1,1,\dots, 1, \alpha)$.
	\end{itemize}
\end{theorem}

\begin{application}
	Loi de réciprocité quadratique (Thm \ref{123dev12}).
\end{application}

\section*{IV. Polynômes et corps finis}

\begin{theorem}[Critère d'Eisenstein - \textnormal{[P] 76}]
	Soit $P = \sum_{k=0}^{n} a_kX^k\in\IZ[X]$.
	Soit $p$ un nombre premier. Si $p\nmid a_n$, si $\forall k\in \llbracket 0, n-1\rrbracket$, $p\mid a_k$ et $p^2\nmid a_0$, alors $P$ est irréductible dans $\IQ[X]$.
\end{theorem}

\begin{example}
	Pour tout $p$ premier, $\Phi_p = X^{p+1} + \dots + X + 1$ est irréductible sur $\IQ$.
\end{example}

\begin{theorem}[\textnormal{[P] 77}]
	Soit $P = \sum_{k=0}^{n} a_kX^k\in\IZ[X]$, $n\geq 1$, $a_n\neq 0$.
	Soit $p\in\IZ$ premier. Si $p\nmid a_n$ et si l'image $\overline{P}$ de $P$ 
	dans $\IF_p[X]$ est irréductible, alors $P$ est irréductible sur $\IZ$.
\end{theorem}

\begin{remark}
	La réciproque est fausse : considérer $X^4 + 1$.
\end{remark}

\section*{Développements}
\begin{itemize}
	\item Développement 1 : Proposition \ref{123dev11}, et théorème \ref{123dev12} : loi de réciprocité quadratique (par les formes quadratiques)
	\item Développement 2 : Théorème \ref{123dev2}
\end{itemize}

\section*{Références}
\begin{itemize}
	\item[R] \emph{Mathématiques pour l'agrégation - Algèbre et géométrie}, Jean-Étienne Rombaldi, 2e édition
	\item[P] \emph{Cours d'algèbre}, Perrin
	\item[C] \emph{Nouvelles histoires hédonistes de groupes et géométries}, P. Caldero, J. Germoni
\end{itemize}

\begin{figure}[!htb]
	\centering
	\includegraphics[trim={0 0 0 0},clip,width=1\linewidth]{img/diagramme_extensions_corps_finis.pdf}
	\caption{Diagramme des extensions de corps finis}
\end{figure}


\chapter*{141 : Polynômes irréductibles à une indéterminée. Corps de rupture. Exemples et applications.}
\setcounter{definition}{0}
\textcolor{paragraphtext}{Soient $A$ un anneau unitaire intègre commutatif, et $L/K$ une extension de corps commutatif. Soit $P\in A[X]$.}

\section*{I. Polynômes irréductibles}
\subsection*{A. Notion d'irréductibilité pour les polynômes}

\begin{definition}[\textnormal{[R] 370}]
		On dit que $P$ est \emph{irréductible sur $A$} si $P\notin A[X]^{\times} = A^{\times}$, si $P\neq 0$ et si :
		$\forall(P_1,P_2)\in A[X]^2$, $P = P_1P_2 \implies P_1\in A^{\times}$ ou $P_2\in A^{\times}$.
\end{definition}

\begin{example}[\textnormal{[R] 370}]
	Tout polynôme de degré $1$ est irréductible ; et les polynômes réels de degré $2$ de discriminant $< 0$ sont irréductibles.
\end{example}

\begin{proposition}[\textnormal{[R] 371}]
	\begin{itemize}
		\item Si $P\in K[X]$ est irréductible et si $\deg P > 1$ , alors $P$ n'a pas de racine dans $K$.
		\item Si $P\in K[X]$ n'a pas de racine dans $K$ et si $\deg P \leq 3$, alors $P$ est irréductible sur $K$.
	\end{itemize}
\end{proposition}

\begin{example}
	\begin{itemize}
		\item $(x^2+1)^2$ est réductible sur $\IR$ et sans racine dans $\IR$.
		\item Les polynômes irréductibles de petit degré de $\IF_2[X]$ sont $X$, $X+1$, $X^2+X+1$.
	\end{itemize}
\end{example}

\subsection*{B. Proprétés de $A[X]$}
\begin{proposition}[\textnormal{[R] 374}]
	$A[X]$ euclidien $\iff A[X]$ principal $\iff A$ est un corps.
\end{proposition}

\begin{proposition}[\textnormal{[R] e375}]
	Si $P\in K[X]$ est irréductible, alors $K[X]/\langle P\rangle$ est un corps.
\end{proposition}

\textcolor{paragraphtext}{On suppose $A$ factoriel.}

\begin{definition}[\textnormal{[S] 547-548; [P] 51}]
	Le \emph{contenu de $P\in A[X]\setminus \left\{0\right\}$}, noté $c(P)$, est un PGCD des coefficients de $P$.
	On dit que $P$ est \emph{primitif} si $c(P)\in A^{\times}$.
\end{definition}

\begin{theorem}[\textnormal{[P] 51; [S] 548}]
	Soit $P\in A[X]$ primitif non constant. $P$ est irréductible dans $A[X] \iff A$ est irréductible dans $K[X]$.
\end{theorem}

\begin{example}
	Soient $a_1,\dots,a_n$ des entiers distincts. Le polynôme $(X-a_1)\dots (X-a_n) - 1$ est irréductible sur $\IQ$.
\end{example}

\begin{lemma}
	Un produit de polynômes primitifs est primitif.
\end{lemma}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{lemma}[de Gauss - \textnormal{[S] 548; [P] 51}]
\label{141dev1a}
	$c(PQ) = c(P)c(Q)$
\end{lemma}
\end{tcolorbox}

\begin{theorem}[\textnormal{[R] 358; [S] 548; [P] 51}]
	$A[X]$ est factoriel $\iff A$ est factoriel.
\end{theorem}

\subsection*{C. Critères d'irréductibilité}

\begin{theorem}[Critère d'Eisenstein - \textnormal{[S] 549; [P] 76}]
	Ecrivons $P=\sum_{k=0}^{n} a_kX^k$, $a_n \neq 0$.
	S'il existe $p\in A$ premier non nul tel que $\forall k\in \llbracket 1,n-1\rrbracket$, $p\mid a_k$, $p^2 \nmid a_0$ et $p\nmid a_n$, alors $P$ est irrductible dans $\Frac(A)[X]$.
\end{theorem}

\begin{example}
	$\forall n\geq 2$, $\forall d\in\IN^*$ sans facteur carré, $X^n - d$ est irréductible dans $\IZ[X]$.
\end{example}

\begin{theorem}[\textnormal{[P] 77}]
	Soit $I$ un idéal de $A$. Ecrivons $P = \sum_{k=0}^{n} a_kX_k$, $a_n\neq 0$.
	Si $a_n \not\equiv 0$ mod $I$ et si $P$ mod $I$ est irréductible dans $\left(A/I\right)[X]$ alors
	$P$ est irréductible dans $A[X]$.
\end{theorem}

\begin{example}[\textnormal{[P] 77}]
	Pour tout $p$ premier, $X^p-X-1$ est irréductible sur $\IQ$.
\end{example}

\section*{II. Polynômes et extensions de corps}
\textcolor{paragraphtext}{Soient $L$ et $K$ deux corps commutatifs. Soit $P\in K[X]$.}

\subsection*{A. Extensions de corps, éléments algébriques}
\begin{definition}[\textnormal{[P] 65}]
	On dit que $L$ est \emph{une extension de $K$}, et on note $L/K$, si $K\subseteq L$.
\end{definition}

\begin{proposition_def}[\textnormal{[P] 65}]
	$L$ est un $K$-espace vectoriel dont on note $[L:K]$ la dimension, que l'on appelle \emph{degré de l'extension $L/K$}.
	On dit que $L/K$ est finie si $[L:K]$ est fini.
\end{proposition_def}

\begin{theorem}[de la base téléscopique - \textnormal{[P] 65}]
	Soient $\left(e_i\right)_{i\in I}$ une base $K$-base de $M$ et $\left(f_j\right)_{j\in K}$ une $M$-base de $L$,
	alors $\left(e_if_j\right)_{(i,j)\in I\times J}$ est une $K$-base de $L$.
\end{theorem}

\begin{corollary}[Multiplicativité des degrés - \textnormal{[P] 65}]
	$[L:K] = [L:M]\times [M:K]$
\end{corollary}

\begin{definition}[\textnormal{[P] 66}]
	On dit que $\alpha\in L$ est \emph{algébrique sur $K$} s'il existe $P\in K[X]$ tel que $P(\alpha)=0$.
	Sinon, on dit que $\alpha$ est \emph{transcendant}.
\end{definition}

\begin{theorem_def}[\textnormal{[P] 66}]
	Si $\alpha\in L$ est algébrique sur $K$, alors $\left\{P\in K[X]\mid P(\alpha) = 0\right\}$
	est un idéal non nul, qui donc admet un unique générateur unitaire $P_{\alpha, K}$ appelé \emph{polynôme minimal de $\alpha$ sur $K$}.
\end{theorem_def}

\begin{notation*}
	$K[\alpha] = \left\{P(\alpha)\mid P\in K[X]\right\}$
\end{notation*}

\begin{theorem}[\textnormal{[P] 66}]
	Soit $\alpha\in L$. Sont équivalentes :
	\begin{enumerate}
		\item $\alpha$ est algébrique sur $K$
		\item $K[\alpha] = K(\alpha)$
		\item $K[\alpha]$ est un $K$-espace vectoriel de dimension finie.
	\end{enumerate}

	Le cas échéant, $\deg P_{\alpha, L} = [K(\alpha) : K]$.
\end{theorem}

\subsection*{B. Corps de rupture et de décomposition}

\begin{definition}[\textnormal{[P] 70}]
	Supposons $P$ irréductible. On dit que $L$ est un \emph{corps de rupture de $P$ sur $K$} s'il existe $\alpha\in L$ tel que $P(\alpha) = 0$ et $L=K(\alpha)$.
\end{definition}

\begin{theorem}[\textnormal{[P] 70}]
	Supposons $P$ irréductible. Le corps $K[X]/\langle P\rangle$ est un corps de rupture de $P$ sur $K$, et c'est le seul à isomorphisme près.
\end{theorem}

\begin{example}
	$\IC$ peut être défini comme $\IR[X]/\langle X^2 + 1 \rangle$.
\end{example}

\begin{application}
	Si $P$ est irréductible et si $\deg P \wedge [L:K]$, alors $P$ est irréductible sur $L$.
\end{application}

\begin{definition}[\textnormal{[P] 71}]
	On dit que $L$ est un \emph{corps de décomposition de $P$ sur $K$} si $P$ est sciendé sur $L$ et si $L = K(\alpha_1,\dots,\alpha_n)$ avec $\alpha_1,\dots,\alpha_n$ les racines de $P$.
\end{definition}

\begin{theorem}[\textnormal{[P] 71}]
	Il existe un corps de décomposition de $P$ sur $K$, unique à isomorphisme près.
\end{theorem}

\begin{example}[\textnormal{[P] 72}]
	$\IQ(j,\sqrt[3]{}2)$ est un corps de décomposition de $X^3 - 2$ sur $\IQ$.
\end{example}

\begin{theorem}[de l'élément primitif - \textnormal{[P] 87}]
	Toute extension finie d'un corps de caractéristique nulle est monogène.
\end{theorem}

\subsection*{C. Clôture algébrique}
\begin{definition}[\textnormal{[P] 67}]
	On dit que $K$ est \emph{algébriquement clos} si tout polynôme non nul de $K[X]$ est scindé, et si $K$ n'admet pas d'extension algébrique non triviale.
\end{definition}

\begin{definition}[\textnormal{[P] 72}]
	On dit que $L$ est une \emph{clôture algébrique} de $K$ si c'est une extension de $K$ algébrique et algébriquement close.
\end{definition}

\begin{example}[\textnormal{[P] 68-72}]
	\begin{itemize}
		\item $\IC$ est algébriquement clos (théorème de d'Alembert-Gauss) ;
		\item $\IC$ est une clôture algébrique de $\IR$.
	\end{itemize}
\end{example}

\begin{example}[\textnormal{[G] 94}]
	Si $L$ est algébriquement clos, alors l'ensemble des éléments de $L$ algébriques sur $K$ est un corps algébriquement clos.
\end{example}

\begin{theorem}
	$K$ admet une unique clôture algébrique à isomorphisme près.
\end{theorem}

\section*{III. Polynôme cyclotomiques}
\textcolor{paragraphtext}{On note $\IU := \left\{z\in \IC\mid z^n = 1\right\}$ le groupe des racines complexes $n$-ièmes de l'unité,
et $\mu_n^*$ l'ensemble de ses générateurs (que l'on appelle \emph{racines primitives $n$-ièmes de l'unité}).}

\begin{definition}[\textnormal{[P] 80; [R] 385}]
	Pour $n\in\IN^*$, on définit le \emph{$n$-ième polynôme cyclotomique} :
	$$\Phi_n = \prod_{\zeta\in \mu_n^*} X-\zeta$$
\end{definition}

\begin{proposition}[\textnormal{[P] 80-83; [R] 386}]
	On a les propriétés suivantes :
	\begin{itemize}
		\item Pour $\zeta_n\in\mu_n^*$, $$\Phi_n = \prod_{\substack{k=1 \\ k\wedge n = 1}}^{n} X - \zeta_n^k$$
		\item $X^n - 1 = \prod_{d\mid n} \Phi_d$
		\item $\Phi_n\in\IZ[X]$
	\end{itemize}
\end{proposition}

\begin{example}[\textnormal{[P] 81}]
		\begin{itemize}
			\item Pour $p$ premier, $\Phi_p = X^{p-1}+\dots X + 1$
			\item $\Phi_1 = X - 1$, $\Phi_4 = X^2 + 1$, $\Phi_6 =X^2 - X + 1$, $\Phi_8 = X^4 + 1$
		\end{itemize}
\end{example}


\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[\textnormal{[P] 82-83; [R] 392}]
	\label{141dev1b1}
	Soit $\zeta_n\in\mu_n^*$. Le polynôme minimal de $\zeta_n$ sur $\IQ$ est $\Phi_n$.
\end{theorem}

\begin{corollary}
	\label{141dev1b2}
	$\Phi_n$ est irréductible sur $\IQ$ et $[\IQ(\zeta) : \IQ] = \varphi(n)$.
\end{corollary}
\end{tcolorbox}

\section*{IV. Polynômes irréductibles des corps finis}

\begin{definition}[\textnormal{[R] 331}]
	La \emph{fonction de Moëbius} est définie par :
	\begin{align*}
		\mu\,\colon n\in\IN^* \mapsto \begin{cases}
			1\quad \text{si } n =1 \\
			(-1)^r\quad \text{si n est le produit de $r$ facteurs premiers distincts} \\
			0\quad\text{sinon}
		\end{cases}
	\end{align*}
\end{definition}


\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[Formule d'inversion de Moëbius = \textnormal{[R] 333}]
	\label{141dev21}
	Soient $\left(u_n\right)_{n\in\IN^*}\in\IR^{\IN^*}$ et $\left(v_n\right)_{n\in\IN^*}\in\IR^{\IN^*}$.
	Si $\forall n\in\IN^*$, $u_n = \sum_{d\mid n} v_d$, alors $\forall n\in\IN^*$, $v_n = \sum_{d\mid n}\mu(\frac{n}{d})u_d$.
\end{theorem}
\begin{theorem}[\textnormal{[R] 423}]
	\label{141dev22}
	$P_n := X^{p^n}-X =\prod_{d\mid n}\prod_{\mathcal{U}_d(p)} P$ où $\mathcal{U}_d(p)$ est l'ensemble des 
	polynômes irréductibles unitaires de degré $d$ de $\IF_p[X]$.
\end{theorem}
\begin{corollary}[\textnormal{[R] 424}]
	\label{141dev23}
	$\#\mathcal{U}_n(p) = \frac{1}{n}\sum_{d\mid n}\mu(\frac{n}{d})p^d$
\end{corollary}
\end{tcolorbox}

\section*{Développements}
\begin{itemize}
	\item Développement 1 : Lemme de Gauss \ref{141dev1a}
	\item Développement 2 : Théorème \ref{141dev1b1} et Corollaire \ref{141dev1b2}
	\item Développement 2 : Théorème \ref{141dev21}, Théorème \ref{141dev22} et Corollaire \ref{141dev23}
\end{itemize}

\section*{Références}
\begin{itemize}
	\item[R] \emph{Mathématiques pour l'agrégation - Algèbre et géométrie}, Jean-Étienne Rombaldi, 2e édition
	\item[P] \emph{Cours d'algèbre}, Perrin
	\item[G] \emph{Les maths en tête - Algèbre et probabilités}, Xavier Gourdon, 3e édition
	\item[S] \emph{Algèbre pour la licence 3}, Szpirglas
\end{itemize}

\chapter*{142 : PGCD et PPCM, algorithmes de calcul. Applications.}
\setcounter{definition}{0}
\section*{I. Notion de PGCD et de PPCM dans différents types d'anneaux}
\textcolor{paragraphtext}{Dans cette section, $A$ est un anneau intègre (commutatif) et $(a,b,a_1,\dots,a_r)\in A^{r+2}$.}

\subsection*{A. Première définition, existence, cas des anneaux factoriels}

\begin{definition}
	Si $a_1,\dots,a_r \neq 0$, alors sous réserve d'existence, on appelle \emph{PGCD} (resp. \emph{PPCM})
	de $a_1,\dots, a_r$, noté $a_1\wedge \dots\wedge a_R$ ou $\pgcd(a_1,\dots,a_r)$ (resp. $a_1\vee\dots\vee a_r$ ou $\ppcm(a_1,\dots,a_r)$)
	un plus grand minorant (resp. un plus grand majorant) de $\left\{a_1,\dots, a_r\right\}$ pour la relation (binaire) de divisibilité.
	On pose par ailleurs $0\wedge 0 = 0\vee a = 0$.

	En particulier, le PGCD et le PPCM sont associatifs et commutatifs: $a\wedge b = b\wedge a$ et $a_1\wedge a_2 \wedge a_3\wedge a_4\wedge a_5 = (a_1\wedge a_2)\wedge(a_3\wedge a_4)\wedge a_6$.
\end{definition}

\begin{remark}
	Les PGCD (resp. PPCM) de $a_1,\dots, a_r$ sont tous associés. L'écriture $d = a_1\wedge\dots\wedge a_r$ est un abus signifiant que $d$ est \underline{un} PGCD de $a_1,\dots,a_r$.
\end{remark}

\begin{proposition}[\textnormal{[R] 246}]
	Si $a$ et $b$ ont un PPCM alors ils ont un PGCD $a\wedge b = ab(a\vee b)^{-1}$.
\end{proposition}

\begin{example}
	$3$ et $2+i\sqrt{5}$ ont un PGCD mais pas de PPCM dans $\IZ[i\sqrt{5}]$.
	$4$ et $2+2i\sqrt{3}$ n'ont pas de PGCD dans $\IZ[i\sqrt{3}]$.
\end{example}

\begin{definition}
	On dit que $a_1,\dots, a_r$ sont \emph{premiers entre eux} (dans leur ensemble)
	si $a_1\wedge \dots\wedge a_r = 1$. On dit que $a_1, \dots, a_r$ sont \emph{deux à deux premiers entre eux} 
	si $\forall(i,j)\in \llbracket 1,n\rrbracket^2$, $i\neq j\implies a_i\wedge a_j = 1$.
\end{definition}

\begin{theorem}[de Gauss - \textnormal{[R] 247}]
	$\forall (a,b,c)\in A^3$, $a\mid bc$ et $a\wedge b=1 \implies a\mid c$. 
\end{theorem}

\begin{proposition}[\textnormal{[R] 246}]
	Si toute paire d'éléments de $A$ admet un PGCD (on dit alors que $A$ est un anneau à PGCD),
	alors toute paire d'éléments de $A$ admet un PPCM, et la réciproque est vraie.
\end{proposition}

\begin{proposition}[\textnormal{[P] 49}]
	Supposons $A$ factoriel, notons $\mathcal{P}$ un système
	complet de représentants des irréductibles de $A$. Alors :
	\begin{align*}
		\prod_{p\in\mathcal{P}} p^{\min(v_p(a), v_p(b))}\text{ est un PGCD de $a$ et $b$.}
	\end{align*}
	\begin{align*}
		\prod_{p\in\mathcal{P}} p^{\max(v_p(a), v_p(b))}\text{ est un PPCM de $a$ et $b$.}
	\end{align*}
\end{proposition}

\begin{definition}
	Si $A = \IZ$ (resp. $A=K[X]$, $K$ un corps), alors
	le PGCD de $a$ et $b$ est l'unique $PGCD$ de $a$ et $b$ qui est positif (resp. unitaire).
\end{definition}

\subsection*{B. Situation dans les anneaux principaux}
\textcolor{paragraphtext}{On suppose $A$ principal.}

\begin{proposition}
	$m\in A$ est un PPCM de $a$ et $b$ si, et seulement si, $aA\cap bA = mA$.

	$d\in A$ est un PGCD de $a$ et $b$ si, et seulement si, $aA + bA = dA$.
\end{proposition}

\begin{theorem}[de Bézout]
	$\left(\exists(u,v)\in A^2\, au+bv = 1\right)\iff a\wedge b = 1$
\end{theorem}

\begin{remark}
	$\forall(a,b)\in A^2,\, \exists(u,v)\in A^2\, \colon au+bv = 1$. Le théorème de Bézout
	indique que la réciproque est vraie si $a\wedge b = 1$ (contre-exemple : $3\times (2) + 2 \times (-2) = 2$, mais $3\wedge 2 \neq 2$).
\end{remark}

\begin{definition}[\textnormal{[R] 247}]
	Un couple $(u,v)\in A^2$ tel que $a\wedge b = au+bv$ est appelé \emph{couple de Bézout de $(a,b)$}, et l'égalité est appelée \emph{relation de Bézout}.
\end{definition}

\begin{application}
	Résolution de $ax + by=c$ avec $a\wedge b = 1$.
\end{application}

\begin{application}
	Lemme des noyaux : soit $(P,Q)\in K[X]^2$ tel que $P\wedge Q = 1$.
	Soient $V$ un $K$-espace vectoriel de dimension finie. Pour tout endomorphisme $f$ de $V$;
	$\Ker\left(\left(PQ\right)\left(f\right)\right) = \Ker\left(P(f)\right)\bigoplus\Ker\left(Q(f)\right)$.
\end{application}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[des restes chinois - \textnormal{[R] 250}]
	\label{142dev11}
	Si $a_1,\dots, a_d$ sont non nuls, non inversibles et deux à deux premiers entre eux, alors :
	\begin{align*}
		\overline{\varphi}\,\colon x\,mod\,a_1\dots a_d &\mapsto (x\,mod\,a_1,\dots, x\, mod\, a_d)
	\end{align*}
	est un isomorphisme d'anneaux de $A/\langle a_1\dots a_r\rangle$ dans $A/\langle a_1\rangle \times \dots A/\langle a_r\rangle$.
	
	Posons $a = a_1\dots a_r$ et pour $j\in \llbracket 1,r\rrbracket$, $b_j = \frac{a}{a_j}$.
	Il existe $(u_1,\dots, u_r)\in A^r$ tel que $\sum_{i=1}^{r} u_ib_i = 1$.
	La réciproque de $\overline{\varphi}$ s'exprime alors :
	\begin{align*}
		\overline{\varphi}^{-1}\,\colon (x_1\,mod\,a_1,\dots, x_d\, mod\, a_d) \mapsto \sum_{i=1}^{d} x_i a_i b_i\, mod\, a_1\dots a_d
	\end{align*}
\end{theorem}
\end{tcolorbox}

\begin{application}[\textnormal{[R] 291}]
	Résolution d'un système de congruence.
\end{application}

\begin{example}[Interpolation de Lagrange]
	Soient $x_1,\dots, x_n\in K$ deux à deux distincts et $y_1,\dots,y_n\in K^n$.
	Un polynôme interpolateur des $x_i$ en $y_i$ est une solution du système : 
	$$\{ \forall i\in\llbracket 1, n\rrbracket,\, P\equiv y_i\,[X-x_i]$$
\end{example}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{example}
	\label{142dev12}
	Recherche de $P\in \left(\IZ/5\IZ\right)[X]$ tel que 
	$P(\overline{0}) = \overline{2}$, $P(\overline{1}) = \overline{0}$, $P(\overline{2}) = \overline{1}$
	de degré minimal.
\end{example}
\end{tcolorbox}

\begin{proposition}[\textnormal{[R] 298}]
	$\forall (n,m)\in \IN^2_{\geq 2}$, $\IZnZ \times \IZ/m\IZ \cong \IZ/n\wedge m\IZ \times \IZ/ n\vee \IZ$
\end{proposition}

\section*{II. Algorithmes de calcul dans un anneau eculidien}
\textcolor{paragraphtext}{Dans cette section, $A$ est supposé euclidien.
Soit $(a,b)\in A\times A\setminus\left\{0\right\}$}.

\subsection*{A. Algorithmes d'Euclide}

\begin{lemma}[d'Euclide - \textnormal{[R] 264}]
	Si $a=bq+r$ avec $(q,r)\in A^2$, alors $a\wedge b = b\wedge r$.
\end{lemma}

\begin{algorithm}[d'Euclide - \textnormal{[R] 264}]
	Posons $r_{-1} = a$ et $r_0 = b$, et pour $n\geq 1$, $r_n$ est un 
	reste d'une division euclidienne de $r_{n-2}$ par $r_{n-1}$ si $r_{n-1} \neq 0$, et $r_n = 0$ sinon.

	Il existe $N\in \IN$ tel que $\forall n\geq N+1$, $r_n = 0$ ; de plus, $a\wedge b = r_n$.
\end{algorithm}

\begin{example}
	$M_n\wedge M_m = M_{n\wedge m}$, où $(n,m)\in \IN^2$ et $M_n = 2^n -1$.

	$(X^n-1)\wedge (X^m - 1) = X^{n\wedge m} - 1$.
\end{example}

\begin{algorithm}[d'Euclide étendu - \textnormal{[R] 265}]
	Soit $\left(q_n\right)_{n\geq 1}$ une quite de quotients dans l'algorithme d'Euclide,
	soit $N$ le rang du dernier reste non nul. On peut
	trouver un couple de Bézout en "remontant" l'algorithm d'Euclide, \emph{i.e.} en 
	écrivant $a\wedge b = r_N = r_{N-2} - q_Nr_{N-1}$, puis en y substituant $r_{N-1} = r_{N-3} - q_{N-1}r_{N-2}$,
	puis en y substituant $r_{N-2} = r_{N-4} - q_{N-2}r_{N-3}$, etc. jusqu'à exprimer $a\wedge b$ sous 
	la forme $a\wedge b = a f(q_1,\dots, q_N) + b g(q_1,\dots, q_n)$.
\end{algorithm}

\begin{application}
	Calcul d'un inverse dans un corps de rupture : soit $K = \IQ[X] / \langle X^2 -X-1\rangle \cong \IQ(\varphi)$.
	Dans $K,\, (2\varphi + 1)^{-1} = 2\varphi - 3$.
\end{application}

\begin{proposition}
	$Gl_2(\IZ)$ agit sur $\IZ^2$ par $\begin{pmatrix}
		\alpha & \beta \\ \gamma & \delta
	\end{pmatrix}\cdot \begin{pmatrix}
		a \\ b
	\end{pmatrix} = \begin{pmatrix}
		\alpha & \beta \\ \gamma & \delta
	\end{pmatrix}\begin{pmatrix}
		a \\ b
	\end{pmatrix} = \begin{pmatrix}
		\alpha a + \beta b \\ \gamma a + \delta b
	\end{pmatrix}$

	Les orbites de cette action sont les $E_d = \left\{\begin{pmatrix}
	a \\ b
	\end{pmatrix}\in \IZ^2 \mid a\wedge b = d\right\}$, $d\in \IN$.
\end{proposition}

\begin{corollary}
	D'après l'algorithme d'Euclide, $\forall (a,b)\in\IZ^2,\, \exists P\in GL_2(\IZ)\,\colon P\begin{pmatrix}
		a \\ b
	\end{pmatrix} = \begin{pmatrix}
		a\wedge b\\ 0
	\end{pmatrix}$
\end{corollary}

\begin{application}
	Soit $a = (a_1,\dots, a_n)$ un vecteur de $\IZ^n$. 
	On peut compléter $(a)$ en une $\IZ$-base de $\IZ^n$ si, et seulement si, 
	$a_1\wedge \dots \wedge a_n = 1$.
\end{application}

\subsection*{B. Du côté de $\IZ$ et $K[X]$, un point sur la complexité}

\textcolor{paragraphtext}{Dans le cas de la division euclidienne dans $\IZ$, on impose aux 
restes d'être positifs, ce qui rend les reste et quotient uniques.}

\begin{theorem}[de \textsc{Lamé} - \textnormal{[D] 38}]
	Supposons que $a>b\geq 1$.
	Soient $\left(F_k\right)_k$ la suite de \textsc{Fibonacci} débutant à 0, et $k\in \IN$ tel 
	que $b< F_{k+1}$. L'algorithme d'\textsc{Euclide} pour $a$ et $b$ termine en moins de $k$ étapes.
\end{theorem}

\begin{remark}
	Cette majoration est optimale : considérer $a = F_{k+1}$, $b = F_k$.
\end{remark}

\begin{algorithm}[PGCD binaire - \textnormal{[D] 36}]
	\label{142algPGCDbinaire}
	Supposons $a \geq b\geq 0$. La fonction suivante : 
	
	\emph{PGCD\_binaire(a,b):} \\
	\indent\indent\emph{Si $a=0$: renvoyer b} \\
	\indent\indent\emph{Si $2\mid a$ et $2\mid b$: renvoyer $2\times $PGCD\_binaire($a/2, b/2$)} \\
	\indent\indent\emph{Si $2\mid a$ et non$(2\mid b)$: renvoyer PGCD\_binaire($a/2, b$)} \\
	\indent\indent\emph{Si non$(2\mid a)$ et $2\mid b$: renvoyer PGCD\_binaire($a, b/2$)} \\
	\indent\indent\emph{Sinon : renvoyer PGCD\_binaire($(a-b)/2, b$)}
	
	appliquée à $(a,b)$ renvoie $a\wedge b$.
\end{algorithm}

\begin{remark}
	Algorithme \ref{142algPGCDbinaire} se termine en au plus $\lceil \textnormal{log}_2(a)\rceil$ récursions.
\end{remark}

\begin{proposition}
	Soit $(P,Q)\in K[X]^2$ tel que $n:= \deg P\geq \deg Q \geq 1$.
	L'algorithme d'\textsc{Euclide} appliqué à $P$ et $Q$ termine en au plus $n$ étapes.
\end{proposition}

\section*{III. Applications en arithmétique et en théorie des groupes}
\subsection*{A. (Systèmes d') équations diophantiennes linéaires}

\begin{definition}[\textnormal{[G] 163}]
	Soit $M\in \M_{n,m}(IZ)$. On dit que $M$ est sous \emph{forme normale d'\textsc{Hermite}}
	si elle est sous la forme :

	$$\left(\begin{smallmatrix}
			0 & \cdots & 0 & p_1 & * & \cdots & * & + & * & \cdots & * & + & & & & & & \\
			& & & & & & & p_2 & * & \cdots & * & + & & & & & & \\
			& & & & & & & & & & & p_3 & \cdots & & & & & \\
			& & & & & & & & & \vdots & & & & & & & & \\
			& & & & & & & & & & & & & \cdots & + & * & \cdots & * \\
			& & & & & & & & & & & & & & p_r & * & \cdots & * \\
			& & & & & & & & & & & & & & & & & 0 \\
			& & & & & & & & & & & & & & & & & \vdots \\
			& & & & & & & & & & & & & & & & & 0
		\end{smallmatrix}\right)$$
	où les pivots $p_i$ (\emph{i.e.} les premiers coefficients non-nuls sur chaque ligne) sont strictement positifs, et les coefficients au dessus de 
	chaque pivot sont positifs et inférieurs au pivot.
\end{definition}

\begin{algorithm}[d'\textsc{Hermite} - \textnormal{[G] 164}]
	Soit $M\in \M_{n,m}(\IZ)\setminus \left\{0\right\}$.
	On définit $\delta_{i_0,j}(M) = \min \left\{\vert M_{i,j}\vert \,\colon i \geq i_0,\, M_{i,j}\neq 0\right\}$.
	L'algorithme d'\textsc{Hermite} : \\

	\emph{Soit $i_0=1$. Tant que $i_0 < n$ : soit $j_0 = \min \left\{1\leq j\leq m \mid \delta_{i_0, j}(M)\neq 0\right\}$} \\
	\indent\indent\emph{Si $\forall i > i_0,\, M_{i,j_0} = 0$, alors $L_{i_0} \longleftarrow sg(M_{i_0, j_0})L_{i_0}$, et pour $i$ allant
	de $1$ à $i_0 - 1$, $L_i \longleftarrow L_i - q_iL_{i_0}$ où $q_i$ est le quotient de la division euclidienne de $M_{i,j_0}$ par $M_{i_0,j_0}$. 
	On remplace $i_0$ par $i_0 + 1$} \\
	\indent\indent\emph{Sinon, soit $k\in \llbracket i_0, n\rrbracket$ tel que $\vert M_{k,j_0}\vert$ soit non nul et minimal.
	On effectue $L_i \longleftrightarrow L_{i_0}$ puis, pour $i$ allant de $i_0+1$ à $n$, $L_i\longleftarrow L_i - q_iL_{i_0}$}
	\\

	transforme $M$ sous une forme normale d'\textsc{Hermite} $M_H$.
	En particulier, il existe $P\in GL_n(\IZ)$ telle que $M_H = PM$.
\end{algorithm}

\begin{application}
	Résolution d'un système d'équations diophantiennes linéaires.
\end{application}

\begin{example}
	Cas d'une seule équation linéaire $(E)\,\colon \begin{pmatrix}
		a_1 \\ \vdots \\ a_n
	\end{pmatrix}^T\begin{pmatrix}
		x_1 \\ \vdots \\ x_n
	\end{pmatrix} = b$
	avec $a_1\wedge \cdots \wedge a_n = 1$.
	D'après Cor 24, il existe $P\in GL_4(\IZ)$ telle 
	que 
	$\begin{pmatrix}
		a_1 \\ \vdots \\ a_n
	\end{pmatrix}^TP = \begin{pmatrix}
		a_1\wedge \cdots \wedge a_n \\ 0 \\ \vdots \\ 0
	\end{pmatrix}^T = \begin{pmatrix}
		1 \\ 0 \\ \vdots \\ 0
	\end{pmatrix}^T$

	De là, $(E)\iff \begin{pmatrix}
		1 \\ \vdots \\ 0
	\end{pmatrix}^T\begin{pmatrix}
		\tilde{x_1} \\ \vdots \\ \tilde{x_n}
	\end{pmatrix} = b \iff \tilde{x_1} = b$ où 
	$\left(\begin{smallmatrix}
		\widetilde{x_1} \\ \vdots \\ \widetilde{x_n}
	\end{smallmatrix}\right) = P^{-1}\left(\begin{smallmatrix}
		x_1 \\ \vdots \\ x_n
	\end{smallmatrix}\right)$

	Donc $S(E) = \left\{P\left(\begin{smallmatrix}
		1 \\ x_1 \\ \vdots \\ x_n
	\end{smallmatrix}\right) \mid (x_2,\cdots,x_n)\in \IZ^{n-1}\right\}$
\end{example}


\subsection*{B. Un théorème de \textsc{Liouville}}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[de \textsc{Liouville} - \textnormal{[FGN] 179, [R] 404}]
	\label{142dev2}
	L'équation $P^n+Q^n + R^n = 0$ n'admet 
	pas de solution non triviale (\emph{i.e.} $P,Q,R$ non associées) dans 
	$\IC[X]$ dès lors que $n\geq 3$.
\end{theorem}
\end{tcolorbox}

\subsection*{C. Quelques résultats en théorie des groupes}

\textcolor{paragraphtext}{Soit $G$ un groupe fini. On note $\ord(g)$ l'ordre de $g\in G$.}

\begin{proposition}[\textnormal{[R] 9}]
	L'exposant de $G$ ($\max_{g\in G} \ord(g)$) vaut $\ppcm\left(\left\{\ord(g)\right\}_{g\in G}\right)$.
\end{proposition}

\begin{lemma}[\textnormal{[R] 29}]
	Soit $n\in \IN\setminus\left\{0,1\right\}$, soit $\overline{d}\in\IZnZ$.
	On a $\ord(\overline{d}) = \frac{n^d}{n\wedge d}$.
\end{lemma}

\begin{theorem}[de structure des groupes abéliens finis - \textnormal{[R] 28}]
	Supposons $G$ abélien, de cardinal au moins $2$. Il existe 
	$(d_1, \dots, d_s)\in \left(\IN\setminus \left\{0,1\right\}\right)^s$ tels que :
	$$G \cong \IZ/d_1\IZ \times \cdots \times \IZ/d_s\IZ,\quad d_1 \mid d_2 \mid \cdots \mid d_s$$

	Les entiers $d_1,\dots,d_s$ sont appelés \emph{facteurs invariants de $G$}. Ils sont uniques 
	et déterminent la classe d'isomorphisme de $G$.
\end{theorem}

\begin{example}
	Soit $p$ un nombre premier. Un groupe abélien d'ordre $p^2$
	est isomorphe à $\IZ/p^2\IZ$ ou $\left(\IZ/p\IZ\right)^2$.
\end{example}

\section*{Développements}
\begin{itemize}
	\item Développement 1 : Théorème des restes chinois \ref{142dev11} et Exemple de calcul \ref{142dev12}.
	\item Développement 2 : Théorème de Liouville \ref{142dev2}
\end{itemize}

\section*{Références}
\begin{itemize}
	\item[R] \emph{Mathématiques pour l'agrégation - Algèbre et géométrie}, Jean-Étienne Rombaldi, 2e édition
	\item[P] \emph{Cours d'algèbre}, Perrin
	\item[D] \emph{Cours d'algèbre}, Michel Demazure
	\item[FGN] \emph{Oraux X-ENS Algèbre 1}, Serge Francinou, Hervé Gianella, Serge Nicolas  
	\item[G] \emph{Algèbre I - Groupes, corps et théorie de Galois}, Daniel Guin, Thomas Hausberger 
\end{itemize}


\chapter*{148 : Dimension d'un espace vectoriel (on se limitera au cas de la dimension finie). Rang. Exemples et applications.}
\setcounter{definition}{0}
\textcolor{paragraphtext}{Dans toute cette leçon, $E$ désigne espace vectoriel sur un corps $K$.
On ne rappellera pas les éléments de la théorie des espaces vectoriels.}

\section*{I. Théorie de la dimension finie}
\subsection*{A. Familles libres, familles génératrices, bases}
\textcolor{paragraphtext}{Soit $\mathcal{F}\subseteq E$.}

\begin{definition}[\textnormal{[Gr] 11-11-10-13}]
	On dit que $\mathcal{F}$ est \emph{libre} si :
	$\forall (\overrightarrow{v_1}, \dots, \overrightarrow{v_n})\in\mathcal{F}^n,\, \forall (\lambda_1, \dots, \lambda_n) \in K^n$,
	$$\sum_{k=1}^{n}\lambda_k \overrightarrow{v_k} = \overrightarrow{0}\implies \lambda_1 = \dots = \lambda_n = 0$$

	On dit que $\mathcal{F}$ est \emph{liée} si $\mathcal{F}$ n'est pas libre.

	On dit que $\mathcal{F}$ est \emph{génératrice} (de $E$) si tout vecteur de $E$ peut s'écrire 
	comme combinaison linéaire finie de vecteurs de $\mathcal{F}$.

	On dit que $\mathcal{F}$ est une base de $E$ si $\mathcal{F}$ est à la fois libre et génératrice.
\end{definition}

\begin{example}
	\begin{itemize}
		\item Dans $\IR^2$ : \begin{itemize}
			\item $\{(1,1), (1,-1)\}$ est génératrice et libre ;
			\item $\{(0,1), (1,0), (2,5)\}$ est génératrice et liée ;
			\item $\{(-4, 3)\}$ est non génératrice et libre ;
			\item $\{(1,1), (2,2)\}$ est non génératrice et liée ;
		\end{itemize}
		\item [\textnormal{[Gr] 14}] La famille $\left\{(0,\dots, 1, \dots, 0)\right\}_{i\in \llbracket 1,n\rrbracket}$ est une base de $K^n$, appelée \emph{base canonique}.
	\end{itemize}
\end{example}

\begin{proposition}[\textnormal{[Gr] 13}]
	$\mathcal{F} = \left\{\right\}\subseteq E$ est une base de $E$ si, et seulement si,
	$\forall x\in E,\, \exists ! (\lambda_1,\dots,\lambda_n)\in K^n\,\colon x = \lambda_1\overrightarrow{v_1} + \cdots + \lambda_k\overrightarrow{v_n}$
\end{proposition}

\begin{proposition}[\textnormal{[Gr] 14}]
	\begin{itemize}
		\item $\left\{x\right\}$ est libre $\iff x\neq 0$
		\item Toute sur-famille d'une famille génératrice (resp. liée) est génératrice (resp. liée)
		\item Toute sous-famille d'une famille libre est libre 
		\item Une famille contenant le vecteur nul est liée
	\end{itemize}
\end{proposition}

\subsection*{B. Dimension d'un espace vectoriel}
\begin{definition}[\textnormal{[Gr] 11}]
	On dit que $E$ est de \emph{dimension finie} si $E$ admet une famille génératrice finice.
\end{definition}

\begin{example}
	\begin{itemize}
		\item $K^n$ est un $K$-espace vectoriel de dimension finie, contrairement à $K[X]$.
		\item $\IR$ est un $\IQ$-espace vectoriel de dimension infinie.
	\end{itemize}
\end{example}

\begin{lemma}[de \textsc{Steiniz} - \textnormal{[Gr] 17}]
	Si $\mathcal{G}\subset E$ est finie et génératrice, alors toute
	famille de $E$ contenant plus de $\#\mathcal{G}$ éléments est liée.
\end{lemma}

\begin{theorem_def}[\textnormal{[Gr] 17}]
	Si $E$ est de dimension finie, alors toutes les bases de $E$ ont le même cardinal (fini),
	que l'on appelle \emph{dimension de $E$}, et que l'on note 
	$\dim_K(E)$ ou $\dim(E)$ s'il n'y a pas d'ambiguité sur $K$.
\end{theorem_def}

\textcolor{paragraphtext}{À partir de maintenant, on suppose $E$ de dimension finie.}

\begin{theorem}[\textnormal{[Gr] 18}]
	$\mathcal{B}\subseteq E$ est une base de $E \iff$ $\mathcal{B}$ est 
	libre et $\#\mathcal{B}= \dim(E)\iff \mathcal{B}$ est génératrice et $\#\mathcal{B} = \dim(E)$.
\end{theorem}

\begin{theorem}[\textnormal{[Gr] 19}]
	Si $F$ est un sous-espace vectoriel de $E$, alors $F$ est de dimension finie, et 
	$\dim(F)\leq \dim(E)$ avec égalité si, et seulement si, $E= F$.
\end{theorem}

\begin{theorem}[des bases extraites et incomplètes - \textnormal{[Gr] 19}]
	Soient $\mathcal{L}\subseteq E$ libre et $\mathcal{G}\subseteq E$ génératrice 
	telles que $\mathcal{L}\subseteq \mathcal(G)$. Alors il existe une base $\mathcal{B}$ de 
	$E$ telle que $\mathcal{L}\subseteq \mathcal{B} \subseteq \mathcal{G}$.
\end{theorem}

\begin{corollary}
	Tout espace vectoriel de dimension finie admet une base.
\end{corollary}

\begin{proposition}[\textnormal{[Gr] 63}]
	Soit $F$ un espace vectoriel de dimension finie. Les espaces
	vectoriels $E$ et $F$ sont isomorphes si, et seulement si, $\dim(E) = \dim(F)$.
\end{proposition}

\begin{example}
	Soit $(a_0,\dots, a_{p-1})\in \IC^p$.
	L'application $y \mapsto (y(0), y'(0), \dots, y^{(p-1)}(0))$
	est un isomorphisme entre $S_{\IR}(E) = \left\{y\in C^p(\IR,\IC) \mid y^{(p)} = a_{p-1}y^{(p-1)} + \dots + a_0y\right\}$
	et $\IC^p$. Par conséquent, $\dim(S_{\IR}(E)) = p$.
\end{example}

\begin{proposition}[\textnormal{[Gr] 22}]
	Soient $E_1,\dots,E_p$ supplémentaires dans $E$.
	Si $\mathcal{B}_1,\dots, \mathcal{B}_p$ sont des bases de $E_1,\dots, E_p$, alors $\mathcal{B} = \mathcal{B}_1 \sqcup \cdots \sqcap \mathcal{B}_p$
	est une base de $E$, dite \emph{adaptée à la décomposition $E = E_1\bigoplus \cdots \bigoplus E_p$}.
\end{proposition}

\begin{corollary}[\textnormal{[Gr] 22}]
	$\dim(E\bigoplus F) = \dim(E) + \dim(F)$
\end{corollary}

\begin{proposition}[\textnormal{[Gr] 23}]
	\begin{align*}
		E = E_1 \bigoplus E_2 &\iff \begin{cases}
			E = E_1 + E_2 \\ \dim(E) = \dim(E_1) + \dim(E_2)
		\end{cases}\\
		&\iff \begin{cases}
			E_1 \cap E_2 = \left\{\overrightarrow{0}\right\} \\ \dim(E) = \dim(E_1) + \dim(E_2)
		\end{cases}
	\end{align*}
\end{proposition}

\subsection*{C. Calculs de dimensions}

\textcolor{paragraphtext}{Dans ce paragraphe, $F$ est un espace vectoriel de dimension finie.}

\begin{theorem}[Formule de \textsc{Grassmann} - \textnormal{[Gr] 24}]
	$\dim(E+F) = \dim(E) + \dim(F) - \dim(E\cap F) < +\infty$
\end{theorem}

\begin{proposition}[\textnormal{[Gr] 18}]
	$\dim(E\times F) = \dim(E) + \dim(F) < +\infty$
\end{proposition}

\begin{proposition}
	$\dim(\mathcal{L}(E,F)) = \dim(E)\times \dim(F) < +\infty$
\end{proposition}

\subsection*{D. Extensions de corps}

\textcolor{paragraphtext}{Dans ce paragraphe, $F/L/K$ est une tour d'enxtensions de corps.}

\begin{definition}[\textnormal{[P] 65}]
	On appelle \emph{degré de $L/K$} l'entier $[L:K] = \dim_K(L)$.
\end{definition}

\begin{theorem}[de la base téléscopique - \textnormal{[P] 65}]
	Supposons $F/L$ et $L/K$ de degrés finis :
	elles admettent alors des bases $\left\{f_1,\dots,f_n\right\}$
	et $\left\{e_1,\dots, e_p\right\}$ respectivement.

	La famille $\left\{e_if_j\right\}_{\substack{1\leq i\leq p \\ 1\leq j \leq n}}$
	est une base de $F/K$, et donc $[F:K] = [F:L]\cdot [L:K]$.
\end{theorem}

\begin{definition}[\textnormal{[P] 66}]
	On dit que $\alpha \in L$ est \emph{algébrique} sur $K$ s'il existe $P\in K[X]\setminus \left\{0\right\}$ tel 
	que $P(\alpha) = 0$.

	Le cas échéant, on définit le \emph{polynôme minimal de $\alpha$ sur $K$} comme étant l'unique générateur unitaire
	de l'idéal $\left\{P\in K[X] \mid P(\alpha) = 0\right\}$, appelé \emph{idéal annumateur de $\alpha$}.
\end{definition}

\begin{notation}[\textnormal{[P] 66}]
	Soit $\alpha \in L$. On pose $K[\alpha] = \left\{P(\alpha)\mid P\in K[X]\right\}$
	et $K(\alpha = \Frac(K[\alpha]))$.
\end{notation}

\begin{theorem}[\textnormal{[P] 66}]
	Soit $\alpha\in L$. Sont équivalentes :
	\begin{enumerate}
		\item $\alpha$ est algébrique sur $K$
		\item $K[\alpha] = K(\alpha)$
		\item $[K[\alpha] : K] < +\infty$
	\end{enumerate}

	Le cas échéant, $[K[\alpha] : K]$ est le degré du polynôme minimal de $\alpha$ sur $K$.
\end{theorem}

\section*{II. Rang d'une application linéaire, d'une matrice, d'une famille}
\subsection*{A. Définitions - formule du rang et conséquences}

\textcolor{paragraphtext}{Dans ce paragraphe, on se donne $F$ de dimension finie, $u\in\mathcal{L}(E,F)$, une
base $\mathcal{B}=(e_1,\dots, e_n)$ de $E$, et $(x_1,\dots, x_r)\in E^r$.}

\begin{definition}[\textnormal{[Gr] 61,82}]
		\begin{enumerate}
			\item Le \emph{rang de $u$} est l'entier $\rg(u)=\dim(\im(u))$ ;
			\item Le \emph{rang de $\left\{x_1,\dots,x_r\right\}$} est l'entier $\rg(x_1,\dots, x_r) = \dim(\Vect(x_1,\dots, x_r))$.
		\end{enumerate}
\end{definition}

\begin{proposition}[\textnormal{[Gr] e82}]
	$\rg(u) = \rg(u(e_1),\dots, u(e_n))$
\end{proposition}

\begin{theorem}[du rang - \textnormal{[Gr] 64}]
	$\dim(E) = \dim(\Ker(u)) + \rg(u)$
\end{theorem}

\begin{theorem}[\textnormal{[Gr] 65}]
	Si $\dim(F) = \dim(E)$, alors $u$ bijective $\iff$ $u$ injective 
	$\iff$ $u$ surjective $\iff$ $\exists v\mathcal{L}(F,E)\,\colon u\circ v = \id_E \iff \exists v\in \mathcal{L}(E,F)\,\colon v\circ u = \id_F$.
\end{theorem}

\begin{example}[\textnormal{[Gr] 65}]
	Ce n'est pas vrai en dimension infinie : dans $K[X]$, $P\mapsto P'$ est 
	surjective mais pas injective.
\end{example}

\begin{proposition}
	\begin{itemize}
		\item $\forall v\in GL(E)$, $\rg(u\circ v) = \rg(u)$
		\item $\forall w \in GL(F)$, $\rg(w\circ u) = \rg(u)$
	\end{itemize}
\end{proposition}

\begin{corollary}
	Le rang est invariant par équivalence.
\end{corollary}

\subsection*{B. Le cas particulier des matrices}
\textcolor{paragraphtext}{Soit $A\in\M_{n,p}(K)$. Notons $C_1,\dots, C_p$ ses colonnes et $L_1,\dots, L_n$ ses lignes.}

\begin{definition}[\textnormal{[Gr] 33}]
	Le \emph{rang de $A$} est l'entier $\rg(A) = \dim\left(\left\{AX\mid X\in\M_{n,1}(X)\right\}\right) = \rg(C_1,\dots,C_p)$.
\end{definition}

\begin{proposition}[\textnormal{[Gr] 82}]
	Le rang d'une application linéaire est le rang de sa matrice dans n'importe quel couple de bases.
\end{proposition}

\begin{theorem}[\textnormal{[Go] 128}]
	$\rg(A) = r\implies A$ est équivalente à $J_{n,p,r} := \begin{pmatrix}
		I_r & 0_{p-r} \\ 0_{n-r} & 0_*
	\end{pmatrix}$.
\end{theorem}

\begin{corollary}[\textnormal{[Go] 128}]
	Deux matrices sont équivalentes si, et seulement si, elles ont le même rang.
\end{corollary}

\begin{remark}[\textnormal{[Go] 128}]
	Pour déterminer le rang de $A$ en pratique, on utilise l'algorithme du pivot de \textsc{Gauss}
	pour transformer $A$ en $J_{n,p,r}$.
\end{remark}

\begin{theorem}[\textnormal{[Gr] 83}]
	$\rg(A) = \rg(^tA)$
\end{theorem}

\begin{theorem}[\textnormal{[Go] 128}]
	Le rang de $A$ est la taille de sa plus grande sous-matrice inversible, donc l'ordre de son plus grand mineur non nul.
\end{theorem}

\begin{corollary}
	Si $L/K$ est une extension de $K$, alors $\rg_K(A) = \rg_L(A)$.
\end{corollary}

\section*{III. Applications}
\subsection*{A. Formes quadratiques réelles}


\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[Loi d'inertie de \textsc{Sylvester} - \textnormal{[R] 476}]
	\label{148dev11}
	Soient $E$ est un $\IR$-espace vectoriel de dimension finie $n>0$, et $q$ est une 
	forme quadratique sur $E$.
	Soit $\mathcal{B} = \left\{e_1,\dots, e_n\right\}$ une base de $E$ orthogonale pour $q$.
	Quitte à renuméroter $\mathcal{B}$, supposons que $q(e_1) > 0,\dots, q(e_s) > 0, q(e_{s+1}) < 0,\dots, q(e_{s+t}) < 0, q(e_{s+t+1}) = \cdots = q(e_n) = 0$.
	Le couple $(s,t)$ ne dépend alors pas du choix de la base orthogonale : on l'appelle \emph{signature de $q$}.
\end{theorem}

\begin{theorem}
	\label{148dev12}
	La classe de congruence d'une forme quadratique réelle ne dépend que du rang et de la signature.
\end{theorem}
\end{tcolorbox}

\subsection*{B. Réduction des endomorphismes}
\textcolor{paragraphtext}{Dans ce paragraphe, on fixe $u\in \mathcal{L}(E)$.}

\begin{proposition_def}[\textnormal{[R] 604}]
	$\left\{P\in K[X]\mid P(u)=0_{\mathcal{L}(E)}\right\}$ est un idéal non nul : son unique
	générateur unitaire est appelé \emph{polynôme minimal de $u$}. On le note $\mu_u$.
\end{proposition_def}

\begin{theorem}[\textnormal{[R] 683}]
	$u$ est diagonalisable $\iff \mu_u$ est sciendé à racines simples.
\end{theorem}

\textcolor{paragraphtext}{Dans le groupe suivant, $E$ est un espace euclidien et $u\in\mathcal{L}(E)$.}
\begin{definition}[\textnormal{[R] 743}]
	On dit que $u$ est \emph{normal} si $uu^* = u^*u$ où $u^*$ est l'adjoint de $u$.
\end{definition}


\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{lemma}[\textnormal{[R] 745}]
	\label{148dev21}
	Si $u$ est normal, $\exists P_1,\dots, P_r$ sont de dimension $1$ ou $2$, 
	deux à deux orthogonaux et stables par $u$ tels que $E=P_1\bigoplus\cdots\bigoplus P_r$.
\end{lemma}
\begin{theorem}
	\label{148dev22}
	Si $u$ est normal, alors il existe une base orthonormée $\mathcal{B}$ de $E$ telle que
	$\Mat_{\mathcal{B}}(u) = \left(\begin{smallmatrix}
		D & & & \\
		& R_1 & & \\
		& & \ddots & \\
		& & & R_p \\
	\end{smallmatrix}\right)$ par blocs, avec $D$ diagonale et les $R_k$ de la forme $\begin{pmatrix}
		a_k & -b_k \\ b_k & a_k
	\end{pmatrix}$, $b_k\neq 0$.
\end{theorem}
\end{tcolorbox}

\section*{Développements}
\begin{itemize}
	\item Développement 1 : Loi inertie Sylvester \ref{148dev11} et Th \ref{148dev12}.
	\item Développement 2 : Lemme \ref{148dev21} et Théorème \ref{148dev22}
\end{itemize}

\section*{Références}
\begin{itemize}
	\item[R] \emph{Mathématiques pour l'agrégation - Algèbre et géométrie}, Jean-Étienne Rombaldi, 2e édition
	\item[P] \emph{Cours d'algèbre}, Perrin
	\item[Gr] \emph{Algèbre linéaire}, Joseph Grifone, 6e édition, 2e version
	\item[Go] \emph{Les maths en tête - Algèbre et Probabilités}, Xavier Gourdon, 3e édition  
\end{itemize}


\chapter*{149 : Déterminant. Exemples et applications.}
\setcounter{definition}{0}

\textcolor{paragraphtext}{Dans cette leçon, $K$ désigne un corps, $\IK$ désigne $\IR$ ou $\IC$, et $E$ est un $\IK$-espace vectoriel de dimension finie $n\geq 1$.
On fixe une base $\mathcal{B}=(e_1,\dots,e_n)$ de $E$.}

\section*{I. Les notions de déterminants}
\subsection*{A. Des formes multilinéaires au déterminant d'une famille de vecteurs}

\begin{definition}[\textnormal{[Go] 140}]
	Une \emph{forme $k$-linéaire sur $E$} est une application $\varphi\,\colon E^k\to \IK$ 
	telle que pour tout $i\in\llbracket 1,k\rrbracket$, pour tout $(x_1,\dots, x_k)\in E^k$, $\varphi(x_1,\dots, x_{i-1}, \cdot, x_{i+1},\dots, x_k)$
	est linéaire. On note $\bigotimes^k E^*$ l'ensemble des formes $k$-linéaires sur $E$.
\end{definition}

\begin{proposition}
	$\left(e_{i_1}^*\otimes \dots\otimes e_{i_k}^*\right)_{1\leq i_1\leq\cdots\leq i_k\leq n}$ est une base de $\bigotimes^k E^*$, où pour $(x_1,\dots, x_k)\in E^k$,
	$e_{i_1}^*\otimes\dots\otimes e_{i_k}^*(x_1,\dots, x_k) = e_{i_1}^*(x_1)\cdots e_{i_k}^*(x_k)$.
\end{proposition}
\begin{definition}[\textnormal{[Go] 140-141}]
	Une forme $k$-linéaire \emph{alternée} est une forme $k$-linéaire $\varphi\in\bigotimes^kE^*$
	telle que $\forall\sigma\in\mathfrak{S}_k$, $\forall(x_1,\dots, x_k)\in E^k$, $\varphi(x_{\sigma(1)},\dots, x_{\sigma(k)}) = \varepsilon(\sigma)\varphi(x_1,\dots, x_k)$.

	On note $\bigwedge^k E^*$ l'espace des formes $k$-linéaires alternées sur $E$.
\end{definition}

\begin{proposition}
	$\left(e_{i_1}^*\wedge \dots \wedge e_{i_k}^*\right)_{1\leq i_1 < \dots < i_k\leq n}$ est une base de $\bigwedge^kE^*$, où pour $(x_1,\dots,x_k)\in E^k$,
	$e_{i_1}^*\wedge \dots \wedge e_{i_k}^*(x_1,\dots,x_k) = \sum_{\sigma\in\mathfrak{S}_k} \varepsilon(\sigma) e_{i_1}^*(x_{\sigma(1)}) \dots e_{i_k}^*(x_{\sigma(k)})$.
\end{proposition}

\begin{corollary}
	On a $\dim\left(\bigwedge^kE^*\right) = {n \choose k}$.
\end{corollary}

\begin{definition}[\textnormal{[Go] 141}]
	On appelle \emph{déterminant dans la base $\mathcal{B}$} l'unique forme $n$-linéaire alternée $\det_{\mathcal{B}}$ sur $E$ vérifiant
	$\det_{\mathcal{B}}(\mathcal{B}) = 1$. (La fammille $\left(\det_{\mathcal{B}}\right)$ est une base de $\bigwedge^n E^*$.)
\end{definition}

\begin{proposition}[\textnormal{[Go] 141}]
	$\forall(x_1,\dots, x_n)\in E^n$, $\det_{\mathcal{B}}(x_1,\dots, x_n) = \sum_{\sigma\in \mathfrak{S}_n} \varepsilon(\sigma)e^*_1(x_{\sigma(1)})\dots e^*_{n}(x_{\sigma(n)})$.
\end{proposition}

\begin{corollary}[\textnormal{[Go] 141}]
	Soient $\varphi\in \bigwedge_n E^*$ et $\mathcal{B}'$ une autre base de $E$. On a $\varphi = \varphi(\mathcal{B})\det_{\mathcal{B}}$,
	en particulier on a donc $\det_{\mathcal{B}'} = \det_{\mathcal{B}'}(\mathcal{B})\det_{\mathcal{B}'}$.
\end{corollary}

\begin{proposition}[\textnormal{[Go] 141-142}]
	Soit $(x_1,\dots, x_n)\in E^n$. Sont équivalentes :
	\begin{enumerate}
		\item $(x_1,\dots, x_n)$ est liée ;
		\item Pour toute base $\mathcal{B}$ de $E$, $\det_{\mathcal{B}}(x_1,\dots,x_n) = 0$ ;
		\item Il existe une base $\mathcal{B}$ de $E$ telle que $\det_{\mathcal{B}}(x_1,\dots, x_n) = 0$.
	\end{enumerate}
\end{proposition}

\subsection*{B. Déterminant d'une matrice carrée, d'un endomorphisme}
\textcolor{paragraphtext}{Soient $u\in\mathcal{L}(E)$ et $A = \left(a_{i,j}\right)_{1\leq i,j\leq n} \in \M_n(\IR)$.}

\begin{definition}[\textnormal{[Go] 142}]
	Si $C_1,\dots, C_n$ sont les colonnes de $A$, alors :
	$$\det(A) := \det{}_{\mathcal{E}}(C_1,\dots,C_n) = \frac{1}{n!}\sum_{\sigma\in\mathfrak{S}_n} \varepsilon(\sigma)a_{1,\sigma(1)}\cdots a_{n,\sigma(n)}$$
	où $\mathcal{E}$ déisgne la base canonique de $K^n$.
\end{definition}

\begin{proposition}[\textnormal{[Go] 142}]
	Soient $\lambda\in K$ et $B\in\M_n(K)$.
	\begin{enumerate}
		\item $\det(A)$ ne change pas si on ajoute à une colonne une combinaison linéaire des autres colonnes ;
		\item $\det(A^T)=\det(A)$
		\item $\det(\lambda A) = \lambda^n \det(A)$
		\item $\det(AB) = \det(A)\det(B)$
		\item $A\in GL_n(K)\iff \det(A)\neq 0$ (auquel cas, $\det(A^{-1}) = {\det(A)}^{-1}$)
	\end{enumerate}
\end{proposition}

\begin{definition}[\textnormal{[Go] 142}]
	Le déterminant de $u$, défini par :
	$\det(u) = \det_{\mathcal{B}}(u(e_1),\dots, u(e_n)) = \det(\Mat_{\mathcal{B}}(u))$
	ne dépend pas du choix de $\mathcal{B}$.
\end{definition}

\subsection*{C. Propriétés analytiques}
\begin{proposition}[\textnormal{[Rv] 83}]
	$A\mapsto \det A$ est polynomiale en les coefficients de $A$ (relativement à la base canonique de $\M_n(K)$), donc lisse.
\end{proposition}

\begin{corollary}
	$GL_n(\IK)$ est ouvert dans $\M_n(\IK)$, et $SL_n(\IR)$ est fermé.
\end{corollary}

\begin{proposition}[\textnormal{[Rv] 83}]
	$\forall x\in \M_n(\IR)$, $\forall H\in \M_n(\IR)$, $d(\det)(X)(H) = \tr (\Com(X)^T H)$,
	où $\Com(X)$ est rappelée dans le paragraphe $II. B$.
\end{proposition}

\section*{II. Calcul pratique d'un déterminant}
\subsection*{A. Cas simples, pivot de \textsc{Gauss}}

\begin{notation}[\textnormal{[Go] 142}]
	On note $\mid A\mid$ le determinant d'une matrice carrée $A$.
\end{notation}

\begin{proposition}[\textnormal{[Go] 106}]
	\begin{itemize}
		\item $\begin{vmatrix}
			a & b \\ c & d
		\end{vmatrix} = ad - bc$
		\item $\begin{vmatrix}
			a & b & c \\ d & e & f \\ i & j & k
		\end{vmatrix} = aek+bfi+djc -cei-fja-bdk$ (règle de \textsc{Sarrus})
	\end{itemize}	
\end{proposition}

\begin{lemma}[\textnormal{[Go] 142}]
	Si $A = \left(a_{i,j}\right)_{1\leq i,j\leq 1}$ est triangulaire, 
	alors $\det(A) = a_{1,1}a_{2,2}\dots a_{n,n}$.
\end{lemma}

\begin{algorithm}[pivot de \textsc{Gauss}]
	Pour calculer le déterminant d'une matrice, 
	on peut la transformer en une matrice triangulaire par des opérations élémentaires sur les lignes et 
	les colonnes :
	\begin{itemize}
		\item la transvection $(C_i \longrightarrow C_i+\lambda C_j)$ ne change pas le déterminant ;
		\item la permutation $(C_i \longleftrightarrow C_j)$ change le signe du déterminant ;
		\item la dilatation $(C_i \Longrightarrow \alpha C_i)$ change le déterminant d'un facteur $\alpha$.
	\end{itemize}
\end{algorithm}

\begin{example}
	\begin{align*}
		\begin{vmatrix}
			1&1&1\\
			0&1&1\\
			-1&-1&0
		\end{vmatrix}=
		\begin{vmatrix}
			1&1&1\\
			0&1&1\\
			0&0&1
		\end{vmatrix} = 1
	\end{align*}
\end{example}

\begin{theorem}[\textnormal{[Go] 142}]
	Le déterminant d'une =atrice triangulaire par blocs est égal au produit des déterminants des blocs diagonaux.
\end{theorem}


\subsection*{B. Mineurs, cofacteurs et développements}

\textcolor{paragraphtext}{Soient $A=\left(a_{i,j}\right)_{1\leq i,j\leq n}\in\M_n(K)$.}
\begin{definition}[\textnormal{[Go] 142}]
	Soit $(i,j)\in \llbracket 1,n \rrbracket ^2$.
	On appelle \emph{mineur d'indice $(i,j)$ de $A$} le déterminant de la matrice extraite de $A$
	en supprimant sa $i$-ième ligne et sa $j$-ième colonne.
	On note $\Delta_{i,j}$ ce mineur.
	
	On appelle \emph{cofacteur d'indice $(i,j)$ de $A$} la quantité $A_{i,j} = \left(-1\right)^{i+j}\Delta_{i,j}$.

	On appelle \emph{comatrice de $A$} la matrice $\Com(A) = \left(A_{i,j}\right)_{1\leq i,j\leq n}$.
\end{definition}

\begin{theorem}[Formules de développement d'un déterminant - \textnormal{[Go] 143}]
	\begin{itemize}
		\item Par rapport à la $i$-ième ligne :$\det A = \sum_{j=1}^{n}a_{i,j}A_{i,j}$ 
		\item Par rapport à la $j$-ième colonne : $\det A = \sum_{i=1}^{n}a_{i,j}A_{i,j}$
	\end{itemize}
\end{theorem}

\begin{example}
	$\begin{vmatrix}
		1&1&1\\0&1&1\\-1&-1&0
	\end{vmatrix} = 1\cdot \begin{vmatrix}
		1&1\\-1&0
	\end{vmatrix} - 0\cdot \begin{vmatrix}
		1&1\\-1&0
	\end{vmatrix}+ (-1)\cdot \begin{vmatrix}
		1&1\\1&1
	\end{vmatrix}= 1-0+0 = 1$
\end{example}

\begin{theorem}[Formule de la comatrice - \textnormal{[Go] 143}]
	$A\Com(A)^T = \Com(A)^T A = \det(A)I_n$
\end{theorem}

\subsection*{C. Déterminants remarquables}


\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{example}[déterminant circulant - \textnormal{[Go] 143; [IP] 388}]
	\label{149dev11}
	Pour tout $(a_1,\dots, a_n)\in \IC^n$,
	$$\begin{vmatrix}
		a_1&a_2&a_3&\cdots &a_n \\
		a_n&a_1&a_2&\cdots &a_{n-1} \\
		a_{n-1}&a_n&a_1&\cdots &a_{n-2} \\
		\vdots&\vdots&\vdots& &\vdots \\
		a_{2}&a_3&a_4&\cdots &a_{1}
	\end{vmatrix} = \prod_{k=1}^{n}P(\omega^k)$$
	où $\omega = e^{\frac{2i\pi}{n}}$ et $P=\sum_{i=0}^{n-1} a_{i+1}X^i$.
\end{example}

\begin{application}[FIG 1 - \textnormal{[IP] 388}]
	\label{149dev12}
	Soient $z_1,\dots, z_n$ des complexes qui sont les affixes des points $M_1,\dots,M_n$.
	On définit une suite de polygônes du plan comme suivant :
	\begin{itemize}
		\item $P_0=M_1\dots M_n$
		\item Pour $n\geq 1$, $P_n$ est le polygône dont les sommets sont les milieux des arêtes de $P_{n-1}$.
		Alors $(P_n)_n$ converge vers l'isobarycentre de $P_0$.
	\end{itemize}
\end{application}
\end{tcolorbox}

\begin{example}[déterminant de \textsc{Vandermonde} - \textnormal{[Go] 143}]
	Pour tout $(a_1,\dots, a_n)\in K^n$,
	$$\begin{vmatrix}
		1&a_1&a_1^2&\cdots & a_1^{n-1} \\
		1&a_2&a_2^2&\cdots & a_2^{n-1} \\
		\vdots&\vdots&\vdots& & \vdots \\
		1&a_n&a_n^2&\cdots & a_n^{n-1}
	\end{vmatrix} = \prod_{1\leq i,j\leq n} a_i-a_j$$
\end{example}

\section*{III. Applications des déterminants...}
\subsection*{A. ...en algèbre linéaire}

\begin{remark}[\textnormal{[BMP] 181}]
	On étend la formule explicite du déterminant au cas des matrices à coefficients dans un anneau intègre $A$.
	Si $M\in \M_n(A)$, alors $\det(M)\in A$, et par plongement de $A$ dans $\Frac(A)$, les propriétés dékà vues restent vraies.
\end{remark}

\begin{definition}[\textnormal{[Go] 172}]
	Le \emph{polynôme caractéristique de $A\in\M_n(K)$} est $\chi_A = \det(XI_n - A)$.

	Le \emph{polynôme caractéristique d'un endomorphisme} est celui de sa matrice dans n'importe quelle base.
\end{definition}

\begin{proposition}[\textnormal{[Go] 159; [C] 47}]
	\begin{itemize}
		\item $\forall A\in\M_n(K)$, $\Sp(A) = \chi^{-1}_A(\left\{0\right\})$
		\item $\forall (A,B)\in\M_n(\IC)$, $\chi_{AB} = \chi_{BA}$
	\end{itemize}
\end{proposition}

\begin{theorem}[de \textsc{Cayley-Hamilton} - \textnormal{[M2] 81}]
	$\forall A\in\M_n(\IK)$, $\chi_A(A)=0$.
\end{theorem}

\begin{theorem}[Systèmes de \textsc{Cramer} - \textnormal{[Gr] 145}]
	Soient $A\in GL_n(K)$ et $B\in K^n$. On note $A_1,\dots, A_n$
	les colonnes de $A$. La solution de $AX=B$ est donnée par $X=(x_1,\dots, x_n)$ où
	$$\forall i\in \llbracket 1,n\rrbracket,\quad x_i = \frac{\det(A_1,\dots,A_{i-1},B,A_{i+1},\dots, A_n)}{\det(A)}$$
\end{theorem}

\subsection*{B. ...en calcul intégral}
\begin{theorem}[de changement de variable - ADMIS - \textnormal{[BP] 255-256}]
	Soient $U$ et $V$ deux ouverts de $\IR^n$, et 
	$\varphi\,\colon U\to V$ un $C^1$-difféomorphisme. Pour tout fonction $f\,\colon V\to \IR^+$ borélienne,
	$$\int_{U} f\circ \varphi(u)\cdot \vert \det(d\varphi(u))\vert du = \int_{V}f(v)dv$$
\end{theorem}

\begin{application}
	$\forall \alpha > 0$, $\int_{\IR} e^{-\alpha x^2}dx = \sqrt{\frac{\pi}{\alpha}}$
\end{application}

\begin{theorem}[\textnormal{[BMP] 184}]
	Notons $\lambda$ la mesure de \textsc{Lebesgue} sur $\IR^n$. Pour tous $X\subseteq\IR^n$ mesurable ett $u\in\mathcal{L}(\IR^n)$,
	$\lambda(u(X))=\vert \det(u)\vert\cdot \lambda(X)$
\end{theorem}

\begin{corollary}[FIG. 3 - \textnormal{[BMP] 184}]
	Soit $(v_1,\dots, v_n)\in \IR^n$, notons $\mathcal{P}(v_1,\dots,v_n) = \left\{\sum_{i=1}^{n} \lambda_i v_i \mid 0\leq \lambda_i \leq 1\right\}$
	le parallélotope engendré par $v_1,\dots,v_n$. On a $\lambda(\mathcal{P}(v_1,\dots,v_n))=\vert \det(v_1,\dots, v_n)\vert$.
\end{corollary}

\subsection*{C. ...en géométrie}
\textcolor{paragraphtext}{Dans ce paragraphe, $(E,\langle \cdot \mid \cdot \rangle)$ est un $\IK$-espace préhilbertien.}

\begin{definition}[\textnormal{[Go] 274}]
	Soit $(x_1,\dots,x_n)\in E^n$. On appelle \emph{matrice de \textsc{Gram} de} $x_1,\dots, x_n$ la matrice 
	$M_G(x_1,\dots,x_n)=\left(\langle x_i\mid x_j\rangle\right)_{1\leq i,j\leq n}$,
	et \emph{déterminant de \textsc{Gram} de} $x_1,\dots, x_n$ sont déterminant $G(x_1,\dots,x_n)$.
\end{definition}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[\textnormal{[Go] 275}]
	\label{149dev21}
	Soient $F$ un sous-espace vectoriel de $E$, et $\mathcal{B}=(e_1,\dots, e_n)$ une base de $F$. Alors, 
	$\forall x\in E$, $d(x,F)^2=\frac{G(e_1,\dots,e_n, x)}{G(e_1,\dots,e_n)}$.
\end{theorem}
\begin{theorem}[inégalités de \textsc{Hadamard} - \textnormal{[Go] 275}]
	\label{149dev22}
	On a :
	\begin{enumerate}
		\item $\forall(x_1,\dots, x_n)\in E^n$, $G(x_1,\dots, x_n)\leq \|x_1\|^2\dots \|x_n\|^2$
		\item $\forall (x_1,\dots,x_n)\in \left(\IC^n\right)^n$, $\vert \det(x_1,\dots, x_n)\vert\leq \|x_1\|_2\dots \|x_n\|_2$
	\end{enumerate}
	
	De plus, dans les deux points, il y a égalité si, et seulement si, $(x_1,\dots, x_n)$ est orthogonale.
\end{theorem}
\end{tcolorbox}

\section*{Développements}
\begin{itemize}
	\item Développement 1 : Exemple \ref{149dev11} et Application \ref{149dev12}.
	\item Développement 2 : Théorèmes \ref{149dev21} et \ref{149dev22}
\end{itemize}

\section*{Références}
\begin{itemize}
	\item[Rv] \emph{Petit guide du calcul différentiel}, François Rouvière, 4e édition
	\item[IP] \emph{L'oral à l'agrégation de mathématiques}, Lucas Issenmann, Timothée Pecatte
	\item[M2] \emph{Algèbre linéaire. Réduction des endomorphismes}, Roger Mansuy, Rached Mneimné, 3e édition
	\item[Gr] \emph{Algèbre linéaire}, Joseph Grifone, 6e édition, 2e version
	\item[Go] \emph{Les maths en tête - Algèbre et Probabilités}, Xavier Gourdon, 3e édition  
	\item[BMP] \emph{Objectif Agrégation}, Vincent Beck, Jérôme Malick, Gabriel Peyré, 2e édition
	\item[BP] \emph{Théorie de l'intégration}, Marc Briane, Gilles Pagès, 7e édition
	\item[C] \emph{Carnet de voyage en Algébrie}, Philippe Caldero, Marie Peronnier
\end{itemize}

\begin{figure}[!htb]
	\centering
	\includegraphics[trim={0 0 0 0},clip,width=1\linewidth]{img/149.pdf}
	\caption{s}
\end{figure}

\section*{Le p'tit recul personnel}
\textbf{En quoi est-ce que la continuité du déterminant est intéressante (dim finie) ?}
\begin{enumerate}
	\item \textbf{Stabilité :} en dim finie, le déterminant est un indicateur de bijectivité, tout comme le noyau est un indicateur d'injectivité. La continuité de la fonction $\det$ permet d'affirmer que si un endomorphisme est de déterminant disons 50, alors les endomorphismes \emph{proches} de celui-ci devraient être bijectifs. De même lorsqu'on est proche de $0$, où on peut se demander en pratique si une valeur de déterminant de $0.001$ n'implique pas que l'on travaille avec des endomorphismes dangereusement proches de la non-inversibilité. C'est ce qu'on fait en robotique en étudiant soit le déterminant de la Jacobienne d'un système, soit la dernière valeur singulière si la Jacobienne n'est pas carrée.
	\item \textbf{Topologie :} toute image réciproque d'un ouvert par une application continue est un ouvert. On a dont naturellement le fait que $GL_n(\IR) = \det^{-1}(\IR^*)$ est un ouvert de $\M_n(\IR)$. Comme $GL_n(\IR)$ est un groupe (multiplicatif non-abélien), sa structure topologique lui induit une structure de variété différentielle et donc de groupe de Lie.
	\item \textbf{Exponentielle :} cf. partie topologie : continuité de $\det \implies GL_n(\IR) = \det^{-1}(\IR^*)$ est un ouvert de $\M_n(\IR) \implies$ $GL_n(\IR)$ est un groupe de Lie donc c'est le cadre naturel pour l'existence et la définition de l'exponentielle dessus.
	\item \textbf{Continuité des valeurs propres :} 1) $\det A$ (et $\tr A$) sont des polynômes en les coefficients de $A$; 2) en analyse complexe un théorème dit que les racines d'un polynôme varient continûment en fct de ses coefficients $\implies$ valeurs propres d'une matrice sont des fcts continues des coefficients de cette matrice.
\end{enumerate}

\textbf{Pourquoi ça fait chier qu'elle ne soit pas forcément assurée en dimension infinie ?}
\begin{enumerate}
	\item \textbf{Inversibilité n'est plus stable :} voila. L'inversibilité c'est une propriété fragile désormais. En particulier, une suite d'opérateurs inversibles peuvent converger vers un opérateur non-inversible. Exemple : sur $\ell^2(\IN)$, $A_{\varepsilon} \,\colon (x_1,x_2,x_3\dots)\mapsto (\varepsilon x_1, x_2,x_3,\dots)$. L'inverse de $A_{\varepsilon}$ est naturellement $A_{1/\varepsilon}$ pour tout $\varepsilon > 0$ aussi petit soit-il. Par contre si on fait tendre $\varepsilon \longrightarrow +\infty$, alors $A_{\varepsilon}\to A_0$ qui n'est pas invesible (de noyau toutes les suites de la formes $(c,0,0,\dots)$).
	\item \textbf{Généralement :} en fait la notion d'inversibilité ne devrait pas être transposée en dimension finie : on devrait plutôt avoir une notion de \emph{oui c'est inversible, \textbf{mais c'est à un cheveu de ne pas l'être}}, ou \emph{à quel point est l'opérateur inversible ?}
\end{enumerate}

\textbf{Comment on y remédie en dim infinie ?}
\begin{enumerate}
	\item \textbf{Déterminant de Fredholm :} $A\mapsto \det(I+A) = \prod_{\lambda\in \Sp(A)} (1+\lambda)$ avec $A$ un opérateur à trace (\emph{i.e.} suffisament "petit" : la somme de ses valeurs singulières est finie - c'est une condition très forte, bien plus qu'être compact) joue un rôle analogue au déterminant en dimension finie : il est non nul si et seulement si l'équation suivante admet une unique solution pour tout $g$ : $g(x) = f(x) + \int K(x,y)f(y)dy$, qui est une équation de la forme $g = (I+A)f$ où $A$ est un opérateur intégral. On a bien ici que le déterminant de Fredholm est continue pour cette classe de matrices.
\end{enumerate}

\chapter*{151 : Sous-espaces stables par un endomorphisme ou une famille d'endomorphismes d'un espace vectoriel de dimension finie. Applications.}
\setcounter{definition}{0}

\textcolor{paragraphtext}{Soient $K$ un corps commutatif, $E$ un $K$-espace vectoriel de dimension $n\geq 1$ et $u\in\mathcal{L}(E)$. 
Soit $F$ un sous-espace vectoriel de $E$.}

\section*{I. Stabilité d'un sous-espace par un endomorphisme}
\subsection*{A. Introduction}

\begin{definition}[\textnormal{[M2] 17}]
	On dit que $F$ est \emph{stable par $u$} (ou \emph{$u$-stable}) si $u(F)\subseteq F$.
\end{definition}

\begin{example}[\textnormal{[M2] 17}]
	On a :
	\begin{itemize}
		\item $\left\{0\right\}$, $\Ker(u)$, $\im(u)$ et $E$ sont stables par $u$.
		\item $\forall P\in K[X]$, $\Ker(P(u))$ et $\im(P(u))$ sont stables par $u$.
	\end{itemize}
\end{example}

\begin{proposition}[\textnormal{[M2] 17}]
	Soit $v\in\mathcal{L}(E)$. Si $v$ commute avec $u$, alors pour tout $P\in K[X]$,
	$\Ker(P(u))$ et $\im(P(u))$ sont stables par $u$.
\end{proposition}

\begin{remark}
	En particulier, $\forall \lambda\in K$, $E_{\lambda}(u) := \Ker(u-\lambda \id_E)$ est 
	stable par $u$, et par tout endomorphisme qui commute avec $u$.
\end{remark}

\begin{proposition}[\textnormal{[M2] e17}]
	Soit $E = F\bigoplus G$ une décomposition de $E$, soit $\mathcal{B}$ une base de $E$ 
	adaptée à cette décomposition, notion $\Mat_{\mathcal{B}}(u) = \begin{pmatrix}
		A & B \\ C & D
	\end{pmatrix}$ par blocs. Alors $F$ (resp. $G$) est stable par $u$ si, et seulement si, $C=0$ (resp. $B = 0$).
\end{proposition}

\begin{corollary}[\textnormal{[M2] e120}]
	$F$ est stable par $u$ si, et seulement si, $F^{\perp}$ est stable par ${}^tu$.
	(NB : $\Mat_{\mathcal{B}^*}({}^t u) = {}^t\Mat_{\mathcal{B}}(u)$).
\end{corollary}

\subsection*{B. Notion d'endomorphisme induit}
\begin{definition}[\textnormal{[M2] 17}]
	Si $F$ est stabe par $u$, alors on dispose de \emph{l'endomorphisme induit par $u$ sur $F$} :
	$u_F\,\colon F\to F$, $x\mapsto u(x)$.
\end{definition}

\begin{proposition}[\textnormal{[M2] 55, 18}]
	Si $F$ est stable par $u$, alors $\chi_{u_F} \mid \chi_u$ et $\pi_{u_F}\mid \pi_u$.
\end{proposition}

\begin{corollary}[\textnormal{[M2] 93}]
	Si $F$ est stable par $u$ et si $u$ est diagonalisable (resp. trigonalisable, resp. nilpotent), alors $u_F$ aussi.
\end{corollary}

\begin{proposition}[\textnormal{[M2] 55, 18}]
	Si $E=F_1\bigoplus \cdots \bigoplus F_p$ est une décomposition de $E$ en somme de sous-espaces stables, alors :
	$\chi_u = \chi_{u_{F_1}}\cdots \chi_{u_{F_p}}$ et $\pi_u = \pi_{u_{F_1}}\vee \cdots \vee \pi_{u_{F_p}}$.
\end{proposition}

\section*{II. Application à la réduction des endomorphismes}

\begin{lemma}[des noyaux - \textnormal{[M2] 43}]
	$\forall (P,Q)\in K[X]^2$, $P\wedge Q = 1 \implies \Ker((PQ)(u)) = \Ker(P(u))\bigoplus \Ker(Q(u))$
\end{lemma}

\subsection*{A. Diagonalisation, trigonalisation}
\begin{theorem}[de \textsc{Cayley-Hamilton} - \textnormal{[M2] 82}]
	$\chi_u(u) = 0_{\mathcal{L}(E)}$
\end{theorem}

\begin{corollary}
	$E = \bigoplus_{\lambda\in \Sp(u)} \Ker\left(\left(u-\lambda \id_E\right)^{\mu_{\lambda_u}(\lambda)}\right)$
	est une décomposition de $E$ en somme de sous-espaces stables.
\end{corollary}

\begin{proposition}[\textnormal{[M2] 84}]
	Écrivons $\chi_u = \prod_{\lambda\in\Sp(u)} \left(X_\lambda\right)^{m(\lambda)}$
	et posons $E_{\lambda}(u)=\Ker(\lambda\id_E - u)$.
	Pour tout $\lambda\in \Sp(u)$, $1\leq \dim(E_{\lambda}(u))\leq m(\lambda)$.
\end{proposition}

\begin{theorem}[\textnormal{[R] 683; [M2] 90-93}]
	On a :
	\begin{itemize}
		\item $u$ est diagonalisable $\iff \pi_u$ est sciendé à racines simples $\iff$ il existe $P$ annulateur de $u$ sciendé à racines simples $\iff \chi_u$ est sciendé et $\forall\lambda\in\Sp(u)$, $\dim(E_{\lambda}(u)) = \mu_{\chi_u}(\lambda)$.
		\item $u$ est trigonalisable $\iff \chi_u$ est scindé $\iff$ il existe un polynôme scindé qui annule $u$.
	\end{itemize}
\end{theorem}

\begin{theorem}[de réduction simultanée - \textnormal{[M2] 94,107}]
	Soit $\left(u_i\right)_{i\in I}\in\mathcal{L}(E)^I$ une famille d'endomorphismes qui commutent deux à deux.
	Si tous les $u_i$, $i\in I$ sont diagonalisables (resp. trigonalisables), alors il existe une base de $E$ qui 
	diagonalise (resp. trigonalise) simultanément tous les $u_i$, $i\in I$.
\end{theorem}


\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{lemma}[\textnormal{[R] 743}]
	\label{151dev11}
	Il existe un sous-espace de $E$ de dimension $1$ ou $2$ stable par $u$.
\end{lemma}
\end{tcolorbox}

\subsection*{B. Cas des endomorphismes normaux}
\textcolor{paragraphtext}{Dans l'encadré suivant, on suppose $u$ normal}


\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{lemma}[\textnormal{[R] 743}]
	\label{151dev12}
	Si $F$ est un sous-espace de $E$ stable par $u$, alors $F^{\perp}$ est stable par $u$.
\end{lemma}
\begin{lemma}[\textnormal{[R] 744}]
	\label{151dev13}
	Il existe des sous-espaces $P_1,\dots, P_r$ de $E$ stables par $u$, de dimension $1$ ou $2$, deux à deux orthogonaux, tels que 
	$$E = P_1\bigoplus^{\perp}\cdots\bigoplus^{\perp} P_r$$
\end{lemma}
\end{tcolorbox}

\begin{lemma}[PAS DEV - \textnormal{[R] 745}]
	Si $n = \dim E = 2$, alors :
	\begin{itemize}
		\item Si $u$ admet une valeur propre réelle, alors $u$ est diagonalisable dans une base orthonormée,
		\item Sinon, pour toute base orthonormée $\mathcal{B}$ de $E$, il existe $(a,b)\in\IR^2$ tel que $b\neq 0$ et $\Mat_{\mathcal{B}}(u)=\begin{pmatrix}
			a & -b \\ b & a
		\end{pmatrix}$.
	\end{itemize}
\end{lemma}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[de réduction des endomorphismes normaux - \textnormal{[R] 745}]
	Il existe une base orthonormée $\mathcal{B}$ de $E$ telle que, par blocs, $\Mat_{\mathcal{B}}(u) = \diag(D_p, R_1,\dots, R_r)$, où 
	$D_p\in\M_n(\IR)$ est diagonale, $\forall i\in \llbracket 1,n\rrbracket$, $\exists (a_i, b_i)\in\IR^2\,\colon b_i \neq 0$ et $R_i = \begin{pmatrix}
		a_i & -b_i \\ b_i & a_i
	\end{pmatrix}$ et $p+2r = n$.
\end{theorem}
\end{tcolorbox}

\begin{corollary}[théorème spectral - \textnormal{[R] 746 (734)}]
	Tout endomorphisme auto-adjoint se diagonalise dans une base orthonormée.
\end{corollary}

\begin{corollary}[\textnormal{[R] 727}]
	Si $u$ est orthogonal, alors il existe une base de $E$ dans laquelle la matrice de $u$ est de la forme, par blocs :
	$\begin{pmatrix}
		I_p & & & & \\
		& -I_q & & & \\
		& & R_1 & & \\
		& & & \ddots & \\
		& & & & R_r
	\end{pmatrix}$, où $R_k = \begin{pmatrix}
		\cos(\theta_k) & -\sin(\theta_k) \\ \sin(\theta_k) & \cos(\theta_k)
	\end{pmatrix}$
\end{corollary}

\begin{proposition}
	Si $u$ est une rotation et que $\dim (E)$ est impaire, alors $\Ker(u-\id_E)\neq \left\{0\right\}$.
\end{proposition}

\section*{II. Application à la décomposition des endomorphismes}
\subsection*{A. Décomposition de \textsc{Jordan} des endomorphismes nilpotents}

\begin{definition}[\textnormal{[M2] 143}]
	On appelle \emph{bloc de \textsc{Jordan}} de taille $d$ la matrice :
	$$J_d := \begin{pmatrix}
		0 & 1 & \cdots & 0 \\
		\vdots & \ddots & \ddots & \vdots \\
		\vdots & & \ddots & 1 \\
		0 & \cdots & \cdots & 0
	\end{pmatrix}$$

	Pour $\lambda = (\lambda_1, \dots, \lambda_r)\in\IN^r$, on pose $J_{\lambda} = \diag(J_{\lambda_1},\dots, J_{\lambda_r})$.
\end{definition}

\begin{theorem}[décomposition de \textsc{Jordan} des endomorphismes nilpotents - \textnormal{[M2] 144}]
	Supposons $u$ nilpotent d'indice $\lambda_1$.
	Il existe $\lambda_1 \geq \lambda_2 \geq \cdots \geq \lambda_r$
	telle que $\lambda_1 + \cdots + \lambda_r = n$, et $\mathcal{B}$ une base de $E$ telle que $\Mat_{\mathcal{B}}(u) = J_{\lambda_1,\dots,\lambda_r}$.
	Cette décomposition est unique.
\end{theorem}

\subsection*{B. Décomposition de \textsc{Dunford}}

\begin{theorem}[décomposition de \textsc{Dunford} - \textnormal{[M2] 141; [R] 613}]
	Si $u$ est trigonalisable, alors il existe un unique couple $(d,n)\in\mathcal{L}(E)^2$ tel que $u = d+n$, $d\circ n = n\circ d$, $d$ est diagonalisable et $n$ est nilpotent.
\end{theorem}

\begin{corollary}[\textnormal{[R] 634}]
	Sur $K =\IR$ ou $K=\IC$, $e^u$ est diagonalisable si, et seulement si, $u$ l'est.
\end{corollary}

\subsection*{C. Une application : le critère de diagonalisabilité de \textsc{Klarès}}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[critère de \textsc{Klarès} - \textnormal{[M2] 154}]
	\label{151dev2}
	Posons $ad_u\,\colon v\in\mathcal{L}(E) \mapsto u\circ v - v\circ u$.
	Si $u$ est trigonalisable, alors :
	$$u \text{ diagonalisable} \iff \Ker(ad_u) = \Ker(ad_u^2)$$
\end{theorem}
\end{tcolorbox}

\section*{Développements}
\begin{itemize}
	\item Développement 1 : Lemmes \ref{151dev11}, \ref{151dev12}, \ref{151dev13} et Théorème \ref{151dev14}.
	\item Développement 2 : Théorème \ref{151dev2}
\end{itemize}

\section*{Références}
\begin{itemize}
	\item[R] \emph{Mathématiques pour l'agrégation - Algèbre et géométrie}, Jean-Étienne Rombaldi, 2e édition
	\item[M2] \emph{Algèbre linéaire. Réduction des endomorphismes}, Roger Mansuy, Rached Mneimné, 3e édition
\end{itemize}




\chapter*{155 : Exponentielle de matrices. Applications.}
\setcounter{definition}{0}

\textcolor{paragraphtext}{Dans cette leçon, $\IK$ désigne $\IR$ ou $\IC$, $n\in \IN^*$
et $(A,B)\in\M_n(\IK)^2$. On fixe une norme d'algèbre $\|\cdot\|$ sur $\M_n(\IK)$.
On suppose connu et maîtrisé le calcul matriciel élémentaire.}

\begin{theorem_def}[\textnormal{[R] 761}]
	La série $\sum_{k\in\IN} \frac{A^k}{k!}$ converge normalement sur 
	tout compact. Sa somme est appelée \emph{exponentielle de $A$}, et est notée $\exp(A)$ ou $e^A$.
\end{theorem_def}

\begin{example}[\textnormal{[R] 761}]
	$\forall (\lambda_1,\dots,\lambda_n)\in\IK^n$, $\exp(\diag(\lambda_1,\dots,\lambda_n)) = \diag(e^{\lambda_1},\dots,e^{\lambda_n})$.
	En particulier, $\exp(0_n) = I_n$ et $\exp(I_n) = e\cdot I_n$.
\end{example}

\begin{example}
	$\forall \theta\in\IR$, $R(\theta) := \begin{pmatrix}
		\cos(\theta) & -\sin(\theta) \\ \sin(\theta) & \cos(\theta)
	\end{pmatrix} = \exp\left(\begin{pmatrix}
		0 & -\theta \\ \theta & 0
	\end{pmatrix}\right)$
\end{example}

\section*{I. Propriétés algébriques de l'exponentielle matricielle}
\begin{proposition}
	Si $A$ et $B$ commutent, alors $\exp(A+B) = \exp(A)\exp(B)$.
	(NB : la réciproque est vraie !) et $\exp(A)$ et $\exp(B)$ commutent.
\end{proposition}

\begin{cexample}
	$A = \begin{pmatrix}
		1 & 0 \\ 0 & -1
	\end{pmatrix}$ et $B = \begin{pmatrix}
		0&1\\0&0
	\end{pmatrix}$ ne commutent pas, et $e^A e^B = \begin{pmatrix}
		e&e\\0& 1/e
	\end{pmatrix} \neq \begin{pmatrix}
		e & 1/e \\ 0 & 1/e
	\end{pmatrix} = e^B e^A$.
\end{cexample}

\begin{corollary}
	$\exp(\M_n(\IK)) \subseteq GL_n(\IK)$, et $\exp(A)^{-1} = \exp(-A)$.
\end{corollary}

\begin{proposition}[\textnormal{[R] 761-762}]
	On a les propriétés suivantes :
	\begin{itemize}
		\item $\forall P\in GL_n(\IK)$, $P\exp(A)P^{-1}=\exp(PAP^{-1})$
		\item ${}^t\exp(A) = \exp({}^tA)$
		\item $\det(\exp(A)) = e^{\tr(A)}$
		\item $\overline{\exp(A)} = \exp(\overline{A})$
	\end{itemize}
\end{proposition}

\begin{corollary}
	$\exp(\mathcal{A}_n(\IK)) \subseteq O_n(\IK)$, avec $\mathcal{A}_n(\IK) = \left\{M\in\M_n(\IK)\mid {}^tM = -M\right\}$.
\end{corollary}

\begin{remark}
	On peut montrer que $\exp(\mathcal{A}_n(\IR)) = SO_n(\IR)$.
\end{remark}

\begin{proposition}
	Si $A$ est diagonalisable, alors $\Sp(\exp(A)) = \exp(\Sp(A))$.
\end{proposition}

\begin{theorem}
	On a :
	\begin{itemize}
		\item $\exp(A)\in \IK_{n-1}[A]$ et commute avec $A$.
		\item Si $A$ est diagonalisable et $\IK = \IR$, alors $A\in \IR_{n-1}[\exp(A)]$.
	\end{itemize}
\end{theorem}

\begin{remark}
	Pour $A = \begin{pmatrix}
		0&0\\0& 2i\pi
	\end{pmatrix}\in\M_2(\IC)$, on a $\exp(A) = I_2$ donc pour tout $P\in \IC[X]$, $P(\exp(A)) = P(1)I_2 \neq A$.
\end{remark}

\section*{II. L'exponentielle d'une matrice en pratique}
\subsection*{A. Quelques méthodes de calcul}

\begin{proposition}
	Supposons $A$ diagonalisable. Il existe $(\lambda_1,\dots, \lambda_n)\in\IK^n$ et $P\in O_n(\IK)$ tels que 
	$A = P\begin{pmatrix}
		\lambda_1 & & \\
		& \ddots & \\
		& & \lambda_n
	\end{pmatrix}P^{-1}$; alors $\exp(A) = P\begin{pmatrix}
		e^{\lambda_1} & & \\ & \ddots & \\ & & e^{\lambda_n}
	\end{pmatrix}P^{-1}$.
\end{proposition}

\begin{theorem}[décomposition de \textsc{Dunford} - \textnormal{[R] 613}]
	Si $A$ est trigonalisable, alors il existe un unique $(D,B)\in \M_n(\IK)^2$ tel que $D$ est diagonalisable, $N$ est nilpotente, $D$ et $N$ commutents, et $A = D+N$.
	De plus, $(D,N)\in K[A]^2$.
\end{theorem}

\begin{proposition}
	Si $A$ est nilpotente d'indice $r$, alors $\exp(A) = \sum_{k=0}^{r-1} \frac{A^k}{k!}$.
\end{proposition}

\begin{proposition}[\textnormal{[R] 765}]
	Si $A$ est trigonalisable, et si $A=D+N$ est la décomposition de \textsc{Dunford} de $A$,
	alors $e^A = e^D + e^D(e^N-I_n)$.

	En particulier, $e^D$ est diagonalisable et $e^D(e^N -I_n)$ est nilpotente, et ce sont les éléments de la décomposition de \textsc{Dunford} de $e^A$.
\end{proposition}

\begin{proposition}[\textnormal{[R] 778}]
	$\left(I_n + \frac{A}{k}\right)^k \to_{k\to +\infty} \exp(A)$
\end{proposition}

\begin{remark}
	Cela fournit une méthode pour approcher numériquement l'exponentielle d'une matrice, toutefois bien moins efficace qu'un calcul direct.
\end{remark}

\subsection*{B. Application : résolution d'EDO linéaires à coéfficients constants}
\begin{proposition}[\textnormal{[Gr] 378}]
	$t\mapsto e^{tA}$ est lisse sur $\IR$, de dérivée $t\mapsto Ae^{tA} = e^{tA}A$.
\end{proposition}

\begin{proposition}[\textnormal{[Gr] e378}]
	L'unique solution du problème de \textsc{Cauchy}
	$$\begin{cases}
		Y' = AY \\ Y(t_0) = Y_0
	\end{cases}$$
	pour $t_0\in \IR$, $Y\in\M_{n,1}(\IR)$, est $t\mapsto e^{(t-t_0)A}Y_0$.
\end{proposition}

\begin{example}
	Le problème de \textsc{Cauchy}
	$\begin{cases}
		Y' = \begin{pmatrix}
			1&1\\0&1
		\end{pmatrix}Y,\quad Y(0) = \begin{pmatrix}
			0\\1
		\end{pmatrix}
	\end{cases}$
	admet pour (unique) solution $t\mapsto \exp\left(t\begin{pmatrix}
		1&1\\0&1
	\end{pmatrix}\right)\begin{pmatrix}
		0\\1
	\end{pmatrix} = e^t\begin{pmatrix}
		1&t\\0&1
	\end{pmatrix}\begin{pmatrix}
		0\\1
	\end{pmatrix} = e^t\begin{pmatrix}
		t\\1
	\end{pmatrix}$.
\end{example}

\begin{proposition}[formule de \textsc{Duhamel}]
	Soient $B\,\colon \IR\to \M_{n,1}{\IR}$ continue, $t_0\in\IR$ et $Y_0\in\M_{n,1}(\IR)$.
	L'unique solution du problème de \textsc{Cauchy}
	$\begin{cases}
		Y' = AY + B ;\quad Y(t_0) = Y_0
	\end{cases}$ est 
	$$t\mapsto e^{(t-t_0)A}Y_0 + \int_{t_0}^t e^{(t-s)A}B(s)ds$$
\end{proposition}


\section*{III. Propriétés analytiques de l'exponentielle matricielle}
\subsection*{A. Injectivité, surjectivité}

\begin{theorem}[\textnormal{[R] 769}]
	L'application $\exp\,\colon \M_n(\IC)\to GL_n(\IC)$ est surjective, non injective.
\end{theorem}

\begin{cexample}
	$\forall k\in\IZ$, $\exp(2i\pi kI_n)= I_n$
\end{cexample}

\begin{theorem}
	L'application $\exp\,\colon \M_n(\IR)\to GL_n(\IR)$ n'est ni surjective, ni injective.
	Plus précisément,
	\begin{itemize}
		\item $\exp(\M_n(\IR)) = \left\{M^2 \mid M\in GL_n(\IR)\right\} \neq GL_n(\IR)$
		\item Exemple 3 justifie la non-injectivité
	\end{itemize}
\end{theorem}

\begin{remark}
	Comme $\det(\exp(A)) = e^{\tr (A)} > 0$, on a $\det^{-1}(\IR^-)\cap \exp(\M_n(\IR)) = \emptyset$.
\end{remark}

\begin{proposition}[\textnormal{[R] e768-777}]
	Notons $\mathcal{N}_n(\IR)$ l'ensemble des matrices nilpotentes de $\M_n(\IR)$.
	L'application $\exp\,\colon \mathcal{N}_n(\IR) \to GL_n(\IR)$ est injective.

	Notons $\Delta_n(\IR)$ l'ensemble des matrices diagonalisables de $\M_n(\IR)$.
	L'application $\exp\,\colon \Delta_n(\IR)\to  GL_n(\IR)$ est injective.
\end{proposition}

\begin{application}[\textnormal{[R] 777}]
	$\exp(A)$ est diagonalisable si, et seulement si, $A$ l'est.
\end{application}


\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[\textnormal{[C] 357}]
	\label{155dev1}
	L'application $\exp\,\colon S_n(\IR)\to S_n^{++}(\IR)$ est un homéomorphisme.
\end{theorem}
\end{tcolorbox}

\begin{theorem_def}[\textnormal{[R] 766-768}]
	Si $A\in \mathcal{B}(I_n, 1)$, alors $\sum_{n\geq 1}\left(-1\right)^{n-1}\frac{A^n}{n}$
	converge normalement sur tout compact. Sa somme est notée $\ln(I_n+A)$, et est appelée \emph{logarithme de $A$}.
\end{theorem_def}

\begin{remark}
	On a $\ln(I_n) = 0_n$.
\end{remark}

\begin{theorem}[ADMIS]
	L'application $\exp\,\colon \mathcal{N}_n(\IC)\to I_n + \mathcal{N}_n(\IC)$ est une 
	bijection de réciproque $\ln$.
\end{theorem}

\subsection*{B. Régularité}
\begin{theorem}[ADMIS - \textnormal{[Rv] 306}]
	$\exp$ est lisse sur $\M_n(\IR)$.
\end{theorem}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{proposition}
	\label{155dev2}
	La différentielle de $\exp$ en $X\in\M_n(\IR)$ est :
	$$d(\exp)(X)\,\colon H\mapsto \left(\sum_{n=0}^{+\infty}\frac{[\cdot, X]^n}{(n+1)!}\right)(H)$$
	où $[\cdot, X]\,\colon H \mapsto [H, X] = HX - XH$.
\end{proposition}
\end{tcolorbox}

\begin{corollary}
	$\exp$ induit un $C^1$-difféomorphisme local d'un voisinage de $0_n$ sur un voisinage de $I_n$.
\end{corollary}

\section*{Développements}
\begin{itemize}
	\item Développement 1 : Théorème \ref{155dev1}
	\item Développement 2 : Proposition \ref{155dev2}
\end{itemize}

\section*{Références}
\begin{itemize}
	\item[R] \emph{Mathématiques pour l'agrégation - Algèbre et géométrie}, Jean-Étienne Rombaldi, 2e édition
	\item[C] \emph{Nouvelles histoires hédonistes de groupes et géométries I}, P. Caldero, J. Germoni
	\item[Gr] \emph{Algèbre linéaire}, Joseph Grifone, 6e édition, 2e version
	\item[Rv] \emph{Petit guide du calcul différentiel}, François Rouvière, 4e édition
\end{itemize}


\chapter*{156 : Endomorphismes trigonalisables. Endomorphismes nilpotents.}
\setcounter{definition}{0}
\textcolor{paragraphtext}{Dans cette leçon, $K$ désigne un corps, $E$ est un $K$-espace vectoriel de dimension finie $n$, et $u\in\mathcal{L}(E)$.}

\section*{I. Rappels sur l'étude des endomorphismes}

\begin{theorem}[de structure - \textnormal{[M2] 2}]
	L'application $\varphi_u\,\colon K[X]\to \mathcal{L}(E)$ qui à 
	$P = \sum a_kX^k$ associe $P(u) := \sum a_k u^k$, est un morphisme de $K$-algèbres.
\end{theorem}

\begin{proposition_def}[\textnormal{[M2] 3,4}]
	L'ensemble $I_u = \Ker(\varphi_u)$ des polynômes dits \emph{annulateurs de $u$}, est un idéal de $K[X]$,
	appelé \emph{idéal annulateur de $u$}. Il n'est pas réduit à $\left\{0\right\}$, et 
	donc admet un unique générateur unitaire, noté $\mu_u$, appelé \emph{polynôme minimal de $u$}.
\end{proposition_def}

\begin{remark}
	Par correspondance entre $\mathcal{L}(E)$ et $\M_n(K)$, ces résultats restent valables pour les matrices.
\end{remark}

\begin{definition}[\textnormal{[M2] 54}]
	Le \emph{polynôme caractéristique de $u$} est définie par $\chi_u = \det(X\id_E - u)$.
\end{definition}

\begin{theorem}[de \textsc{Cayley-Hamilton} - \textnormal{[M2] 81}]
	$\chi_u(u) = 0_{\mathcal{L}(E)}$
\end{theorem}

\begin{proposition}[\textnormal{[R] 605}]
	$\Sp(u) = \chi^{-1}(\left\{0\right\}) = \pi^{-1}(\left\{0\right\})$
\end{proposition}

\begin{proposition}[\textnormal{[M2] 55 ?}]
	Soit $F$ un sous-espace vectoriel de $E$ stable par $u$.
	Notons $u_F\in\mathcal{L}(E)$ l'nedomorphisme induit par $u$ sur $F$. Alors $\pi_{u_F} \mid \pi_u$ et $\chi_{u_F} \mid \chi_u$.
\end{proposition}

\begin{proposition}[\textnormal{[M2] 18-55}]
	Si $E = F_1\bigoplus \cdots\bigoplus F_r$ est une décomposition de $E$ en sous-espaces stables par $u$,
	alors $\chi_u = \chi_{u_{F_1}} \cdots \chi_{u_{F_r}}$ et $\pi_u = \pi_{u_{F_1}} \vee \cdots \vee \pi_{u_{F_r}}$.
\end{proposition}

\begin{lemma}[des noyaux - \textnormal{[M2] 43}]
	Soit $(P,Q)\in K[X]^2$. Si $P\wedge Q = 1$, alors
	$\Ker\left(\left(PQ\right)(u)\right) = \Ker(P(u))\bigoplus\Ker(Q(u))$.
\end{lemma}

\section*{II. Trigonalisation}

\begin{definition}[\textnormal{[R] 675}]
	On dit que $u$ est \emph{trigonalisable} s'il existe une base $\mathcal{B}$ de $E$ telle que $\Mat_{\mathcal{B}}(u)$ est triangulaire.
\end{definition}

\begin{corollary}[\textnormal{[R] 676}]
	Si $u$ est trigonalisable, alors $\tr(u) = \sum_{\lambda\in\Sp(u)} m(\lambda)\lambda$ et $\det(u) = \prod_{\lambda\in\Sp(u)} \lambda^{m(\lambda)}$.
\end{corollary}

\begin{theorem}[\textnormal{[R] 676}]
	$u$ est trigonalisable $\iff$ $\pi_u$ est scindé $\iff$ il existe $P\in I_u$ scindé.
\end{theorem}

\begin{corollary}[\textnormal{[R] 676}]
	Sur un corps algébriquement clos, tout endomorphisme est trigonalisable.
\end{corollary}

\begin{example}
	$\begin{pmatrix}
		0&1\\-1&0
	\end{pmatrix}$ est trigonalisable sur $\IC$ mais pas sur $\IR$.
\end{example}

\begin{application}[\textnormal{[R] 762}]
	$\forall A\in \M_n(\IC)$, $\det(e^A) = e^{\tr(A)}$.
\end{application}

\begin{proposition}
	Si $F$ est un sous-espace vectoriel stable par $u$ et si $u$ est trigonalisable, alors $u_f\,\colon F\to F$ est trigonalisable.
\end{proposition}

\begin{proposition}
	Si $A\in\M_n(K)$ s'écrit par blocs $\diag(A_1,\dots,A_r)$,
	alors $\chi_A = \chi_{A_1}\cdots \chi_{A_r}$ et $\pi_A = \pi_{A_1}\vee \cdots \vee \pi_{A_r}$.
\end{proposition}

\begin{proposition}[\textnormal{[Go] 175}]
	Soit $v\in \mathcal{L}(E)$. Si $u$ et $v$ commutent, alors popur tout $\lambda\in\Sp(u)$, $E_{\lambda}(u)$ est stable par $v$.
\end{proposition}

\begin{theorem}[\textnormal{[R] 678}]
	Soit $\left(u_i\right)_{i\in I}\in\mathcal{L}(E)^I$ une famille d'endomorphismes qui commutent deux à deux. Si les $u_i$, $i\in I$, sont tous trigonalisables, alors ils le sont dans une même base (on dit qu'ils sont \emph{cotrigonalisables}).
\end{theorem}

\begin{proposition}[\textnormal{[Go] e192}]
	Soit $v\in\mathcal{L}(E)$. Si $u$ et $v$ sont cotrigonalisables, alors $u+v$ et $u\circ v$ sont trigonalisables.
\end{proposition}

\begin{example}
	On a :
	\begin{itemize}
		\item $\left(\begin{smallmatrix}
			0& -1\\ 0 & 0
		\end{smallmatrix}\right)$ et $\left(\begin{smallmatrix}
			0& 1\\ 0 & 0
		\end{smallmatrix}\right)$ sont trigonalisables, mais pas leur somme.
		\item $\left(\begin{smallmatrix}
			0& 1\\ 1 & 0
		\end{smallmatrix}\right)$ et $\left(\begin{smallmatrix}
			1 & 1\\ 0 & -1
		\end{smallmatrix}\right)$ sont trigonalisables, mais pas leur produit.
	\end{itemize}
\end{example}

\section*{III. Endomorphismes nilpotents}
\subsection*{A. Définition, critères, propriétés}

\begin{definition}[\textnormal{[Gr] 93}]
	On dit que $u$ est \emph{nilpotent} s'il existe $k\in\IN^*$ tel que $u^k=0_{\mathcal{L}(E)}$.
	On définit alors \emph{l'indice (de nilpotence) de $u$} comme $\min\left\{k\in\IN^*\mid u^k = 0_{\mathcal{L}(e)}\right\}$.
\end{definition}

\begin{example}
	La dérivation de $\IC_n[X]$ est nilpotente d'indice $n+1$.
\end{example}

\begin{proposition}[\textnormal{[Gr] e192}]
	Soit $v\in\mathcal{L}(E)$ nilpotent. Si $u$ et $v$ commutent, alors $u+v$ et $u\circ v$ sont nilpotents.
\end{proposition}

\begin{theorem}
	Les assertions suivantes sont équivalentes :
	\begin{itemize}
		\item $u$ est nilpotent
		\item $\chi_u = X^n$
		\item $\exists k\in \llbracket 1,n\rrbracket$, $\pi_u = X^p$
		\item $u$ est trigonalisable et $\Sp(u) = \left\{0\right\}$.
	\end{itemize}
\end{theorem}

\begin{corollary}
	Si $K$ est algébriquement clos, alors $u$ est nilpotent $\iff \Sp(u)=\left\{0\right\}$. 
\end{corollary}

\begin{example}
	$\left(\begin{smallmatrix}
		0&0&0\\ 0&0&-1 \\ 0&1&0
	\end{smallmatrix}\right)$ n'est pas nilpotente, mais son spectre est $\left\{0\right\}$.
\end{example}

\begin{theorem}[\textnormal{[C] 27-32}]
	Si $K=\IR$, alors $u$ est nilpotent $\iff$ $\forall k\in \IN^*$, $\tr(u^k) = 0$.
\end{theorem}

\begin{remark}
	Si $K$ est un corps fini, le résultat est faux : considérer $\id_{\left(\IF_p\right)^p}$.
\end{remark}

\begin{proposition}
	Si $F$ est un sous-espace vectoriel stable par $u$ et si $u$ est nilpotent, alors $u_F\,\colon F\to F$ est nilpotent.
\end{proposition}

\subsection*{B. Réduction de \textsc{Jordan} des endomorphismes nilpotents}

\begin{notation}[\textnormal{[M2] 143}]
	Posons $$J_r := \begin{pmatrix}
		0 & 1 & \cdots & 0 \\
		\vdots & \ddots & \ddots & \vdots \\
		\vdots & & \ddots & 1 \\
		0 & \cdots & \cdots & 0
	\end{pmatrix}$$

	On l'appelle \emph{bloc de \textsc{Jordan}} d'ordre $r$.
\end{notation}

\begin{lemma}[\textnormal{[R] 678}]
	Supposons $u$ nilpotent d'indice $p$. Soit $x\notin \Ker(u^{p-1})$, posons $F_x = \Vect(x, u(x), \dots, u^{p-1}(x))$.
	\begin{itemize}
		\item $F_x$ est stable par $u$ et $(x,u(x),\dots,u^{p-1}(x))$ est une base de $F_x$ ;
		\item $F_x$ admet un supllémentaire stable par $u$.
	\end{itemize}
\end{lemma}

\begin{theorem}[réduction de \textsc{Jordan}]
	Supposons $u$ nilpotent. Il existe $d_1\geq \cdots\geq d_r$ et une base $\mathcal{B}$ de $E$ tels que $\Mat_{\mathcal{B}}(u) = \diag(J_{d_1},\dots,J_{d_r})$.
\end{theorem}

\begin{proposition}
	Posons $A = \diag(J_{i_1},\dots,J_{i_r})$. On a $\chi_A = \pi_A = X^{i_r}$, et $A$ est nilpotente d'indice $r$.
\end{proposition}

\subsection*{C. Noyaux itérés et tableaux de \textsc{Young}}

\begin{proposition}[\textnormal{[M2] 16}]
	La suite $\left(\Ker(u^k)\right)_{k\in\IN}$ est croissante et stationnaire, et si on note $d_k = \dim(\Ker(u^k))$, on a $\forall k\in \IN$, $d_{k+1} = d_k + \dim(\Ker(u)\cap \im(u^k))$.
\end{proposition}

\begin{proposition}[\textnormal{[M2] 16}]
	$\left(d_{k+1}-d_k\right)_{k\in\IN}$ est décroissante (on dit que $\left(d_k\right)_{k\in\IN}$ \emph{s'essouffle}).
\end{proposition}

\begin{proposition}[\textnormal{[Gr] 93}]
	$p=\min\left\{k\in \IN\mid \forall q\geq k,\, \Ker(u^q)=\Ker(u^k)\right\}$ est appelé \emph{caractère de $u$}.
	Il vérifie $p\leq n$. Si $u$ est nilpotent, alors $p$ est aussi l'indice de nilpotence de $u$.
\end{proposition}

\begin{definition}[\textnormal{[M2] 147}]
	\begin{itemize}
		\item Le \emph{tableau de \textsc{Young}} associé à une suite d'entiers $n_1\geq \cdots \geq n_r$ est le tableau à $r$ lignes tel que la $i$-ième ligne contient $n_i$ cases (alignées à gauche).
		\item Le \emph{tableau de \textsc{Young}} d'un endomorphisme nilpotent est le tableau de \textsc{Young} de $d_2-d_1\geq d_3-d2\geq \cdots \geq d_p - d_{p-1}$ avec les notations ci-dessus.
	\end{itemize}
\end{definition}

\begin{example}
	FIGURE 1.
\end{example}

\begin{proposition}
	Soit $d_1\geq \cdots\geq d_r$. La matrice par blocs $\diag(J_{d_1},\dots,J_{d_r})$ est nilpotente d'indice $d_1$.
\end{proposition}

\begin{example*}[Construction du tableau de \textsc{Young} à partir de la réduite de \textsc{Jordan}]
	[\textnormal{[M2] 147}]
	FIGURE 2. A PRESENTER.
\end{example*}

\begin{theorem}[\textnormal{[M2] 148}]
	Deux endomorphismes nilpotents sont semblables si, et seulement si, ils ont la même réduction de \textsc{Jordan}.
\end{theorem}

\begin{corollary}
	Il y a autant de classes de similitude de matrices nilpotentes que de partitions de $n$.
\end{corollary}


\section*{IV. Décomposition de \textsc{Dunford} et applications}
\textcolor{paragraphtext}{Dans cette section, $\IK$ désigne $\IR$ ou $\IC$.}


\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[décomposition de \textsc{Dunford} - \textnormal{[R] 683}]
	\label{156dev11}
	Si $\chi_u$ est scindé, alors il existe un unique $(d,n)\in\mathcal{L}(E)^2$ tel que $d$ est diagonalisable, $n$ nilpotent, $d$ et $n$ commutent et $u = d + n$.
	De plus, $(d,n)\in K[u]^2$.
\end{theorem}

\begin{application}[\textnormal{[R] 684}]
	\label{156dev12}
	Soit $A\in\M_n(\IK)$ tel que $\chi_A$ est scindé. Soit $A = D+N$ sa
	décomposition de \textsc{Dunford}. Il existe $P\in GL_n(\IK)$ et $(\lambda_1,\dots,\lambda_n)\in\IK^n$ tels que 
	$P^{-1}DP = \diag(\lambda_1,\dots, \lambda_n)$. On a alors :
	$$e^A = P\diag(e^{\lambda_1},\dots, e^{\lambda_n})P^{-1}\sum_{k=0}^{n-1}\frac{N^k}{k!}$$
\end{application}
\end{tcolorbox}

\begin{example}
	$\exp\left(\begin{smallmatrix}
		1&1&0\\0&1&1\\0&0&1
	\end{smallmatrix}\right) = \exp\left(I_3 + J_3\right) = \left(\begin{smallmatrix}
		e&e&e/2 \\ 0&e&e \\ 0&0&0
	\end{smallmatrix}\right)$
\end{example}

\begin{application}
	$\left\{Y\in C^1(\IR,\IK^n)\mid Y' = AY\right\} = \left\{t\mapsto e^{tA}Y_0\mid Y_0\in \IK^n\right\}$
\end{application}


\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[critère de \textsc{Klarès} - \textnormal{[M2 154]}]
	\label{156dev2}
	Si $u\in \mathcal{L}(E)$ est trigonalisable, alors $u$ est diagonalisable si, et seulement si, $ad_u\,\colon v\in\mathcal{L}(E)\mapsto u\circ v - v\circ u$ l'est.
\end{theorem}
\end{tcolorbox}

\section*{Développements}
\begin{itemize}
	\item Développement 1 : Théorème \ref{156dev11} et application \ref{156dev12}
	\item Développement 2 : Théorème \ref{156dev2}
\end{itemize}

\section*{Références}
\begin{itemize}
	\item[Gr] \emph{Algèbre linéaire}, Joseph Grifone, 6e édition, 2e version
	\item[M2] \emph{Algèbre linéaire. Réduction des endomorphismes}, Roger Mansuy, Rached Mneimné, 3e édition
	\item[R] \emph{Mathématiques pour l'agrégation - Algèbre et géométrie}, Jean-Étienne Rombaldi, 2e édition
	\item[Go] \emph{Les maths en tête - Algèbre et probabilités}, Xavier Gourdon, 3e édition
	\item[C] \emph{Carnet de voyage en Algébrie}, Philippe Caldero, Marie Peronnier
\end{itemize}
\begin{figure}[!htb]
	\centering
	\includegraphics[trim={0 0 0 0},clip,width=1\linewidth]{img/156.pdf}
	\caption{s}
\end{figure}

\chapter*{157 : Matrices symétriques réelles, matrices hermitiennes.}
\setcounter{definition}{0}
\textcolor{paragraphtext}{Dans cette leçon, $\IK$ désigne $\IR$ ou $\IC$.
On fixe $n\in\IN^*$. Pour $A\in \M_n(\IK)$, on pose $A^*={}^t\overline{A}$.
Soient $E$ un $\IK$-espace vectoriel de dimension finie $n$, soit $\B=\left\{e_1,\dots,e_n\right\}$
une base de $E$.}

\section*{I. Généralités}
\subsection*{A. Définitions et premières propriétés}

\begin{definition}[\textnormal{[Go] 240-241}]
	On définit :
	\begin{itemize}
		\item $\mathcal{S}_n(\IR) = \left\{A\in\M_n(\IR)\mid {}^tA=A\right\}$ est l'ensemble des matrices réelles dites \emph{symétriques} ;
		\item $\A_n(\IR) = \left\{A\in\M_n(\IR)\mid {}^tA=-A\right\}$ est l'ensemble des matrices réelles dites \emph{anti-symétriques} ;
		\item $\mathcal{H}_n(\IR) = \left\{A\in\M_n(\IC)\mid {}^t\overline{A} = A\right\}$ est l'ensemble des matrices complexes dites \emph{hermitiennes} ;
		\item On dit que $A$ est \emph{auto-adjointe} si $A=A^*$, \emph{i.e.} si $A\in \mathcal{S}_n(\IR)$ ou $A\in\mathcal{H}_n(\IC)$.
	\end{itemize}
\end{definition}

\begin{example}
	$\left(\begin{smallmatrix}
		0&1\\1&0
	\end{smallmatrix}\right)\in\mathcal{S}_2(\IR)$ et 
	$\left(\begin{smallmatrix}
		0&-i\\i&1
	\end{smallmatrix}\right)\in\mathcal{H}_2(\IC)$.
\end{example}

\begin{proposition}[\textnormal{[Go] 240-241}]
	$\M_n(\IR) = \mathcal{S}_n(\IR)\bigoplus\A_n(\IR)$
	et $\M_n(\IC) = \mathcal{S}_n(\IC)\bigoplus i\A_n(\IR)$.
\end{proposition}

\begin{definition}
	On définit :
	\begin{itemize}
		\item $\mathcal{S}_n^+(\IR) = \left\{A\in\mathcal{S}_n(\IR)\mid \forall X\in\IRn,\,{}^tXAX \geq 0\right\}$ est l'ensemble des matrices symétriques réelles dites \emph{positives}.
		\item $\mathcal{S}_n^{++}(\IR) = \left\{A\in\mathcal{S}_n^+(\IR)\mid \forall X\in\IRn,\,{}^tXAX = 0\implies X=0\right\}$ l'ensemble des matrices symétriques réelles dites \emph{définies positives}.
		\item $\mathcal{H}_n^+(\IC) = \left\{A\in\mathcal{H}_n(\IC)\mid \forall X\in\IC^n,\,{}^t\overline{X}AX \geq 0\right\}$ est l'ensemble des matrices hermitiennes dites \emph{positives}.
		\item $\mathcal{H}_n^{++}(\IC) = \left\{A\in\mathcal{H}_n(\IC)\mid \forall X\in\IC^n,\,{}^t\overline{X}AX = 0\implies X=0\right\}$ est l'ensemble des matrices hermitiennes dites \emph{définies positives}.
	\end{itemize}
\end{definition}

\subsection*{B. Lien avec les formes quadratiques / hermitiennes}

\begin{definition}[\textnormal{[Go] 240-241}]
	Soit $\varphi\,\colon E^2\to \IR$ une forme bilinéaire. On dit que $\varphi$ est \emph{symétrique} si 
	$\forall(x,y)\in E^2,\, \varphi(x,y)=\varphi(y,x)$. Le cas échéant, $q\,\colon x\in E \mapsto \varphi(x,x)$ est appelée \emph{forme quadratique associée à $\varphi$},
	et $\varphi$ est appelée \emph{forme polaire associée à $q$} (elle est alors unique).
\end{definition}

\begin{definition}
	Soit $\varphi\,\colon E^2\to\IC$ une forme sesquilinéaire (on prend l'antilinéarité à droite).
	On dit que $\varphi$ est \emph{hermitienne} si $\forall(x,y)\in E^2,\,\varphi(x,y)=\overline{\varphi(y,x)}$.
	Le cas échéant, $q\,\colon x\in E\mapsto \varphi(x,x)$ est appelée \emph{forme hermitienne associée à $\varphi$}, et $\varphi$ est appelée \emph{forme polaire associée à $q$} (elle est alors unique).
\end{definition}

\begin{example}[\textnormal{[Go] 239}]
	\begin{itemize}
		\item $(f,g)\mapsto\int_{0}^{1}f\overline{g}$ est une forme sesquilinéaire hermitienne sur $C^0([0,1],\IC)$, et induit une forme bilinéaire symétrique sur $C^0([0,1],\IR)$.
		\item $(X,Y)\mapsto {}^t\overline{X}Y$ est bilinéaire symétrique ou sesquilinéaire hermitienne sur $\IK^n$.
	\end{itemize}
\end{example}

\begin{proposition}[\textnormal{[Go] e241}]
	Soit $\varphi\,\colon E^2\to \IK$ bilinéaire ou sesquilinéaire. On définit la \emph{matrice de $\varphi$ dans $\B$} comme $\Mat_{\B}(\varphi):= \left(\varphi(e_i,e_j)\right)_{i,j}$.
	Pour $x$ et $y$ dans $E$, de vecteurs coordonées $X$ et $Y$, on a alors $\varphi(x,y)={}^t\overline{X}\cdot \Mat_{\B}(\varphi)\cdot Y$ en identifiant $\IK$ et $\M_{n,1}(\IK)$.
	Alors, 
	\begin{itemize}
		\item $\varphi$ est symétrique si, et seulement si, $\Mat_{\B}(\varphi)\in \mathcal{S}_n(\IR)$
		\item $\varphi$ est hermitienne si, et seulement si, $\Mat_{\B}(\varphi)\in \mathcal{H}_n(\IC)$
	\end{itemize}
\end{proposition}

\begin{proposition}[\textnormal{[R] 163}]
	Soit $\B'$ une autre base de $E$. Si $P$ est la matrice de passage de $\B$ à $\B'$, alors $\Mat_{\B'}(\varphi)={}^t\overline{P}AP$.
\end{proposition}

\begin{proposition}
	$\forall A\in\mathcal{S}_n(\IR)\cup \mathcal{H}_n(\IC)$, $\Sp(A)\subseteq \IR$.
\end{proposition}

\section*{II. Réduction des matrices symétriques / hermitiennes}
\subsection*{A. Orthogonalité et théorème spectral}
\textcolor{paragraphtext}{Soit $q$ une forme quadratique ou hermitienne sur $E$, de forme polaire $\varphi$. On pose $A =\Mat_{\B}(\varphi)$.}

\begin{definition}[\textnormal{[Go] 243}]
	On dit que $\B$ est \emph{$q$-orthogonale} si $\forall(i,j)\in\llbracket 1,n\rrbracket$, $i\neq j\implies \varphi(e_i, e_j) = 0$, \emph{i.e.} si $A$ est diagonale.
\end{definition}


\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[spectral - \textnormal{[Go] 256}]
	\label{157dev11}
	Pour toute $M\in\mathcal{S}_n(\IR)$ (resp. $M\in\mathcal{H}_n(\IC)$),
	il existe $P$ orthogonale (resp. unitaire) (\emph{i.e.} $P^{-1} = P^*$) telle que $P^*MP$ est diagonale.
\end{theorem}
\begin{theorem}[\textnormal{[Go] 243}]
	\label{157dev12}
	Il existe une base $q$-orthogonale de $E$.
\end{theorem}
\end{tcolorbox}

\begin{application}
	Soit $A\in\mathcal{S}_n(\IR)$. Alors :
	\begin{itemize}
		\item $A\in\mathcal{S}_n^+(\IR)\iff \Sp(A)\subseteq \IR^+$ ;
		\item $A\in\mathcal{S}_n^{++}(\IR) \iff \Sp(A)\subseteq \IR^{+*}$
	\end{itemize}
\end{application}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}
	\label{157dev13}
	$\forall A\in \mathcal{S}_n^{++}(\IR)$, $\forall B\in \mathcal{S}_n(\IR)$, $\exists P\in GL_n(\IR)$ tels que 
	${}^tPAP=I_n$ et ${}^tPBP$ est diagonale.
\end{theorem}
\end{tcolorbox}

\begin{theorem}
	$\forall A\in \mathcal{S}_n^+(\IR)$, $\exists ! B\in\mathcal{S}_n^+(\IR)$ : $A=B^2$ (on note $B = \sqrt{A}$).
\end{theorem}

\begin{theorem}[décomposition polaire - \textnormal{[C] 348}]
	Toute matrice $A$ (inversible) se décompose (de manière unique)
	sous la forme $A=\Theta S$, où $\Theta\in \mathcal{O}_n(\IR)$ et $S\in\mathcal{S}_n^{++}(\IR)$.
\end{theorem}

\subsection*{B. Réduction de \textsc{Gauss} et signature d'une forme quadratique / hermitienne}

\begin{theorem}[réduction de \textsc{Gauss} - \textnormal{[R] 469}]
	Il existe des formes linéaires $l_1,\dots, l_r$ linéairement indépendantes et $(\lambda_1,\dots,\lambda_n)\in\IK^r$ tels que $q = \lambda_1 \vert l_1\vert^2 + \dots + \lambda_r \vert l_r\vert^2$.
\end{theorem}

\begin{example}
	\label{157ex19}
	$q(x,y,z) = x^2+2xy-yz+\frac{3}{q}z^2=(x+y)^2 -(y+\frac{1}{2})^2 + z^2$
\end{example}

\begin{theorem}[loi d'inertie de \textsc{Sylvester} - \textnormal{[R] 477}]
	Supposons que $\IK = \IR$, soit $\B=(e_1,\dots,e_n)$ une base $q$-orthogonale de $E$.
	Les entiers $s = \#\left\{e_i\in\B \mid q(e_i)> 0\right\}$ et $t = \#\left\{e_i\in\B\mid q(e_i)<0\right\}$
	ne dépendent que de $q$. Le couple $(s,t)$ est appelé \emph{signature de $q$}.
\end{theorem}

\begin{example}
	La forme quadratique de l'exemple \ref{157ex19} a pour signature $(2,1)$.
\end{example}

\begin{corollary}[\textnormal{[R] 207}]
	Les orbites de l'action de $GL_n(\IR)$ sur $\mathcal{S}_n(\IR)$ par congruence sont caractérisées par le rang et la signature.
\end{corollary}

\section*{III. Propriétés topologiques en lien avec $\mathcal{S}_n(\IR)$}

\begin{definition}
	Pour $A\in\M_n(\IK)$, on pose $\exp(A)=\sum_{k=0}^{+\infty} \frac{A^k}{k!}$.
\end{definition}

\begin{example}
	$\forall (\lambda_1,\dots,\lambda_n)\in\IK^n$, $\exp(\diag(\lambda_1,\dots,\lambda_n)) = \diag(e^{\lambda_1},\dots, e^{\lambda_n})$.
\end{example}


\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[\textnormal{[C] 357}]
	\label{157dev2}
	On a que $\exp\,\colon \mathcal{S}_n(\IR)\to \mathcal{S}_n^{++}(\IR)$ est un homéomorphisme.
\end{theorem}
\end{tcolorbox}

\section*{IV. Applications}
\subsection*{A. Vecteurs gaussiens}

\textcolor{paragraphtext}{Soit $(\Omega,\A,\IP)$ un espace probabilisé. On note $\langle\cdot\mid\cdot\rangle$ le produit scalaire canonique sur $\IR^n$.}

\begin{definition}[\textnormal{[CR] 160,157,158}]
	Un vecteur aléatoire $X=(X_1,\dots, X_n)\,\colon (\Omega,\A,\IP)\to (\IR^n,\B(\IR^n))$ est un \emph{vecteur gaussien} si pour tout $u\in\IR^n$, $\langle u\mid X\rangle$
	suit une loi normale (réelle). On note alors $X\sim \mathcal{N}_n(m,\Gamma)$ où $m = {}^t(\IE[X_1],\dots, \IE[X_n])$ est l'espérance de $X$, 
	et $\Gamma = \left(\Cov(X_i,X_j)\right)_{1\leq i,j\leq n}\in\mathcal{S}_n^+(\IR)$ sa matrice de covariance.
\end{definition}

\begin{example}[\textnormal{[CR] 160}]
	Si $X_1,\dots,X_n$ sont indépendantes de loi $\mathcal{N}(0,1)$, alors $\begin{pmatrix}
		X_1 \\ \vdots \\ X_n
	\end{pmatrix}\sim \mathcal{N}(0_n, I_n)$.
\end{example}

\begin{theorem}[\textnormal{[CR] 160}]
	Une variable aléatoire $X$ est gaussienne si, et seulement s'il existe $m\in\IR^m$ et $\Gamma\in\mathcal{S}_n^+(\IR)$ tels que :
	$$\forall u\in\IR^n,\,\varphi_X(u) = \exp(i\langle m,u\rangle - \frac{1}{2}\langle\Gamma u, u\rangle)$$

	Le cas échéant, $m$ est l'espérance, et $\Gamma$ sa matrice de covariance.
\end{theorem}

\begin{corollary}
	La loi d'un vecteur gaussien est entièrement déterminée par son espérance et sa matrice de covariance.
\end{corollary}

\begin{proposition}[\textnormal{[CR] 161}]
	Si $X\sim \mathcal{N}_n(m,\Gamma)$, alors $\forall A\in\M_{p,n}(\IR),\,\forall b\in\IR^p,\, AX+b\sim \mathcal{N}_p(Am+b, A\Gamma {}^tA)$.
\end{proposition}

\begin{proposition}
	$\forall\Gamma\in \mathcal{S}_n^{++}(\IR),\,\exists c\in\M_n(\IR)$ tels que $\Gamma = {}^tCC$.
\end{proposition}

\begin{corollary}[\textnormal{[CR] 161}]
	Pour tous $m\in\IR^n$ et $\Gamma\in\mathcal{S}_n(\IR)$, il existe un vecteur gaussien de loi $\mathcal{N}_n(m,\Gamma)$.
\end{corollary}

\begin{theorem}
	Soient $m\in\IR^n$, $\Gamma\in\mathcal{S}_n^+(\IR)$ et $X\sim\mathcal{N}_n(m,\Gamma)$.
	Alors $X$ est à densité $\iff$ $\Gamma\in\mathcal{S}_n^{++}(\IR)$.
	
	Le cas échéant, $\forall u\in \IR^n$, $f_X(u) = \left(2\pi\right)^{-\frac{n}{2}}\det(\Gamma)^{-\frac{1}{2}}\exp\left(-\frac{1}{2}\langle\Gamma^{-1}(u-m)\mid u-m\rangle\right)$.
\end{theorem}

\subsection*{B. Optimisation des fonctions de plusieurs variables}

\textcolor{paragraphtext}{Soit $f\,\colon \IR^n\to \IR$ de classe $C^2$.}

\begin{definition}[\textnormal{[Rv] 294}]
	On appelle \emph{(matrice) hessien de $f$ en $a$} la matrice $\Hess_a(f) = \left(\frac{\partial^2 f}{\partial e_i\partial e_j}(a)\right)_{1\leq i,j\leq n}$.
\end{definition}

\begin{remark}
	$\Hess_a(f)$ est la matrice dans $\B$ de la forme bilinéaire $d^2f(a)$ : en particulier, pour tous $h = \begin{pmatrix}
		h_1 \\ \vdots \\ h_n
	\end{pmatrix}\in \IR^n$, $d^2f(a)(h)(k) = {}^th\cdot\Hess_a(f)\cdot k$.
\end{remark}

\begin{definition}[\textnormal{[Go] 336}]
	On dit que $a$ est un \emph{point critique} si $df(a)=0$.
\end{definition}

\begin{theorem}[\textnormal{[Go] 335-336}]
	Si $f$ admet un maximum (resp. un minimum) local en $a$, alors $a$ est un point critique, et $\Hess_a(f)$ est négative (resp. positive).

	NB : la réciproque est vraie si on suppose en plus $\Hess_a(f)$ définie.
\end{theorem}

\begin{algorithm}[de descente de gradient à pas fixe]
	Soient $\Omega$ un ouvert de $\IR^n$, $f\in C^1(\Omega, \Omega)$, $\alpha > 0$ et $x_0\in\Omega$.
	La suite définie par $\forall n\in\IN$, $x_{n+1} = x_n - \alpha\nabla f(x_n)$ converge vers un $x^*\in\Omega$ vérifiant $\nabla f(x^*)$.
\end{algorithm}

\begin{theorem}[\textnormal{[BMP] 24-32}]
	Soient $A\in\mathcal{S}_n^{++}(\IR)$ et $b\in\IR^n$.
	La solution de $Ax=b$ est donné par le minimum de $x\mapsto \frac{1}{2}\langle Ax, x\rangle - \langle b,x\rangle$, lequel peut être trouvé par descente de gradient.
\end{theorem}



\section*{Développements}
\begin{itemize}
	\item Développement 1 : Partie 1) Théorèmes \ref{157dev11} et \ref{157dev12}; Partie 2) Théorème \ref{157dev13}
	\item Développement 2 : Théorème \ref{157dev2}
\end{itemize}

\section*{Références}
\begin{itemize}
	\item[R] \emph{Mathématiques pour l'agrégation - Algèbre et géométrie}, Jean-Étienne Rombaldi, 2e édition
	\item[Go] \emph{Les maths en tête - Algèbre et probabilités}, Xavier Gourdon, 3e édition
	\item[C] \emph{Carnet de voyage en Algébrie}, Philippe Caldero, Marie Peronnier
	\item[CR] \emph{Probabilités et statistiques pour l'épreuve de modélisation à l'agrégation de mathématiques}, Marie-Line Chabanol, Jean-Jacques Ruch
	\item[Rv] \emph{Petit guide du calcul différentiel}, François Rouvière, 4e édition
	\item[BMP] \emph{Objectif Agrégation}, Vincent Beck, Jérôme Malick, Gabriel Peyré, 2e édition
\end{itemize}

\chapter*{159 : Formes linéaires et dualité en dimension finie. Exemples et applications.}
\setcounter{definition}{0}

\textcolor{paragraphtext}{Dans cette leçon, $K$ désigne un corps, $\IK$ désigne $\IR$ ou $\IC$, $E$ est un espace vectoriel de dimension finie $n\geq 1$, et $\B=\left\{e_1,\dots, e_n\right\}$ est une base de $E$.}

\section*{I. Formes linéaires, espace dual}
\subsection*{A. Généralités sur les formes linéaires}

\begin{definition}[\textnormal{[R] 441}]
	Une \emph{forme linéaire sur $E$} est une application linéaire de $E$ dans $K$.
	On note $E^*$ l'ensemble des formes linéaires sur $E$, et on l'appelle \emph{(espace) dual de $E$}.
\end{definition}

\begin{example}[\textnormal{[R] 441}]
	\begin{itemize}
		\item Pour tout $x\in E$, il existe un unique $(e_1^*(x),\dots, e_n^*(x))\in K^n$ tel que $x = e_1^*(x)e_1 + \cdots + e_n^*(x)e_n$. L'application $e_i^*$, appellée \emph{$i$-ième application coordonnée}, est une forme linéaire sur $E$.
		\item Si $\langle\cdot\mid\cdot\rangle$ est un produit scalaire sur $E$, alors pour tout $y\in E$, $\langle\cdot \mid y\rangle$ est une forme linéaire sure $E$.
		\item Pour tout $A\in \M_n(K)$, $\tr(A\cdot)$ est une forme linéaire sur $\M_n(K)$.
		\item Si $f\,\colon \IR^n\to\IR^n$ est différentiable en $a\in\IR^n$, alors $df(a)\in\left(\IR^n\right)^*$.
		\item Pour tout $\alpha\in K$, le morphisme d'évaluation en $\alpha$ est une forme linéaire sur $K_n[X]$, l'ensemble des polynômes de $K[X]$ de degré inférieur ou égal à $n$.
	\end{itemize}
\end{example}

\begin{proposition}[\textnormal{[R] e445}]
	Soit $H$ un sous-espace vectoriel de $E$. 
	$H$ est un hyperplan $\iff$ $H$ est le noyau d'une forme linéaire non nulle.
\end{proposition}

\begin{corollary}[\textnormal{[R] 441}]
	Une forme linéaire non nulle est surjective.
\end{corollary}

\subsection*{B. Espace dual, base duale}
\begin{proposition_def}[\textnormal{[R] 442}]
	$\B^* = \left\{e_1^*,\dots, e_n^*\right\}$ est une base de $E^*$, appelée \emph{base duale de $\B$}.
	Plus précisément, $\forall \varphi\in E^*,\, \varphi = \sum_{k=1}^{n}\varphi(e_k)e_k^*$,
	\emph{i.e.} $e_k^{**}(\varphi) = \varphi(e_k)$.
\end{proposition_def}

\begin{example}
	\begin{itemize}
		\item La base duale de la base canonique de $\IR^n$ est $\left\{(x_1,\dots,x_n)\mapsto x_i\right\}_{1\leq i\leq n}$
		\item La base duale de la base canonique $\left\{E_{i,j}\right\}_{1\leq i,j\leq n}$ de $\M_n(K)$ est $\left\{\tr(E_{i,j}\cdot)\right\}_{1\leq i,j\leq n}$.
	\end{itemize}
\end{example}

\begin{corollary}
	$\dim E = \dim E^*$, et $E^*\cong E$.
\end{corollary}

\begin{remark}
	Cet isomorphisme n'est pas canonique, car il dépend du choix de la base $\B$.
\end{remark}

\begin{theorem}[de représentation de \textsc{Riesz} - \textnormal{[BMF] 103}]
	Soit $(H,\langle \cdot \mid\cdot\rangle)$ un espace de Hilbert (on choisit, dans le cas complexe, l'antilinéarité à droite).
	$$\forall \varphi\in H^*,\,\exists ! v\in H\,\colon \varphi = \langle\cdot\mid v\rangle$$
	De plus, $\varphi\mapsto v$ est une isométrie entre $H^*$ et $H$.
\end{theorem}

\begin{remark}
	Si $E$ est euclidien ou hermitien, alors $y\mapsto \langle\cdot\mid y\rangle$ est un isomorphisme canonique entre $E$ et $E^*$.
\end{remark}

\begin{application}
	On se place dans le $\IR$-espace vectoriel $\IR^3$.
	On note $[x,y,z]$ le produit mixte de $(x,y,z)$. Pour tout $x,y\in\IR^3$, il existe un unique vecteur $x\wedge y$ tek que $[x,y,\cdot] = \langle\cdot\mid x\wedge y\rangle$,
	que l'on appelle \emph{produit vectoriel de $x$ et $y$}.
\end{application}

\begin{example}
	Soit $(a_0,a_1,\dots,a_n)\in K^n$ une famille de points deux à deux distincts.
	Pour $i\in \llbracket 0,n\rrbracket$, posons $l_i = \prod_{j\neq i}\frac{X-a_i}{a_j-a_i}$
	et $\B=\left\{l_0,l_1,\dots, l_n\right\}$ la base de $K_n[X]$ des polynômes de \textsc{Lagrange}.
	La base duale de $\B$ est $\B^*=\left\{\eval_{a_0},\dots, \eval_{a_n}\right\}$.
\end{example}

\begin{example}Supposons que $\car K = 0$.
	Fixons $a\in K$. Rappelons que :
	$$\forall P\in K_n[X],\, P=\sum_{k=0}^{n}P^{(k)}(a)\frac{(X-a)^k}{k!}$$
	et cette écriture est unique, \emph{i.e.} $\left\{\frac{(X-a)^k}{k!}\right\}_{0\leq k\leq n}$ est une base de $K_n[X]$.
	Sa base duale est $\left\{P\mapsto P^{(k)}(a)\right\}_{0\leq k \leq n}$.
\end{example}

\begin{application}[\textnormal{[Go'] 324}]
	Si $f\,\colon \IR^n\to \IR$ est différentiable en $a\in\IR^n$, alors il existe un unique vecteur $\nabla f(a)$, appelé \emph{gradient de $f$ en $a$}, tel que $df(a)=\langle \cdot\mid \nabla f(a)\rangle$.
\end{application}

\textcolor{paragraphtext}{\underline{Le cas particulier de $\M_n(K)$} :} Soit $n\geq 2$.


\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[\textnormal{[R] 458}]
	\label{159dev11}
	$A\mapsto \tr(A\cdot)$ est un isomorphisme (canonique) entre $\M_n(K)$ et $\M_n(K)^*$.
\end{theorem}
\begin{proposition}
	\label{159dev12}
	Si $\varphi\in\M_n(K)^*$ vérifie $\forall(A,B)\in\M_n(K)^2,\,\varphi(AB)=\varphi(BA)$, alors $\varphi$ est colinéaire à la trace.
\end{proposition}
\begin{proposition}[\textnormal{[C] 16-18}]
	\label{159dev13}
	\begin{itemize}
		\item Tout hyperplan de $\M_n(K)$ contient une matrice inversible ;
		\item Tout hyperplan de $\M_n(\IR)$ contient une matrice orthogonale.
	\end{itemize}
\end{proposition}
\end{tcolorbox}

\subsection*{C. Espace bidual, base antéduale}

\begin{definition}[\textnormal{[R] 445}]
	L'espace $E^{**} = \left(E^*\right)^*$ est appelé \emph{(espace) bidual de $E$}.
\end{definition}
\begin{theorem}[\textnormal{[R] e445}]
	$\eval\,\colon E\to E^{**}$, $x\mapsto [\varphi\mapsto \varphi(x)]$ est un isomorphisme (canonique).
\end{theorem}

\begin{remark}
	Ce n'est pas toujours vrai en dimension infinie !
\end{remark}

\begin{proposition}[\textnormal{[R] 443-444}]
	Soit $\tilde{\B} = \left\{\varphi_1,\dots,\varphi_n\right\}$ une base de $E^*$.
	Il existe une unique base $\B$ de $E$, appelée \emph{base antéduale de $\tilde{\B}$}, dont $\tilde{\B}$ est la base duale.
\end{proposition}

\section*{II. Notion d'orthogonalité}
\subsection*{A. Orthogonal d'une partie}

\begin{notation}
	Pour $\varphi\in E^*$ et $x\in E$, on pose $\langle\varphi, x\rangle_{E^*, E} = \varphi(x)$ (ou plus simplement, $\langle\varphi,x\rangle$ s'il n'y a aucune ambiguité).
	On appelle cette notation \emph{crochet de dualité}.
	\textcolor{red}{Attention : c'est différent de la notation du produit scalaire.}
\end{notation}

\begin{remark}
	Cette notation n'est pas anodine : dans le cadre eucliden ou hermitien (hilbertien en général), si $\varphi = \langle \cdot\mid y\rangle$, alors $\varphi(x)=0\iff \langle x\mid y\rangle=0$.
\end{remark}

\begin{definition}[\textnormal{[R] 447}]
	\begin{itemize}
		\item L'\emph{orthogonal de $A\subseteq E$} est $A^{\perp} = \left\{\varphi\in E^*\mid \forall x\in A,\, \langle \varphi,x\rangle = 0\right\}$
		\item L'\emph{orthogonal de $B\subseteq E^*$} est $B^{\circ} = \left\{\varphi\in E^*\mid \forall \varphi\in B,\, \langle \varphi,x\rangle = 0\right\}$
	\end{itemize}
\end{definition}

\begin{proposition}[\textnormal{[R] 447}]
	\begin{itemize}
		\item $A\mapsto A^{\perp}$ et $B\mapsto B^{\circ}$ sont décroissantes pour l'inclusion.
		\item $\forall A\subseteq E$, $A^{\perp} = \Vect(A)^{\perp}$
		\item $\forall B\subseteq E^*$, $B^{\circ} = \Vect(B)^{\circ}$
	\end{itemize}
\end{proposition}

\begin{proposition}[\textnormal{[R] 448}]
	\begin{itemize}
		\item Si $F$ est un sous-espace vectoriel de $E$, alors $\left(F^{\perp}\right)^{\circ} = F$ et $\dim F + \dim F^{\perp} = \dim E$
		\item Si $F$ est un sous-espace vectoriel de $E^*$, alors $\left(F^{\circ}\right)^{\perp} = F$ et $\dim F + \dim F^{\circ} = \dim E$
	\end{itemize}
\end{proposition}

\begin{corollary}
	Pour tout sous-espace vectoriel $F$ de $E$, $F=E\iff F^{\perp}=\left\{0\right\}$.
\end{corollary}

\begin{theorem}[Équation d'un s.e.v - \textnormal{[R] 451}]
	Si $(\varphi_1,\dots,\varphi_p)\in (E^*)^p$ est de rang $r$, alors $\bigcap_{i=1}^{p}\Ker(\varphi_i)$ est de dimension $n-r$.
	Réciproquement, si $F$ est un sous-espace vectoriel de $E$ de dimension $n-r$, alors il existe une famille $(\varphi_1,\dots,\varphi_r)$ de $E^*$ libre telle que $F = \bigcap_{i=1}^{r} \Ker \varphi_i$.
\end{theorem}

\begin{remark}[\textnormal{[R] e446}]
	Pour simplifier les notations, plaçons nous dans $E = K^n$.
	Si $H = \Ker \varphi$ est un hyperplan, alors $H = \left\{(x_1,\dots,x_n)\in K^n\mid \varphi(e_1)x_1 + \cdots + \varphi(e_n)x_n = 0\right\}$ 
	(où $\left\{e_1,\dots, e_n\right\}$ est la base canonique de $K^n$).
	Un hyperplan est donc caractérisé par une équation, et d'après le théorème précédent, un sev de $E$ de dimension 
	$n-r$ est caractérisé par un système de $r$ équations (à $n$ inconnues).
\end{remark}

\begin{proposition}[\textnormal{[R] 448}]
	Soient $A$ et $B$ deux sous-espaces vectoriels de $E$.
	Alors :
	\begin{itemize}
		\item $\left(A + B\right)^{\perp} = A^{\perp} \cap B^{\perp}$
		\item $\left(A\cap B\right)^{\perp} = A^{\perp} + B^{\perp}$
	\end{itemize}
	On a les mêmes résultats pour l'orthogonalité dans $E^*$.
\end{proposition}

\textcolor{paragraphtext}{\underline{Application au calcul différentiel}}

\begin{lemma}[\textnormal{[R] 444}]
	$\forall (\varphi,\varphi_1,\dots,\varphi_r)\in \left(E^*\right)^{r+1}$,
	$\varphi \in\Vect(\varphi_1,\dots,\varphi_r)\iff \bigcap_{i=1}^r g_i^{-1}(\left\{0\right\})$.
\end{lemma}

\begin{theorem}[des extrema liés - \textnormal{[Rv] 372}]
	Soient $U$ un ouvert de $\IR^n$ et $(f,g_1,\dots, g_R)\in C^1(U,\IR)^{r+1}$. 
	Posons $\Gamma = \bigcap_{i=1}^r g_i^{-1}(\left\{0\right\})$.
	Si $f_{\mid \Gamma}$ admet un extremum local en $a\in \Gamma$, et si $(dg_1(a),\dots, dg_r(a))$ est libre, alors il existe des réels (uniques) $\lambda_1,\dots, \lambda_n$ appelées \emph{multiplicateurs de \textsc{Lagrange}},
	tels que $df(a) = \lambda_1dg_1(a)+\cdots + \lambda_r dg_r(a)$.
\end{theorem}

\subsection*{B. Morphisme transposé}
\textcolor{paragraphtext}{Dans ce paragraphe, $F$ est un $K$-espace vectoriel de dimension finie $p$, et $u\in\mathcal{L}(E,F)$.}

\begin{definition}[\textnormal{[R] 452}]
	Le morphisme \emph{transposé de $u$} est ${}^tu\,\colon F^*\to E^*$, $\varphi\mapsto \varphi\circ u$.
\end{definition}

\begin{remark}
	Avec la notation du crochet de dualité, ${}^tu$ est le morphisme vérifiant $\forall \varphi\in F^*$
	, $\forall x\in E$, $\langle\varphi, u(x)\rangle_{F^*,F} = \varphi\circ u (x) = {}^tu(\varphi)(x) = \langle {}^tu(\varphi),x\rangle_{E^*,E}$.
\end{remark}

\begin{remark}[\textnormal{[R] 454}]
	Dans le cadre euclidien ou hermitien, la correspondance entre $E$ et $E^*$ tranduit une correspondance entre ${}^tu$ et $u^*$ (l'adjoint de $u$).
\end{remark}

\begin{proposition}[\textnormal{[R] 452}]
	On a :
	\begin{itemize}
		\item $u\mapsto {}^tu$ est linéaire injective de $\mathcal{L}(E,F)$ dans $\mathcal{F^*,E^*}$.
		\item $\Ker {}^tu = \left(\im u\right)^{\perp}$
		\item $\im {}^tu = \left(\Ker u\right)^{\perp}$
		\item Si $v\in\mathcal{L}(F,G)$, alors ${}^t\left(v\circ u\right) = {}^tu\circ{}^tv$.
	\end{itemize}
\end{proposition}

\begin{proposition}[\textnormal{[R] 454-452}]
	Soient $\B_E$ et $\B_F$ des bases de $E$ et de $F$. On a $\Mat_{\B_F^*,\B_E^*}({}^tu) = {}^t\Mat_{\B_E,\B_F}(u)$.
	En particulier, $\rg {}^tu = \rg u$.
\end{proposition}

\begin{proposition}
	Soient $\B_1$ et $\B_2$ deux bases de $E$. Alors, $\Pass_{\B_2^*,\B_1^*} = {}^t\Pass_{\B_1,\B_2}$.
\end{proposition}

\section*{III. Application aux formes quadratiques réelles HORS-SUJET A REFAIRE}
NB : Attention, ne peut rien faire par rapport aux espaces de Hilbert car on doit rester en dimension finie.
Du coup la réflexivité est naturellement présente partout.

\textcolor{paragraphtext}{Soient $E$ un $\IR$-espace vectoriel de dimension finie $n>0$, et $q$ une forme quadratique sur $E$.}

\begin{theorem}
	Il existe une base $q$-orthogonale, que l'on peut déterminer avec l'algorithme de \textsc{Gauss}.
\end{theorem}


\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[Loi d'inertie de \textsc{Sylvester} - \textnormal{[R] 476}]
	\label{159dev2}
	
\end{theorem}
	Soit $\B=\left\{e_1,\dots, e_n\right\}$ une base de $E$ orthogonale pour $q$.
	Quitte à renuméroter $\B$, supposons que $q(e_1)>0,\dots, q(e_s)>0, q(e_{s+1})<_,\dots,q(e_{s+t})<0,q(e_{s+t+1}) = \cdots = q(e_n)=0$.
	Le couple $(s,t)$ ne dépend alors pas du choix de la base orthogonale : on l'appele \emph{signature de $q$}.
\begin{example}
	$q(a,b,c,d,e) =$
\end{example}
\end{tcolorbox}

\section*{Développements}
\begin{itemize}
	\item Développement 1 : Théorème \ref{159dev11} et Propositions \ref{159dev12}, \ref{159dev13}
	\item Développement 2 : Théorème \ref{159dev2}
\end{itemize}

\section*{Références}
\begin{itemize}
	\item[R] \emph{Mathématiques pour l'agrégation - Algèbre et géométrie}, Jean-Étienne Rombaldi, 2e édition
	\item[Go] \emph{Les maths en tête - Algèbre et probabilités}, Xavier Gourdon, 3e édition
	\item[Go'] \emph{Les maths en tête - Analyse}, Xavier Gourdon, 3e édition
	\item[C] \emph{Carnet de voyage en Algébrie}, Philippe Caldero, Marie Peronnier
	\item[Rv] \emph{Petit guide du calcul différentiel}, François Rouvière, 4e édition
	\item[BMP] \emph{Objectif Agrégation}, Vincent Beck, Jérôme Malick, Gabriel Peyré, 2e édition
	\item[FGN] \emph{Oraux X-ENS Algèbre 2}, 2è édition 
\end{itemize}

% \begin{figure}[!htb]
% 	\centering
% 	\includegraphics[trim={0 0 0 0},clip,width=1\linewidth]{img/149.pdf}
% 	\caption{s}
% \end{figure}



\chapter*{171 : Formes quadratiques réelles. Coniques. Exemples et applications.}
\setcounter{definition}{0}

\textcolor{paragraphtext}{On suppose connue la théorie générale des espaces quadratiques, pour se concentrer sur le cas particulier d'une espace quadratique réel $(E,q)$ de dimension $n\geq 1$.
On note $\varphi$ la forme polaire de $q$.}

\section*{I. Propriétés propres aux formes quadratiques réelles}
\subsection*{A. Positivité de définition}

\begin{definition}[\textnormal{[R] 475}]
	On dit que $q$ est \emph{positive} (resp. \emph{négative}) si $\forall x\in E\setminus\left\{0\right\}$, $q(x)\geq 0$ (resp. $q(x)\leq 0$).
	Si cette inégalité est stricte, alors on dit que $q$ est \emph{définie positive} (resp. \emph{définie négative}).
\end{definition}

\begin{example}
	Sur $\IR^2$, $q\,\colon (x,y)\mapsto x^2+y^2$ est définie positive, $q\,\colon(x,y)\mapsto x^2$ est positive non définie, et $q\,\colon(x,y)\mapsto xy$ est rien du tout.
\end{example}

\begin{theorem}[inégalité de \textsc{Cauchy-Schwarz} - \textnormal{[R] 475}]
	Si $q$ est positive, alors pour tout $(x,y)\in E^2$, $\varphi(x,y)^2 \leq q(x)q(y)$, avec égalité si (et seulement si lorsque $q$ est définie positive) $x$ et $y$ sont colinéaires.
\end{theorem}

\begin{corollary}
	Si $q$ est positive, $\sqrt{q}$ est une semi-norme.
	Si $q$ est définie positive, alors $\sqrt{q}$ est une norme.
\end{corollary}

\begin{corollary}
	Si $q$ est positive, alors $q$ définie positive $\iff$ $q$ non dégénérée.
\end{corollary}

\subsection*{B. Réduction et algorithme de \textsc{Gauss}}

\begin{theorem}[réduction de \textsc{Gauss} - \textnormal{[R] 469}]
	Il existe $(l_1,\dots, l_r)$ une famille libre de formes linéaires et $(\lambda_1,\dots,\lambda_n)\in\IK^r$ telles que $q = \sum_{i=1}^{r} \lambda_il_i^2$.
\end{theorem}

\begin{algorithm}[\textnormal{[R] 469-472}]
	Écrivons $q(x_1,\dots,x_n) = \sum_{i=1}^{n} a_ix_i^2 + 2\sum_{1\leq i,j\leq n} b_{i,j}x_ix_j$.
	
	S'il existe $i\in \llbracket 1,n \rrbracket$ tel que $a_i\neq 0$ (quitte à renuméroter, disons $a_1\neq 0$),
	on écrit $q(x_1,\dots, x_n) = a_1\left(x_1 + \frac{1}{a_1}\sum_{2\leq j \leq n}b_{1,j}x_j\right)^2 + [\text{ce qui manque } = f(x_2,\dots, x_n)]$.

	Sinon, quitte à renuméroter, supposons que $b_{1,2}\neq 0$. Alors :
	\begin{align*}
		q(x_1,\dots,x_n) &= 2b_{1,2}x_1x_2 + 2x_1\sum_{3\leq j\leq n}b_{1,j}x_j + 2x_2\sum_{3\leq j\leq n}b_{2,j}x_j +\dots \\	
		&=: 2b_{1,2}x_1x_2 + 2x_1f_1(x_3,\dots,x_n) + 2x_2f_2(x_3,\dots, x_n) + \dots \\
		&= 2b_{1,2}(x_1 + \frac{1}{b_{1,2}}f_2(x_3,\dots, x_n))(x_2 + \frac{1}{b_{1,2}}f_1(x_3,\dots, x_n)) + \dots \\
		&=: 2b_{1,2}l_1l_2 + \dots
	\end{align*}

	puis on écrit $l_1l_2 = \frac{1}{4}\left((l_1+l_2)^2 - (l_1-l_2)^2\right)$
	Puis on itère sur les autres variables.
\end{algorithm}

\begin{example}[\textnormal{[R] 485}]
	$5xy+6xz+3yz = \frac{1}{20}(5x+5y+9z)^2 - \frac{1}{20}(5x+5y-3z)^2 - \frac{18}{5}z^2$
\end{example}

\begin{corollary}[\textnormal{[R] 473}]
	Il existe une base $q$-orthogonale de $E$, \emph{i.e.} dans laquelle la matrice de $q$ est diagonale.
\end{corollary}

\begin{theorem}[orthogonalisation simultanée - \textnormal{[Gr] e315, [Au] 271}]
	Si $q$ et $q'$ sont deux formes quadratiques sur $E$ avec $q$ définie positive, alors il existe une base de $E$ qui est à la fois $q$-orthogonale et $q'$-orthogonale.

	Matriciellement, si $M\in\mathcal{S}_n^{++}(\IR)$ et $N\in\mathcal{S}_n(\IR)$, alors il existe $P\in GL_n(\IR)$ telle que 
	${}^tPMP = I_n$ et ${}^tPNP$ est diagonale.
\end{theorem}

\subsection*{C. Signature et classification}
\begin{definition}[\textnormal{[R] 477}]
	Notons $\P$ (resp. $\mathcal{N}$) l'ensemble des sous-espaces $f$ de $E$ tels que $q_{\mid F}$ est définie positive (resp. définie négative).
	Posons $s = \max_{F\in\P} \dim F$ et $t = \max_{F\in\mathcal{N}} \dim F$ avec la convention $\max \emptyset = 0$.

	Le coupe $(s,t)$ est appelé \emph{signature de $q$}.
\end{definition}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[loi d'inertie de Sylvester - \textnormal{[R] 476}]
	\label{171dev1}
	Supposons que $\B$ est $q$-orthogonale.
	Alors $s = \#\left\{i\in \llbracket 1,n\rrbracket \mid q(e_i)> 0\right\}$
	et $t=\#\left\{i\in \llbracket 1,n \rrbracket \mid q(e_i) > 0\right\}$.
\end{theorem}
\end{tcolorbox}

\begin{remark}[\textnormal{[R] 476}]
	En particulier, $s+t = \rg q$
\end{remark}

\begin{corollary}
	Les classes déquivalence sont caractérisées par la signature. En particulier, il y a $n+1$ classes non dégénérées.
\end{corollary}

\begin{example}[\textnormal{[R] 491}]
	La signature de $M\mapsto \tr(M^2)$ est $\left(\frac{n(n+1)}{2}, \frac{n(n-1)}{2}\right)$.
\end{example}

\subsection*{D. Matrice hessienne et optimisation}
\textcolor{paragraphtext}{Soit $f\in C^2(\IR^n,\IR)$.}

\begin{theorem}[\textnormal{[BMP] 18}]
	Si $f$ admet un maximum (resp. un minimum) local en $a$, alors $a$ est un 
	point critique, et $\Hess_a(f)$ est négative (resp. positive).

	La réciproque est vraie si on suppose en plus $\Hess_a(f)$ définie.

	Si $a$ est un point critique et si $\Hess_a(f)$ admet deux valeurs propres de signes strictement opposés, alors $a$ est un \emph{point-selle}.
\end{theorem}

\begin{remark}
	$x\mapsto x^4$ admet un minimum globale en $0$, mais hessienne (sa dérivée seconde) est nulle en $0$.
\end{remark}

\begin{example}[\textnormal{[BMP] 24-32}]
	Soient $A\in\mathcal{S}_n^{++}(\IR)$, $b\in\IR^n$ et $J\,\colon x\mapsto \frac{1}{2}\langle AX\mid X\rangle - \langle b\mid x\rangle$.
	Alors $\forall x\in \IR^n$, $\nabla J(x)=Ax-b$ et $\Hess_J(x) = A\in\mathcal{S}_n^{++}(\IR)$.
	En particulier, $J$ admet un unique minimum (global) qui est la solution de $Ax= b$.
\end{example}

\section*{II. Étude des coniques d'un plan affine euclidien}
\textcolor{paragraphtext}{Soient $\mathcal{P}$ un plan affine euclidien. On fixe un repère orthonormé.}

\subsection*{A. Définition algébrique, classification}
\begin{definition}[\textnormal{[R] 493-494}]
	Soient $(a,b,c)\in\IR^3$ non tous nuls, et $(d,e,f)\in\IR^3$.
	On pose $q\,\colon (x,y)\mapsto ax^2+bxy+cy^2$ et $l\,\colon(x,y)\mapsto dx+ey$.
	Une \emph{conique} est 
	$$\mathcal{C} = \left\{(x,y)\in \mathcal{P} \mid q(x,y)+l(x,y)+f = 0\right\}$$

	On définit $Q\,\colon (x,y,z) \mapsto q(x,y)+l(x,y)z + fz^2$.
\end{definition}

\begin{example}[\textnormal{[Au] 228-231}]
	On a les coniques suivantes :
	\begin{itemize}
		\item $\left\{(x,y)\in\mathcal{P} \mid (x-\alpha)^2+(y-\beta)^2 = r^2\right\} = \text{Cercle}\left(\begin{pmatrix}
			\alpha \\ \beta
		\end{pmatrix}, r\right)$
		\item $\left\{(x,y)\in\mathcal{P} \mid (x/\alpha)^2+(y/\beta)^2 = r^2\right\}$ est une ellipse.
		\item $\left\{(x,y)\in\mathcal{P} \mid y = 2px^2\right\}$ est une parabole.
	\end{itemize}
\end{example}

\begin{theorem}
	Classification : \textcolor{paragraphtext}{ANNEXE 1}
\end{theorem}

\begin{proposition}
	Soit $\Delta = b^2 - 4ac \equiv \textnormal{disc}(q)$ avec les notations de Def 19.
	\begin{itemize}
		\item Si $\Delta < 0$, alors $\mathcal{C}$ est une ellipse, un point ou vide ;
		\item Si $\Delta = 0$, alors $\mathcal{C}$ est une parabole, deux droites parallèles ou vide ;
		\item Si $\Delta > 0$, alors $\mathcal{C}$ est une hyperbole, deux droites sécantes ou vide.
	\end{itemize}
\end{proposition}

\subsection*{B. Définitions géométriques}
\begin{proposition}[FIG. 2 - \textnormal{[R] 494}]
	Les ellipses, paraboles, hyperboles, points, et couples de droites sécantes sont obtenus comme intersection d'un cône et d'un plan.
\end{proposition}

\begin{theorem}[FIG. 3 - \textnormal{[R] 505-506}]
	Soient $\mathcal{D}$ une droite de $\mathcal{P}$, $F\in \mathcal{P}\setminus \mathcal{D}$ et $e > 0$.
	L'ensemble $\mathcal{C} = \left(M\in\mathcal{P} \mid d(M,F) = ed(M,\mathcal{D})\right)$ est une conique, on appelle $\mathcal{D}$ la \emph{directrice}, $F$ son \emph{foyer} et $e$ son \emph{excentricité}.

	Plus précisément, $\mathcal{C}$ est soit vide, soit une ellipse si $e < 1$, une parabole si $e=1$, une hyperbole si $e> 1$.
\end{theorem}

\begin{remark}[\textnormal{[R] 506}]
	On peut déterminer une équation dans un repère bien choisi, comme détaillé dans FIGURE 3.
\end{remark}

\begin{theorem}[FIG. 1 - \textnormal{[Au] 233-234}]
	\begin{itemize}
		\item Si $\mathcal{C}$ est une ellipse, alors il existe $F$ et $F'$ dans $\mathcal{P}$ (appelés \emph{foyers} de $\mathcal{C}$) et $a > 0$ (appelé \emph{demi-grand axe de $\mathcal{C}$}) tels que : $$\mathcal{C} = \left\{M\in\mathcal{P} \mid MF + MF' = 2a\right\}$$
		\item Si $\mathcal{C}$ est une hyperbole, alors il existe $F$ et $F'$ dans $\mathcal{P}$ (appelés \emph{foyers de $\mathcal{C}$}) et $a>0$ (appelé \emph{demi-grand axe de $\mathcal{C}$}) tels que : $$\mathcal{C} = \left\{M\in\mathcal{P} \mid \vert MF - MF'\vert = 2a\right\}$$
	\end{itemize}
\end{theorem}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[\textnormal{[Ei] 52}]
	\label{171dev2}
	Soient $A,B,C,D$ et $E$ cinq points de $\mathcal{P}$ distincts.
	\begin{enumerate}
		\item Il existe une conique passant par $A,B,C,D$ et $E$ ;
		\item Elle est unique si, et seulement si, $4$ points ne sont pas alignés ;
		\item Elle est non dégénérée si, et seulement si, $3$ points ne sont pas alignés.
	\end{enumerate}
\end{theorem}
\end{tcolorbox}

ANNEXE 1 : Classification des coniques
\begin{table}[]
\begin{tabular}{|l|l|l|l|l|}
Type & Signature de $q$ & Signature de $Q$ & Éq. réduite \\
Ellipse & $(2,0) / (0,2)$ & $(2,1) / (1,2)$ & $x^2+y^2 = 1$ \\
Parabole & $(1,0) / (0,1)$ & $(2,1)/(1,2)$ &  $x^2 +y=1$\\
Hyperbole & $(1,1)$  & $(2,1)/(1,2)$ & $x^2-y^2=1$\\
Droites sécantes & $(1,1)$ &  $(1,1)$ & $x^2-y^2=0$\\
Droites parallèles & $(1,0)/(0,1)$ & $(1,1)$ & $x^2 = 1$\\
Droites confondues & $(1,0)/(0,1)$ & $(1,0)/(0,1)$ & $x^2 = 0$ \\
Point & $(2,0) / (0,2)$ & $(2,0)/(0,2)$ & $x^2+y^2 = 0$ \\
Vide (1) & $(2,0) / (0,2)$ & $(3,0)/(0,3)$ & $x^2 + y^2 = -1$\\
Vide (2) & $(1,0) / (0,1)$ & $(2,0)/(0,2)$ & $x^2 = -1$
\end{tabular}
\end{table}

\section*{Développements}
\begin{itemize}
	\item Développement 1 : Théorème \ref{171dev1}
	\item Développement 2 : Théorème \ref{171dev2}
\end{itemize}

\section*{Références}
\begin{itemize}
	\item[R] \emph{Mathématiques pour l'agrégation - Algèbre et géométrie}, Jean-Étienne Rombaldi, 2e édition
	\item[BMP] \emph{Objectif Agrégation}, Vincent Beck, Jérôme Malick, Gabriel Peyré, 2e édition
	\item[Au] \emph{Géométrie}, Audin
	\item[Ei] \emph{Géométrie analytique classique}, Eiden
	\item[Gr] \emph{Algèbre linéaire}, Joseph Grifone, 6e édition, 2e version
\end{itemize}

\begin{figure}[!htb]
	\centering
	\includegraphics[trim={0 0 0 0},clip,width=1\linewidth]{img/171.pdf}
	\caption{s}
\end{figure}


\chapter*{IMPASSE / PAS FINI 162 : Systèmes d'équations linéaires ; opérations élémentaires, aspects algorithmiques et conséquences théoriques.}
\setcounter{definition}{0}

\textcolor{paragraphtext}{On considère $K$ un corps commutatif. Soient $n,p\geq 1$.}

\section*{I. Mise en place du problème}
\begin{definition}[\textnormal{[TL1] 377; [Gr] 37}]
	Un système d'équations linéaires à $n$ équations et $p$ inconnues est un système de la forme :
	\begin{align*}
		(S) \iff \begin{cases}
			a_{1,1}x_1 + a_{1,p}x_p = b_1 \\
			a_{2,1}x_1 + a_{2,p}x_p = b_2 \\
			\vdots \\
			a_{n,1}x_1 + a_{n,p}x_p = b_n \\
		\end{cases}
	\end{align*}
	où les coefficients $a_{i,j}$ et $b_i$ appartiennent $K$.
	Si tous les $b_i$ sont nuls, le système est dit \emph{homogène} (ou sans second membre).

	La matrice $A = \left(a_{i,j}\right)\in\M_{n,p}(K)$ est la matrice du système.
\end{definition}

\begin{proposition}[\textnormal{[TL1] 378}]
	Le système $(S)$ prend la forme matricielle $AX = B$, où $B = {}^t(b_1,\dots,b_n)$ et $X = {}^t(x_1,\dots, x_n)$.
\end{proposition}

\begin{theorem}[\textnormal{[TL1] 378}]
	Un système linéaire homogène de $n$ équations à $n$ inconnues possède une solution non trivial si, et seulement si, sa matrice $A$ n'est pas inversible.
\end{theorem}

\begin{definition}[\textnormal{[TL1] 379; [R] 191}]
	Le système $(S)$ est dit \emph{compatible} s'il possède au moins une solution et \emph{incompatible} sinon.
\end{definition}

\begin{proposition}[\textnormal{[TL1] 379}]
	Les assertions suivantes sont équivalentes :
	\begin{enumerate}
		\item Le système $(S)$ est compatible ;
		\item $B$ est combinaison linéaire (non triviale) des collones de $A$.
	\end{enumerate}
\end{proposition}

\begin{proposition}
	Supposons $A = 0_{n,p}$. Si $B = 0_{n,1}$, alors tout vecteur $X$ est solution du système.
	Si $B\neq 0_{n,1}$, alors le système n'a pas de solution.
\end{proposition}

\section*{II. Techniques de résolutions dans des cas précis}
\textcolor{paragraphtext}{On considère jusqu'à la fin de la leçon un système $(S)$ à $n$ équations et $p$ inconnues.
On note $A$ la matrice associée à ce système.}

\subsection*{A. Méthode de Cramer}
\begin{definition}[\textnormal{[TL1] 379}]
	Le système $(S)$ est appelé \emph{système de Cramer} si $n=p$ et si $A$ est inversible.
\end{definition}

\begin{theorem}[\textnormal{[TL1] 380}]
	Supposons que $(S)$ soit un système de Cramer.
	Il possède alors une unique solution $X\in K^n$, qui est $X = A^{-1}B$.
	Ses coefficients $x_j$ vérifient, pour tout $1\leq j\leq n$ :
	$$x_j = \frac{\det(C_1,\dots, C_{j-1}, B, C_{j+1},\dots, C_n)}{\det A}$$
	où $C_i$ est donnée par la $i$-ième colonne de $A$.
\end{theorem}

\begin{example}[\textnormal{[TL1] 380}]
	Considérons le système 
	\begin{align*}
		(S)\,\colon \begin{cases}
			x-y+z &= 1\\
			2x+4y+9z&=1\\
			3x-4y+2z &= 1
		\end{cases}
	\end{align*}

La matrice associée à ce système est $A = \begin{pmatrix}
	1 & -1 & 1 \\ 2 & 4 & 9 \\ 3 & -4 & 2
\end{pmatrix}$, en particulier $\det A = 1 \neq 0$ donc il existe une unique solution à ce système.
Cette dernière est donnée par :
\begin{align*}
	x = \begin{vmatrix}
		1 & -1 & 1 \\ 1 & 4 & 9 \\ 1 & -4 & 2
	\end{vmatrix},\, 
	y = \begin{vmatrix}
		1 & 1 & 1 \\ 2& 1 & 9 \\ 3 & 1 & 2
	\end{vmatrix},\,\text{et }
	z = \begin{vmatrix}
		1 & -1 & 1 \\ 2 & 4 & 1 \\ 3 & -4 & 1
	\end{vmatrix}
\end{align*}

donc $x = 29$, $y=15$ et $z=-13$.
\end{example}

\begin{remark}[\textnormal{[TL1] 381}]
	Intérêt essentiellement théorique car coût plus élevé que de résoudre le système par pivot de \textsc{Gauss}.
\end{remark}

\subsection*{B. Matrices échelonnées et méthode de remontée}
\begin{definition}[\textnormal{[R] 187}]
	On dit que $A$ est échelonnée en ligne si elle est nulle ou si il existe $r\in \llbracket 1,n \rrbracket$ tel que les lignes $L_i$ de $A$ vérifient :
	\begin{enumerate}
		\item $L_i\neq 0$, $\forall 1\leq i \leq r$
		\item $L_i = 0$, $\forall i\geq r+1$
		\item $1\leq d_1<d_2<\cdots<d_r\leq p$ où $d_i = \min\left\{1\leq j\leq p\mid a_{ij}\neq 0\right\}$.
	\end{enumerate}

	Les coefficients $a_{i,d_i}$ sont appelés les \emph{pivots} de la \emph{matrice échelonnée $A$}.
\end{definition}

\begin{example}[\textnormal{[Gr] 39}]
	La matrice définie par :
	\begin{align*}
		\begin{pmatrix}
			2&3&1&0&1&2&6 \\
			0&0&7&1&8&2&0 \\
			0&0&0&0&0&6&2 \\
			0&0&0&0&0&0&0
		\end{pmatrix}
	\end{align*}
	est échelonnée, mais ce n'est pas le cas de :
	\begin{align*}
		\begin{pmatrix}
			1&3&1&0&1&5&9 \\
			0&0&7&1&8&2&0 \\
			0&0&5&1&0&6&2 \\
			0&0&0&3&2&1&5
		\end{pmatrix}
	\end{align*}
\end{example}

\begin{proposition}[\textnormal{[R] 187}]
	Avec les notations précédentes, une matrice $A$ non nulle échelonnée en lignes est de rang $r$ ($=$ le nombre de lignes non nulles).
\end{proposition}

\begin{definition}[\textnormal{[R] 188}]
	On dit qu'un système linéaire $AX = B$ est \emph{échelonné} si la matrice $A$ est échelonnée en lignes.
\end{definition}

\begin{algorithm}[Échelonnage d'une matrice - \textnormal{[R] 193}]
	A FAIRE
\end{algorithm}


\section*{Développements}
% \begin{itemize}
% 	\item Développement 1 : Théorème \ref{171dev1}
% 	\item Développement 2 : Théorème \ref{171dev2}
% \end{itemize}

\section*{Références}
\begin{itemize}
	\item[R] \emph{Mathématiques pour l'agrégation - Algèbre et géométrie}, Jean-Étienne Rombaldi, 2e édition
	\item[C] \emph{Carnets de voyage en Algébrie}, Caldero
	\item[Gr] \emph{Algèbre linéaire}, Joseph Grifone, 6e édition, 2e version
	\item[TL1] \emph{Mathématiques Tout-en-un pour la Licence 1}, Jean-Pierre Ramis, André Warusfel
\end{itemize}

% \begin{figure}[!htb]
% 	\centering
% 	\includegraphics[trim={0 0 0 0},clip,width=1\linewidth]{img/171.pdf}
% 	\caption{s}
% \end{figure}

\chapter*{203 : Utilisation de la notion de compacité}
\setcounter{definition}{0}

\textcolor{paragraphtext}{Dans toute la leçon, $(X,d)$ et $(Y,\delta)$ sont des espaces métriques.}
\section*{I. Notion de compacité : définition, caractérisation, propriétés}

\begin{definition}[\textnormal{[G] 27}]
	On dit que $(X,d)$ est \emph{compact} si de tout recouvrement de $X$ par des ouvers on peut extraire un sous-recouvrement fini de $X$.
\end{definition}

\begin{example}[\textnormal{[G] 27}]
	Si $X$ est fini, alors $(X,d)$ est compact.
	$(\IR,\vert\cdot\vert)$ n'est pas compact : $\IR = \bigcup_{n\in\IN^*}]-n,n[$.
\end{example}

\begin{proposition}[\textnormal{[G] 27}]
	Un espace métrique compact est borné.
\end{proposition}

\begin{proposition}[\textnormal{[G] 28}]
	Si $(X,d)$ est compact, alors toute intersection ddécroissante de fermés non vides de $X$ est non vide.
\end{proposition}

\begin{remark}[\textnormal{[G] 28}]
	La compacité est cruciale : considérer $X = \IR$, et $\left([n,+\infty[\right)_{n\in\IN}$.
\end{remark}

\begin{theorem}[de \textsc{Bolzano-Weierstrass} - \textnormal{[G] 28}]
	$(X,d)$ est compact si, et seulement si, de toute suite d'éléments de $X$ on peut extraire une sous-suite convergente.
\end{theorem}

\begin{example}
	Pout tout $(a,b)\in\IR^2$ tel que $a\leq b$, $[a,b]$ est compact.
\end{example}

\begin{corollary}[\textnormal{[G] 30}]
	Tout espace métrique compact est complet.
\end{corollary}

\begin{corollary}[\textnormal{[G] 30}]
	Toute partie fermée d'un compacte est compacte.
\end{corollary}

\begin{example}[\textnormal{[G] 30}]
	Les compacts de $\IR$ sont les fermés bornés.
\end{example}

\begin{proposition}[\textnormal{[G] 30}]
	Tout compact est fermé et borné.
\end{proposition}

\begin{remark}
	La réciproque est fausse : la boule unité fermée de $(\IR[X], \|\cdot\|_{\infty})$ est fermée et bornée, mais pas compacte.
\end{remark}

\begin{theorem}[\textnormal{[G] 30}]
	Les compacts de $(\IR, \|\cdot\|_{\infty})$ sont les fermés bornés.
\end{theorem}

\begin{theorem}[de \textsc{Tychonov} - \textnormal{[G] 30}]
	Un produit fini de compacts est compact.
\end{theorem}

\begin{proposition}[\textnormal{[G] 30}]
	Dans un espace compact, une suite converge si, et seulement si, elle admet une unique valeur d'adhérence.
\end{proposition}

\begin{remark}
	La compacité est cruciale : considérer $\left(n\delta_{n\in 2\IN}\right)_{n\in\IN}\in\IR^{\IN}$.
\end{remark}

\textcolor{paragraphtext}{Dans toute la suite, on supposera $(X,d)$ compact.}
\section*{Fonctions continues sur un compact}
\subsection*{A. Cas des fonctions numériques}

\begin{theorem}[\textnormal{[G] 31}]
	L'image d'un compact par une application continue est compacte.
\end{theorem}

\begin{example}
	La compacité est cruciale : $\IR = \arctan\left(]-\frac{\pi}{2},\frac{\pi}{2}[\right)$
\end{example}

\begin{proposition}[\textnormal{[G] 31}]
	La réciproque d'une bijection continue sur un compact est continue (on a donc homéomorphisme).
\end{proposition}

\begin{theorem}[des bornes atteintes - \textnormal{[G] 31}]
	Toute fonction de $C(X,\IR)$ est bornée et atteint ses bornes.
\end{theorem}

\begin{example}[\textnormal{[Rv] 413}]
	Sur un billard elliptique, il existe une trajectoir fermée à 3 rebonds.
\end{example}

\begin{example}[\textnormal{[G] e33}]
	Soit $F\subseteq X$ non vide fermée. Pour tout $x\in X$, il existe $y\in F$ tel que $d(x,y)=d(x,F)=\inf_{z\in F} d(x,z)$.
\end{example}

\textcolor{paragraphtext}{Dans la suite de ce paragraphe, $(X,d) = ([a,b], \|\cdot\|)$, et on fixe $f\in C^0([a,b], \IR)$.}

\begin{theorem}[de \textsc{Rolle} - \textnormal{[G] 73, [R] 251}]
	Si $f$ est déribale sur $]a,b[$ et vérifie $f(a)=f(b)$, alors il existe $c\in ]a,b[$ tel que $f'(c)=0$.
\end{theorem}

\begin{example}[\textnormal{[R] 243}]
	Si $f$ est $n$ fois dérivabme sur $]a,b[$ et s'annule $n+1$ fois, alors $f^{(n)}$ s'annule au moins une fois.
\end{example}

\begin{theorem}[des accroissements finis - \textnormal{[G] 74, [R] 258}]
	Si $f$ est dérivable sur $]a,b[$, alors il existe $c\in ]a,b[$ tel que $f(b)-f(a) = f'(c)(b-1)$.
\end{theorem}

\begin{example}[\textnormal{[G] 74, [R] 261}]
	Soit $I$ un intervalle de $\IR$, soit $f\,\colon I\to \IR$ continue sur $I$ et dérivable sur $\mathring{I}$. Alors $f$ est croissante sur $I$ si, et seulement si, $f'\geq 0$ sur $\mathring{I}$.
\end{example}

\begin{example}[\textnormal{[R] 238, [G] 96}]
	Soit $I\subseteq \IR$ un intervalle non ponctuel, soit $f\,\colon I\to\IR$ deux fois dérivable.
	Si $f''\geq 0$, alors $f$ est convexe.
\end{example}


\subsection*{B. Uniforme continuité, approximation uniforme}

\begin{theorem}[de \textsc{Heine} - \textnormal{[G] 31}]
	Une fonction continue sur un compact $y$ est uniformément continue.
\end{theorem}

\begin{theorem}[de \textsc{Dini} - \textnormal{[G] 238}]
	\begin{enumerate}
		\item Soit $\left(f_n\right)_{n}\in \mathcal{C}(X,\IR)^{\IN}$. Si $\left(f_n\right)_n$ est croissante et converge simplement vers $f\in\mathcal{C}(X,\IR)$, alors $\left(f_n\right)_n$ converge uniformément vers $f$.
		\item Soit $\left(f_n\right)_n\in\mathcal{C}([a,b],\IR)^{\IN}$ telle que pour tout $n\in\IN$, $f_n$ est croissante. Si $\left(f_n\right)_n$ converge simplement vers $f\in\mathcal{C}([a,b],\IR)$, alors $\left(f_n\right)_n$ converge uniformément vers $f$.
	\end{enumerate}
\end{theorem}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{example}[\textnormal{[HL] 26}]
	\label{203dev11}
	Soit $\left(P_n\right)_n$ définie par $\forall x \in[-1,1],\, P_0(x)= 0$ et $\forall n\in \IN,\, P_{n+1}(x) = P_n(x) + \frac{1}{2}(x^2 - P_n^2(x))$.
	La suite $\left(P_n\right)_n$ converge uniformément vers $\vert\cdot\vert$ sur $[-1,1]$.
\end{example}
\begin{theorem}[de \textsc{Stone-Weierstrass} - \textnormal{[HL] 26}]
	\label{203dev12}
	Toute sous-algèbre $H$ de $C(X,\IR)$ unitaire et séparante (\emph{i.e.} $\forall (x,y)\in X^2$, $x\neq y\implies \exists h\in H\,\colon h(x)\neq h(y)$)
	est dense pour $\|\cdot\|_{\infty}$.
\end{theorem}
\end{tcolorbox}

\begin{corollary}[théorème de \textsc{Weierstrass} - \textnormal{[G] 304}]
	Toute fonction continue sur un segmet est limite uniforme d'une suite de fonctions polynômiales.
\end{corollary}

\subsection*{C. Équicontinuité}

\begin{definition}[\textnormal{[HL] 37}]
	Soit $\A\in\mathcal{C}(X,Y)$. On dit que $\A$ est :
	\begin{itemize}
		\item \emph{équicontinue en $x_0\in X$} si $\forall \varepsilon >0,\,\exists\eta >0\,\colon \forall f\in\A,\,\forall x\in X,\, d(x_0,x)<\eta\implies\delta(f(x), f(x_0))< \varepsilon$.
		\item \emph{uniformément équicontinue} si $\forall\varepsilon > 0,\,\exists \eta > 0\,\colon \forall f\in \A,\,\forall (x,y)\in X^2,\, d(x,y)< \eta\implies \delta(f(x),f(y))< \varepsilon$.
	\end{itemize}
\end{definition}

\begin{proposition}[\textnormal{[HL] 38}]
	$(X,d)$ étant compact, $\A$ est uniformément équicontinue si, et seulement si, elle est équicontinue en tout point de $X$.
\end{proposition}

\begin{example}[\textnormal{[HL] 38}]
	Toute famille finie de $\mathcal{C}(X,Y)$ est uniformément équicontinue, de même que les familles de fonctions $k$-lipschitziennes, pour tout $k> 0$ fixé.
\end{example}

\begin{theorem}[d'\textsc{Ascoli-Arzelà} - \textnormal{[HL] 39}]
	Les parties compactes de $C(X,Y)$ sont les fermés bornés équicontinus.
\end{theorem}

\begin{example}[\textnormal{[HL] 39}]
	Munissons $Y$ d'une mesure $\mu$ finie, et supposons $Y$ compact.
	Pour $K \in C(X\times Y,\IR)$, on définit $T_K\,\colon C(Y,\IR)\to C(X,\IR),\, f\mapsto \int_Y K(\cdot, y)f(y)d\mu(y)$.
	Alors $\overline{T_K(\overline{\B_{C(Y)}(0,1)})}$ est compact.
\end{example}

\section*{III. Compacité dans les espaces vectoriels normés}
\textcolor{paragraphtext}{On fixe $(E,\|\cdot \|_E)$ et $(F,\|\cdot\|_F)$ deux $\IK$-espaces de Banach.}

\subsection*{A. Parties compactes et dimension finie}
\begin{theorem}
	Si $E$ est de dimension finie, alors ses compacts sont les fermés bornés.
\end{theorem}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[\textnormal{[G] 50}]
	\label{203dev21}
	Si $E$ est de dimension finie, alors toutes ses normes sont équivalentes.
\end{theorem}
\begin{theorem}[de \textsc{Riesz} - \textnormal{[G] 56}]
	\label{203dev22}
	$E$ est de dimension finie si, et seulement si, sa boule unité fermée (pour une norme quelconque) est compacte.
\end{theorem}
\end{tcolorbox}

\begin{example}[\textnormal{[G] 33}]
	Supposons $E$ de dimension finie. Soit $f\,\colon E\to \IR$ continue.
	Si $f(x) \to_{\|x\|\to +\infty}+\infty$, alors $f$ est minorée et atteint son minimum.
\end{example}

\subsection*{B. Opérateurs compacts}
\begin{definition}[\textnormal{[HL] 186}]
	On dit que $T\in\mathcal{L}(E,F)$ est \emph{compact} si $\overline{T(\overline{\B_E(0,1)})}$ est compact.
\end{definition}

\begin{example}[\textnormal{[HL] 186}]
	Les opérateurs à noyau, \emph{i.e.} de la forme donnée dans Exemple 37, sont des opérateurs compacts.
\end{example}

\begin{proposition}[\textnormal{[HL] 186}]
	\begin{itemize}
		\item Les opérateurs de rang fini sont compacts ;
		\item $\id_E$ est compact si, et seulement si, $E$ est de dimension finie.
	\end{itemize}
\end{proposition}

\begin{notation}
	On note $\mathcal{K}(E,F)$ l'ensemble des opérateurs compactes de $E$ dans $F$, et $\mathcal{K}(E) = \mathcal{K}(E,E)$.
\end{notation}

\begin{proposition}[\textnormal{[HL] 187}]
	$\mathcal{K}(E)$ est un idéal.
\end{proposition}

\begin{proposition}[\textnormal{[HL] 187}]
	$\mathcal{K}(E,F)$ est un fermé de $(\mathcal{L}(E,F), \vertiii \cdot)$.
\end{proposition}

\begin{corollary}[\textnormal{[HL] 188}]
	Une limite d'une suite d'opérateurs de rang fini est compacte.
\end{corollary}

\section*{Développements}
\begin{itemize}
	\item Développement 1 : Exemple \ref{203dev11} et Théorème \ref{203dev12}
	\item Développement 2 : Théorèmes \ref{203dev21} et \ref{203dev22}
\end{itemize}

\section*{Références}
\begin{itemize}
	\item[G] \emph{Les maths en tête - Analyse}, Xavier Gourdon, 3e édition 
	\item[HL] \emph{Éléments d'analyse fonctionnelle}, Francis Hirsch, Giles Lacombe
	\item[R] \emph{Éléments d'analyse réelle}, Jean-Etienne Rombaldi, 2e édition
	\item[Rv] \emph{Petit guide du calcul différentiel}, François Rouvier, 4e édition
\end{itemize}


\chapter*{208 : Espaces vectoriels normés, applications linéaires continues. Exemples.}
\setcounter{definition}{0}

\textcolor{paragraphtext}{Dans cette leçon, $\IK$ désigne $\IR$ ou $\IC$, et $E$ et $F$ deux $\IK$-espaces vectoriels.}
\section*{I. Normes et opérateurs sur un espace vectoriel}
\subsection*{A. Norme sur un espace vectoriel}

\begin{definition}[\textnormal{[G] 7}]
	Une \emph{norme sur $E$} est une application $N\,\colon E\to\IR^+$ telle que :
	\begin{itemize}
		\item $\forall x\in E,\, \|x\|=0\implies x=0$ (séparation)
		\item $\forall x\in E,\,\forall\lambda\in\IR,\,\|\lambda x\|=\vert\lambda\vert\cdot\|x\|$ (homogénéité)
		\item $\forall (x,y)\in E^2,\, \|x+y\|\leq \|x\|+\|y\|$ (inégalité triangulaire)
	\end{itemize}
\end{definition}

\begin{example}[\textnormal{[G] 7-8}]
	\begin{itemize}
		\item Le module est une norme sur $\IK$ ;
		\item Sur $\IK^n$, $\|\cdot\|_p\,\colon (x_1,\dots, x_n)\mapsto \left(\sum_{k=1}^{n} \vert x_k\vert^p\right)^{1/p}$, avec $p\in [1,+\infty[$ est une norme ;
		\item Sur $\IK^n$, $\|\cdot\|_p\,\colon (x_1,\dots, x_n)\mapsto \max_{1\leq k\leq n} \vert x_k\vert$ est une norme ;
		\item Soit $(X,d)$ un espace métrique compact. L'application suivante est une norme : $$\|\cdot\|_{\infty}\,\colon f\in\mathcal{C}(X,\IK)\mapsto \max_{x\in X}\vert f(x)\vert$$
		\item Pour $p\in [1,+\infty[$, $\|\cdot\|_p\,\colon f\in\mathcal{C}([a,b],\IK)\mapsto \left(\int_{a}^{b}\vert f(t)\vert^p dt\right)^{1/p}$ est une norme.
	\end{itemize}
\end{example}

\begin{definition}[\textnormal{[G] 47}]
	Soient $N_1$ et $N_2$ deux normes sur $E$. On dit que $N_1$ et $N_2$ sont \emph{équivalentes} s'il existe $\alpha > 0$ et $\beta > 0$ tels que $\alpha N_1\leq N_2\leq \beta N_1$.
\end{definition}

\begin{example}
	\begin{itemize}
		\item Sur $\IK^n,\,\|\cdot\|_{\infty}\leq \|\cdot\|_2\leq n\|\cdot\|_{\infty}$.
		\item Sur $C([0,1], \IK)$, $\|\cdot\|_1 \leq \|\cdot\|_{\infty}$, mais $\|\cdot\|_{\infty}\not \leq  \|\cdot\|_1$.
	\end{itemize}
\end{example}

\begin{proposition}
	\begin{itemize}
		\item Sur $\IK^n$, pour $p\in[1,+\infty[$, $\|\cdot\|_p\leq n^{\frac{1}{p}}\|\cdot\|_{\infty}$
		\item Sur $\mathcal{C}([a,b],\IK)$, pour $p\in[1,+\infty[$, $\|\cdot\|_p\leq (b-a)^{\frac{1}{p}}\|\cdot\|_{\infty}$.
	\end{itemize}

	Corollaire : sur ces deux espaces, $\|\cdot\|_p \to_{p\to +\infty}\|\cdot\|_{\infty}$.
\end{proposition}

\begin{definition}[\textnormal{[BP] 157, 158, 175}]
	Soit $(X,\A,\mu)$ un espace mesuré. Pour $p\in [1,+\infty]$, on note $L^p(X,\A, \mu)$ l'\emph{espace de \textsc{Lebesgue}}, et $\|\cdot\|_p$ la norme usuelle sur $L^p(X,\A,\mu)$.
	Les esâce $\left(L^p(\Omega,\A,\mu), \|\cdot\|_p\right)$ sont des espaces vectoriels normés.
\end{definition}

\subsection*{B. Opératuers (applications linéaires continues)}

\begin{theorem}[\textnormal{[G] 48}]
	Soit $T\,\colon E\to F$ linéaire. Sont équivalentes :
	\begin{enumerate}
		\item $T$ est continu sur $E$
		\item $T$ est continu en $0_E$
		\item $T$ est uniformément continue sur $E$
		\item $T$ est lipschitzien 
		\item $T$ est borné sur $E$, \emph{i.e.} $\exists C>0\,\colon \forall x\in E,\,\|Tx\| \leq C\|x\|$
		\item $T$ est borné sur $\overline{\B(0,1)}$
		\item $T$ est borné sur $S(0,1)$
	\end{enumerate}
\end{theorem}

\begin{notation}
	On note $\mathcal{L}(E,F)$ l'ensemble des applications linéaires \underline{continues} de $E$ dans $F$.
	On pose également $\mathcal{L}(E)=\mathcal{L}(E,E)$.
\end{notation}

\begin{example}
	L'application $D\,\colon \left(C^1([0,1]),\|\cdot\|_{\infty}\right)\to \left(C^0([0,1]), \|\cdot\|_{\infty}\right)$, $f\mapsto f'$ est 
	linéaire mais pas continue. Cependant, elle le devien si on munit $C^1([0,1])$ de la norme $f\mapsto \|f\|_{\infty} + \|f'\|_{\infty}$. La continuité dépend donc de la norme !
\end{example}

\begin{proposition}
	La continuité est préservée pour des normes équivalentes.
\end{proposition}

\begin{definition}[\textnormal{[G] 48}]
	Soient $\|\cdot\|_E$ et $\|\cdot\|_F$ deux normes sur $E$ et sur $F$. Soit $T\in\mathcal{L}(E,F)$.
	On pose $\vertiii{T} = \sup \left\{\frac{\|Tx\|_F}{\|x\|_E}\,\mid x\in E\setminus \left\{0\right\}\right\}$.
\end{definition}

\begin{proposition}[\textnormal{[G] 48}]
	L'application $\vertiii{\cdot}$ est appelée \emph{norme d'opérateur}, ou \emph{norme subordonnée à $\|\cdot\|_E$ et $\|\cdot\|_F$}. C'est une norme sur $\mathcal{L}(E,F)$. 
\end{proposition}

\begin{example}
	\begin{itemize}
		\item Soit $T\,\colon u\in l^{\infty}(\IN)\mapsto \sum_{n=0}^{+\infty} \frac{u_n}{12^n}$ : on a $\vertiii{T} = \frac{12}{11}$.
		\item Soit $T\,\colon f\in\left(\mathcal{C}([0,1], \|\cdot\|°{\infty})\right) \mapsto f'$ : on a $\vertiii{T} = 1$.
	\end{itemize}
\end{example}

\begin{proposition}[\textnormal{[G] 48}]
	Soit $(G,\|\cdot\|_G)$ un espace vectoriel normé.
	$\forall f\in \mathcal{L}(E,F),\,\forall g\in\mathcal{L}(F,G),\, \vertiii{g\circ f}\leq \vertiii{f}\cdot\vertiii{g}$.
\end{proposition}

\begin{proposition}[\textnormal{[G] 48}]
	Soit $T\in\mathcal{L}(E,F)$.
	\begin{align*}
		\vertiii{T} &= \sup_{\|x\|_2\leq 1} \|Tx\|_F \\
		&= \sup_{\|x\|_2 = 1} \|Tx\|_F \\
		&= \inf\left\{c>0\mid \forall x\in E,\, \|Tx\|_F \leq C\|x\|_E\right\}
	\end{align*}
\end{proposition}

\begin{lemma}
	Si $T\,\colon E\to F$ est linéaire, alors $T$ est de rang fini $r$ si, et seulement si, il existe $\varphi_1,\dots,\varphi_r\,\colon E\to \IK$ linéaires, linéairement indépendantes, et $(a_1,\dots,a_r)\in F^r$ libre, telles que $\forall x\in E,\, T(x) = \sum_{i=1}^{r}\varphi_i(x) a_i$.
\end{lemma}

\begin{theorem}[\textnormal{[G] e55-56}]
	Soit $T\,\colon E\to F$ linéaire et de rang fini.
	$T$ est continu si, et seulement si, $\Ker T$ est fermé.
\end{theorem}

\section*{II. Espaces de dimension finie}
\textcolor{paragraphtext}{Dans ce paragraphe, on suppose $E$ de dimension finie $n$.}
\subsection*{A. Équivalence des normes}
\begin{definition}
	Soit $\B$ une base de $E$. Soit $x\in E$, notons $(x_1,\dots, x_n)$ le vecteur coordonées de $x$ dans $\B$. Pour $p\in[1,+\infty]$, on définit $\|x\|_p$ comme étant $\|(x_1,\dots, x_n)\|_p$ dans $\IK^n$.
\end{definition}

\begin{proposition}
	Toute norme sur $E$ est une application continue de $\left(E,\|\cdot\|_{\infty}\right)$ dans $\left\{\IR, \vert\cdot\vert\right\}$.
\end{proposition}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[\textnormal{[G] 50}]
	\label{208dev11}
	Toutes les normes sur $E$ sont équivalentes.
\end{theorem}
\end{tcolorbox}

\begin{corollary}[\textnormal{[G] 50}]
	Toute application linéaire de $E$ dans $F$ est continue.
\end{corollary}

\begin{corollary}[\textnormal{[G] 50}]
	$E$ est complet.
\end{corollary}

\begin{corollary}[\textnormal{[G] 50}]
	Tout sous-espace vectoriel de dimension finie est fermé.
\end{corollary}

\begin{application}
	Soit $M$ un sous-espace vectoriel de $F$ de dimension finie.
	Alors, $\forall y\in F,\,\exists x\in M\,\colon d(y,F) = \|x-y\|_F$.
\end{application}

\begin{corollary}[\textnormal{[G] 50}]
	Les compacts de $E$ sont les fermés bornés.
\end{corollary}

\begin{remark}
	On munit $\IR[X]$ de $\|\cdot\|_{\infty}\,\colon \sum_{k=0}^{+\infty}a_kX^k\mapsto \max_{k\in\IN} \vert a_k\vert$.
	La boule unité est fermée et bornée, mais elle n'est pas compacte : la dimension finie est donc cruciale !
\end{remark}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[de \textsc{Riesz} - \textnormal{[G] 56}]
	\label{208dev12}
	$E$ est de dimension finies si, et seulement si, $\overline{\B_E(0,1)}$ est compacte.
\end{theorem}
\end{tcolorbox}


\subsection*{B. Normes matricielles}

\begin{definition}
Une \emph{norme matricielle} est une norme d'algèbre sur $\M_n(\IK)$, \emph{i.e.} une norme $\vertiii{\cdot}$ vérifiant $\forall (A,B)\in\M_n(\IK)^2$, $\vertiii{AB}\leq \vertiii{A}\cdot\vertiii{B}$.
\end{definition}

\begin{example}
	D'après Proposition 14, tout norme subordonée à une norme sur $\IK^n$ est une norme matricielle, en confondant $\IK^n$ et $\M_{n,1}(\IK)$, et $\M_n(\IK)$ et $\mathcal{L}(\IK^n)$.
\end{example}

\begin{theorem}[\textnormal{[Rv] 24}]
	Pour $(p,q)\in[1,+\infty]^2$, pour $A\in\M_n(\IK)$, on pose $\vertiii{A}_{p,q} = \sup\left\{\frac{\|Ax\|_p}{\|x\|_q}\,\colon x\in\IK^n\setminus \{0\}\right\}$
	Soit $A =\left(a_{i,j}\right)_{1\leq i,j\leq n}$. On a :
	\begin{itemize}
		\item $\vertiii{A}_{1,1} = \max_{1\leq j\leq n}\sum_{i=1}^{n}\vert a_{i,j}\vert$
		\item $\vertiii{A}_{\infty,\infty} = \max_{1\leq i\leq n}\sum_{j=1}^{n}\vert a_{i,j}\vert$
		\item $\vertiii{A}_{2,2} = \sqrt{\rho(AA^*)} = \sqrt{\rho(A^*A)} = \vertiii{A^*}_2$ où $A^* = {}^t\overline{A}$ et $\rho(M) = \max_{\lambda\in\Sp(M)} \vert \lambda \vert$.
	\end{itemize}
\end{theorem}

\section*{III. Espaces de Banach : exemples et applications}
\subsection*{A. Définition et premiers exemples}

\begin{definition}[\textnormal{[G] 47}]
	Un \emph{espace de Banach} est un espace vectoriel normé complet.
\end{definition}

\begin{example}
	\begin{itemize}
		\item Tout espace vectoriel normé de dimension finie est un espace de Banach.
		\item $\mathcal{C}([a,b], \IK)$ est de Banach pour $\|\cdot\|_{\infty}$ mais pas pour $\|\cdot\|_1$.
	\end{itemize}
\end{example}

\begin{theorem}[de \textsc{Riezs-Fisher} - \textnormal{[BP] 166-176}]
	$\left(L^p(X,\A,\mu), \|\cdot\|_p\right)$ est un espace de Banach.
\end{theorem}

\begin{proposition}[\textnormal{[G] 48}]
	Si $N_1$ et $N_2$ sont deux normes équivalentes sur $E$, et si $(E, N_1)$ est de Banach pour $N_1$, alors $(E,N_2)$ est de Banach.
\end{proposition}

\begin{theorem}
	$(E,N)$ est de Banach si, et seulement si, toutes ses séries normalement convergentes sont convergentes (dans $(E,N)$).
\end{theorem}

\begin{proposition}[\textnormal{[G] 49}]
	Si $(F,\|\cdot\|_F)$ est de Banach, alors $\left(\mathcal{L}(E,F),\vertiii{\cdot}\right)$ est de Banach.
\end{proposition}

\begin{application}[lemme de \textsc{von Neumann} - \textnormal{[G] 49}]
	Soit $u\in\mathcal{L}(E)$ avec $E$ de Banach. Si $\vertiii{u}<1$, alors $\id_E-u$ est inversible, d'inverse $\sum_{k=0}^{+\infty} u^k$.
\end{application}

\subsection*{B. Espaces de Hilbert}

\begin{definition}[\textnormal{[HL] 84}]
	Un \emph{produit scalaire hermitien sur $E$} est une application $\langle\cdot,\cdot\rangle\,\colon E^2\to \IK$ telle que pour tous $(x,y,z)\in E^3$ et $\lambda\in \IK$, on a :
	\begin{itemize}
		\item $\langle x+\lambda y, z\rangle = \langle x,z\rangle + \lambda\langle y,z\rangle$
		\item $\langle x, y+ \lambda z\rangle = \langle x,y\rangle + \overline{\lambda}\langle x,z\rangle$
		\item $\langle x,y \rangle = \overline{\langle y, x\rangle}$
		\item $\langle x,x\rangle \geq 0$
		\item $\langle x,x \rangle = 0\implies x = 0$
	\end{itemize}

	L'application $\|\cdot\|\,\colon x\mapsto\sqrt{\langle x,x\rangle}$ est une norme sur $E$, appelée \emph{norme associée au produit scalaire hermitien $\langle\cdot,\cdot\rangle$.}
\end{definition}

\begin{example}[\textnormal{[HL] 84}]
	\begin{itemize}
		\item Sur $\IK^n,\, (x,y)\mapsto \sum_{i=1}^{n} x_i \overline{y_i}$ est un produit scalaire hermitien.
		\item Sur $L^2(X\A,\mu),\, (f,g)\mapsto \int_Xf(x)\overline{g(x)}d\mu(x)$ est un produit scalaire hermitien.
	\end{itemize}
\end{example}

\begin{definition}[\textnormal{[HL] 88}]
	On dit que $(H, \langle\cdot,\cdot\rangle)$ est un \emph{espace de Hilbert} si $(H,\|\cdot\|)$ est 
	un espace de Banach pour la norme $\|\cdot\|$ associée à $\langle\cdot,\cdot\rangle$.
\end{definition}

\begin{example}[\textnormal{[HL] 88}]
	Munis des produits scalaires hermitiens de Ex 39, $\IK^n$ et $L^2(X,\A,\mu)$ sont des espaces de Hilbert.
\end{example}

\begin{theorem}[de \textsc{Fréchet - von Neumann - Jordan}]
	Une norme $\|\cdot\|$ est associée à un produit scalaire hermitien si, et seulement si, elle vérifie l'identité du parallélogramme :
	\begin{align*}
		\forall x,y,\, \|x+y\|^2 + \|x-y\|^2 = 2(\|x\|^2 + \|y\|^2)
	\end{align*}

	Le cas échéant, le produit scalaire hermitien associé est $(x,y)\mapsto \frac{1}{4}\sum_{k=0}^{3} i^k\|x+i^ky\|$.
\end{theorem}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[de projection sur un convexe fermé - \textnormal{[HL] 91}]
	\label{208dev21}

	Soient $(H,\langle\cdot,\cdot\rangle)$ un espace de Hilbert et $C$ un convexe de $H$. Alors :
	\begin{align*}
		\forall x\in H,\, \exists ! y\in C\,\colon \|x-y\| = d(x,C)
	\end{align*}
\end{theorem}

\begin{theorem}[de \textsc{Riesz}]
	\label{208dev22}
	$\forall\varphi \in H',\, \exists ! x\in H\,\colon \varphi\langle \cdot \mid x\rangle$.
\end{theorem}
\end{tcolorbox}


\section*{Développements}
\begin{itemize}
	\item Développement 1 : Théorèmes \ref{208dev11} et \ref{208dev12}
	\item Développement 2 : Théorèmes \ref{208dev21} et \ref{208dev22}
\end{itemize}

\section*{Références}
\begin{itemize}
	\item[G] \emph{Les maths en tête - Analyse}, Xavier Gourdon, 3e édition 
	\item[HL] \emph{Éléments d'analyse fonctionnelle}, Francis Hirsch, Giles Lacombe
	\item[BP] \emph{Théorie de l'intégration}, Marc Briane, Filles Pagès, 7e édition
	% \item[R] \emph{Éléments d'analyse réelle}, Jean-Etienne Rombaldi, 2e édition
	\item[Rv] \emph{Petit guide du calcul différentiel}, François Rouvier, 4e édition
\end{itemize}

\chapter*{213 : Espaces de Hilbert. Exemples d’applications.}
\setcounter{definition}{0}

\textcolor{paragraphtext}{Dans cette leçon, $\IK$ désigne $\IR$ ou $\IC$, et $H$ est un $\IK$-espace vectoriel.}

\section*{I. Les espaces de Hilbert et leur structure}
\subsection*{A. Produit scalaire / hermitien, orthogonalité}

\begin{definition}[\textnormal{[HL] 84}]
	Un \emph{produit scalaire} est une application $\ps{\cdot}{\cdot}\,\colon H^2\to\IK$ vérifiant :
	$\forall (x,y,z)\in H^3$, $\forall\lambda\in\IK$,
	\begin{itemize}
		\item $\ps{x+\lambda y}{z} = \ps{x}{z}+\lambda\ps{y}{z}$
		\item $\ps{x}{y} = \overline{\ps{y}{x}}$
		\item $\ps{x}{x} \geq 0$
		\item $\ps{x}{x} = 0 \implies x=0$
	\end{itemize}
\end{definition}

\begin{example}[\textnormal{[HL] 84}]
	\begin{itemize}
		\item $(\underline{x},\underline{y})\mapsto \sum_{k=1}^{n} x_k\overline{y_k}$ est un produit scalaire sur $\IK^n$ (dit \emph{usuel}).
		\item $(f,g)\mapsto\int_{0}^{1} f\overline{g}$ est un produit scalaire sur $C^0([0,1])$.
		\item $(A,B)\mapsto \tr(A{}^t\overline{B})$ est un produit scalaire sur $\M_n(\IK)$.
	\end{itemize}
\end{example}

\textcolor{paragraphtext}{On fixe un produit scalaire $\ps{\cdot}{\cdot}$.}

\begin{proposition}[\textnormal{[HL] 86}]
	$\|\cdot\|\,\colon x\mapsto\sqrt{\ps{x}{x}}$ est une norme sur $H$, dite \emph{associée à $\ps{\cdot}{\cdot}$.}
\end{proposition}

\begin{definition}[\textnormal{[HL] 86,88}]
	On dit que $(H,\ps{\cdot}{\cdot})$ est un \emph{espace préhilbertien}.
	Si $(H, \|\cdot\|)$ est complet, alors $(H,\ps{\cdot}{\cdot})$ est un \emph{espace de Hilbert}.
\end{definition}

\begin{example}[\textnormal{[HL] 88}]
	\begin{itemize}
		\item Un espace euclidien ou hermitien est de Hilbert.
		\item $l^2(\IN)$ est un espace de Hilbert pour $\ps{\cdot}{\cdot}\,\colon (u,v)\mapsto\sum_{n=0}^{+\infty} u_n\overline{v_n}$.
	\end{itemize}
\end{example}

\textcolor{paragraphtext}{On suppose désormais que $(H, \ps{\cdot}{\cdot})$ est un espace de Hilbert.}

\begin{theorem}[inégalité de \textsc{Cauchy-Schwarz} - \textnormal{[HL] 86}]
	Pour tout $(x,y)\in H^2$, $\vert \ps{x}{y}\vert \leq \|x\|\cdot\|y\|$ avec égalité si, et seulement si, $(x,y)$ est liée.
\end{theorem}

\begin{application}
	On définit l'\emph{écart angulaire} entre deux vecteurs non nuls $x,y\in H$ comme $\arccos\left(\frac{\vert \ps{x}{y}\vert}{\|x\|\cdot\|y\|}\right)$.
\end{application}

\begin{theorem}[identité du parallélogramme - \textnormal{[HL] 87}]
	$\forall x,y\in H$, on a 
	$$2(\|x\|^2+\|y\|^2) = \|x+y\|^2 + \|x-y\|^2$$
\end{theorem}

\begin{remark}
	Une norme sur $H$ est associée à un produit scalaire si, et seulement si, elle vérifie l'identité du parallélogramme (= théorème de \textsc{Fréchet - von Neumann - Jordan}).
\end{remark}

\begin{definition}[\textnormal{[HL] 87}]
	Soit $A\subseteq H$. On définit l'\emph{orthogonal de $A$} comme :
	$$A^{\perp} = \left\{x\in H \mid \forall y\in A,\, \ps{x}{y} = 0\right\} = \bigcap_{y\in A} \Ker\left(\ps{\cdot}{y}\right)$$
\end{definition}

\begin{proposition}[\textnormal{[HL] 87}]
	Soient $A\subseteq H$ et $B\subseteq H$.
	\begin{itemize}
		\item $A^{\perp}$ est un sous-espace vectoriel fermé de $H$,
		\item $B\subseteq A\implies A^{\perp}\subseteq B^{\perp}$
		\item $A^{\perp}=\Vect(A)^{\perp}=\overline{A}^{\perp}$
		\item $A\cap A^{\perp} \subseteq \left\{0\right\}$
		\item $A\subseteq A^{\perp\perp}$
	\end{itemize}
\end{proposition}

\begin{example}
	???
\end{example}

\subsection*{B. Projection sur un convex fermé, conséquences}
\textcolor{paragraphtext}{Soient $C$ un convexe fermé non vide de $H$ et $F$ un sous-espace vectoriel fermé de $H$.}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[de projection sur un convexe fermé - FIG. 1 - \textnormal{[HL] 91}]
	\label{213dev1a}
	$\forall x\in H,\, \exists ! P_C(x)\in C\,\colon \|x-P_C(x)\| = d(x,C) =: \inf_{y\in C} \|x-y\|$.

	De plus, $P_C(x)$ est caractérisé par $\forall y\in C,\, \Re(\ps{x-P_C(x)}{x-y})\leq 0$.

	Dans le cas de $F$, le projeté $P_F(x)$ est caractérisé par $P_F(x)\in F$ et $x-P_F(x)\in F^{\perp}$.
\end{theorem}
\end{tcolorbox}

\begin{corollary}[\textnormal{[HL] 92-93}]
	$P_C$ est $1$-lipschitzienne, $P_F$ est un projecteur orthogonal de norme $1$.
\end{corollary}

\begin{cexample}
	C'est faux si $H$ est seulement de Banach : dans $(\IR^2,\|\cdot\|_{\infty})$, tous les $(x,0)$ tels que $-1\leq x\leq 1$ réalisent $d\left(\begin{pmatrix}
		0\\1
	\end{pmatrix}, \Vect\left(\begin{pmatrix}
		1\\0
	\end{pmatrix}\right)\right)$.
\end{cexample}

\begin{corollary}[\textnormal{[HL] 93}]
	$H = F\oplus F^{\perp}$ (et $H = \overline{F}\oplus F^{\perp}$ si $F$ n'est pas supposé fermé).
\end{corollary}

\begin{cexample}
	C'est faux si $F$ n'est pas fermé : dans $H = l^2(\IN)$, pour $F = \IK^{(\IN)}$, on a $F^{\perp} = \left\{0\right\}$ mais $H = F\oplus \left\{0\right\} = F$.
\end{cexample}

\begin{corollary}[\textnormal{[HL] 94-93}]
	On a :
	\begin{itemize}
		\item $F = F^{\perp\perp}$
		\item Pour tout sous-espace vectoriel $G$ de $H$, $\overline{G} = H \iff G^{\perp} = \left\{0\right\}$
	\end{itemize}
\end{corollary}


\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[de représentation de \textsc{Riesz} - \textnormal{[HL] 96}]
	\label{213dev1b}
	$J\,\colon H\to H'$, $y\mapsto\ps{\cdot}{y}$ est un isomorphisme d'espaces de Hilbert, \emph{i.e.} une isométrie linéaire surjective.
\end{theorem}
\end{tcolorbox}

\begin{application}[\textnormal{[Bu] 501, [G] 324}]
	\begin{itemize}
		\item Pour tout $x,y\in \IR^3$, il existe un unique vecteur $x\wedge y\in \IR^3$ appelé \emph{produit vectoriel de $x$ et $y$} tel que $[x,y,\cdot] = \ps{\cdot}{x\wedge y}$ où $[\cdot,\cdot,\cdot]$ est le produit mixte.
		\item Soit $f\,\colon \IR^n\to \IR$ différentiable en $a\in\IR^n$. Il existe un unique vecteur $\nabla f(a)\in\IR^n$ appelé \emph{gradiant de $f$ en $a$}, tel que $df(a) = \ps{\cdot}{\nabla f(a)}$. 
	\end{itemize}
\end{application}

\begin{definition}[\textnormal{[HL] 97}]
	Pour tout $T\in\mathcal{L}(H)$, il existe un unique $T^*\in\mathcal{L}(H)$ tel que $\forall x,y\in H$, $\ps{Tx}{y}=\ps{x}{T^*y}$. On l'appelle \emph{adjoint de $T$}.
	On dit que $T$ est \emph{auto-adjoint} si $T = T^*$.
\end{definition}

\subsection*{C. Notion de base hilbertienne}

\begin{definition}[\textnormal{[HL] 107-108 ?}]
	Soit $(e_i)_{i\in I}$ une famille déléments de $H$. On dit que $(e_i)_{i\in I}$ est :
	\begin{itemize}
		\item \emph{orthogonale} si $\forall (i,j)\in I^2,\, i\neq j\implies \ps{e_i}{e_j} = 0$
		\item \emph{orthonormale} si $\forall (i,j)\in I^2,\, \ps{e_i}{e_j} = \delta_{i,j}$
		\item \emph{totale} si $\overline{\Vect(\left\{e_i\right\}_{i\in I})} = H$.
	\end{itemize}
\end{definition}

\begin{definition}[\textnormal{[HL] 108}]
	Une \emph{base hilbertienne} de $H$ est une famille orthonormale et totale.
\end{definition}

\begin{theorem}[ADMIS - \textnormal{[HL] 113}]
	$H$ est séparable $\iff$ $H$ admet une base hilbertienne dénombrable.
\end{theorem}

\textcolor{paragraphtext}{Dans la suite, on suppose $H$ séparable, et $(e_n)_{n\in\IN}$ désigne une base hilbertienne de $H$.}

\begin{example}[\textnormal{[HL] ? - 108}]
	\begin{itemize}
		\item En dimension finie pour le produit scalaire usuel, toute base (algébrique) orthonormée est hilbertienne.
		\item $\left((\delta_{k,n})_{n\in\IN}\right)_{k\in\IN}$ est une base hilbertienne de $l^2(\IN)$.
	\end{itemize}
\end{example}

\begin{remark}
	Dans un espace euclidien ou hermitien, les notions de base hilbertienne et de base (algébrique) orthogonal coincident. Ce n'est plus vrai en dimension infinie, comme on le verra par la suite.
\end{remark}

\begin{proposition}[\textnormal{[HL] 109}]
	Soit $(e_0,\dots,e_n)\in H^{n+1}$ une famille orthonormale, posons $F = \Vect(e_0,\dots, e_n)$.
	Alors,
	$$P_F = \sum_{k=0}^{n} \ps{\cdot}{e_k}e_k$$
\end{proposition}

\begin{theorem}[procédé de \textsc{Gram-Schmidt} - FIG. 2 - \textnormal{[HL] 112}]
	Soit $\left(f_n\right)_{n\in\IN}$ libre. On définit $e_1 = \frac{f_1}{\|f_1\|}$ et pour tout $n\in \IN^*$, $\tilde{e}_k = f_k - \sum_{i=0}^{k-1}e_i = f_k - P_{\Vect(e_0,\dots, e_{k-1})}(f_k)$
	et $e_k = \frac{\tilde{e}_k}{\|\tilde{e}_k\|}$.

	La famille $\left(e_n\right)_{n\in \IN}$ est orthonormale.
\end{theorem}

\begin{theorem}[\textnormal{[HL] e103}]
	Soit $\left(e_n\right)_{n\in\IN}$ une famille orthonormée.
	Les assertions suivantes sont équivalentes :
	\begin{itemize}
		\item $\left(e_n\right)_{n\in\IN}$ est une base hilbertienne de $H$
		\item $\forall x\in H$, $x = \sum_{n=0}^{+\infty} \ps{x}{e_n}e_n$ au sens $\|x - \sum_{n=0}^{N}\ps{x}{e_n}e_n \longrightarrow_{N\to +\infty} 0$
		\item $\forall x\in H$, $\|x\|^2 = \sum_{n=0}^{+\infty}\vert \ps{x}{e_n}\vert^2$ (égalité de \textsc{Bessel-Parseval})
		\item $\left\{e_n\right\}_{n\in\IN}^{\perp} = \left\{0\right\}$.
	\end{itemize}
\end{theorem}

\begin{theorem}[\textnormal{[HL] 109}]
	$x\mapsto (\ps{x}{e_n})_{n\in \IN}$ est un isomorphisme d'espaces de Hilbert de $H$ dans $l^2(\IN)$.
\end{theorem}

\section*{II. L'exemple fondamental : les espace $L^2$}
\begin{theorem}[\textnormal{[HL] e125}]
	Soit $(X,\A, \mu)$ un espace mesuré. Pour $f$ et $g$ dans $L^2(X,\A,\mu)$, posons $\ps{f}{g}= \int_{X}f(x)\overline{g(x)}d\mu(x)$ (produit scalaire usuel).
	L'espace $L^2(X,\A,\mu)$ muni de $\ps{\cdot}{\cdot}$ est un espace de Hilbert.
\end{theorem}

\subsection*{A. Cas des fonctions périodiques : séries de \textsc{Fourier}}
\textcolor{paragraphtext}{Dans ce paragraphe, $H = L^2_{2\pi}$ est l'espace des fonctions $2\pi$-périodiques de carré intégrable sur $[-\pi,\pi]$.
On pose $\forall f,g\in H,\, \ps{f}{g} = \int_{-\pi}^{\pi}f(t)\overline{g(t)}\frac{dt}{2\pi}$. Pn pose $\forall n\in \IZ,\, e_n\,\colon t\mapsto e^{int}$. On not $\sum_{n=-\infty}^{+\infty} u_n = \lim_{N\to +\infty}\sum_{n=-N}^{N} u_n$
et $\sum_{n\in \IZ}u_n = u_0 + \sum_{n\in\IN^*} u_n + u_{-n}$.}

\begin{proposition}[\textnormal{[EA] 172}]
	$\left(e_n\right)_{n\in \IZ}$ est orthonormale.
\end{proposition}

\begin{definition}[\textnormal{[EA] 173}]
	Pour $n\in \IZ$ et $f\in L_{2\pi}^1$, on pose $c_n(f) = \int_{-\pi}^{\pi}f(t)e^{-int}\frac{dt}{2\pi}$.
	Si $f\in L^2_{2\pi}$, alors $c_n(f)=\ps{f}{e_n}$. On l'appelle \emph{$n$-ième coefficient de \textsc{Fourier} de $f$}.
\end{definition}

\begin{definition}[\textnormal{[EA] 184-186}]
	Soient $f\in H$ et $N\in \IN^*$. On pose :
	\begin{itemize}
		\item $D_N = \sum_{n=-N}^{N} e_n$ (\emph{noyau de \textsc{Dirichlet}})
		\item $K_N = \frac{1}{N}\sum_{n=0}^{N_1} D_n = \sum_{n=-N}^{N} (1-\frac{\vert n\vert}{N})e_n$ (\emph{noyau de \textsc{Féjer}})
		\item $S_N(f) = \sum_{n=-N}^{N}c_n(f)e_n = D_n * f$
		\item $\sigma_N(f) = \frac{1}{N}\sum_{n=0}^{N_1}S_n(f) = K_N * f$
	\end{itemize}
\end{definition}

\begin{remark}
	$S_N(f)$ est le projeté de $f$ sur $\Vect\left(\left\{e_n\right\}_{-N\leq n\leq N}\right)$.
\end{remark}

\begin{proposition}[\textnormal{[EA] 184-186}]
	Soient $N\in \IN^*$ et $t\in \IR$.
	\begin{itemize}
		\item $D_N(-t) = D_N(t)=\sin\left((N+\frac{1}{2})t\right) / \sin(t/2)$
		\item $\|D_N\|_1 = 1$
		\item $K_N(t) = \frac{1}{N}\left(\frac{\sin(\frac{NT}{2})}{\sin(\frac{t}{2})}\right)^2\geq 0$
		\item $\|K_N\|_1 = 1$
		\item $\forall \delta\in ]0,\pi],\, \int_{\pi \geq \vert t \vert \geq \delta}K_N(t)dt \longrightarrow_{N\to +\infty} 0$
	\end{itemize}
\end{proposition}

\begin{theorem}[de \textsc{Féjer} - \textnormal{[EA] 190}]
	\begin{itemize}
		\item $\forall f\in C^0_{2\pi}$, $\forall N\in \IN^*$, $\|\sigma_N(f)\|_{\infty}\leq \|f\|_{\infty}$ et $\|\sigma_N(f) - f\|_{\infty} \longrightarrow_{N\to +\infty} 0$
		\item $\forall p \geq 1$, $\forall f\in L^0_{2\pi}$, $\forall N\in \IN^*$, $\|\sigma_N(f)\|_{p}\leq \|f\|_{p}$ et $\|\sigma_N(f) - f\|_{p} \longrightarrow_{N\to +\infty} 0$
	\end{itemize}	
\end{theorem}

\begin{corollary}[\textnormal{[EA] 193}]
	$\left(e_n\right)_{n\in\IZ}$ est une base hilbertienne de $L^2_{2\pi}$. En particulier, $\forall f\in L^2_{2\pi}$, 
	\begin{itemize}
		\item $\|S_N(f)-f\|_2 \longrightarrow_{N\to +\infty} 0$
		\item $\|f\|^2_2 = \sum_{n=-\infty}^{+\infty} \vert c_n(f) \vert^2$. Plus précisément, $f\mapsto \left(c_n(f)\right)_{n\in\IZ}$ est une isométrie linéaire de $L^2_{2\pi}$ dans $\ell^2(\IZ)$.
	\end{itemize}
\end{corollary}

\begin{application}
	$\sum_{n=1}^{+\infty} \frac{1}{n^2} = \frac{\pi^2}{6}$ et $\sum_{n=1}^{+\infty} \frac{1}{n^4} = \frac{\pi^4}{90}$.
\end{application}

\subsection*{B. Cas des variables aléatoires}

\textcolor{paragraphtext}{Soient $(\Omega, \A, \IP)$ un espace probabilisé, $X$ et $Y$ dans $L^2(\Omega, \A, \IP)$ à valeurs réelles, et $\B\subseteq \A$ une sous-tribu.}

\begin{proposition}
	$(X,Y)\mapsto \IE[XY]$ est le produit scalaire usuel sur $L^2(\Omega, \A,\IP)$, qui en fait donc un espace de Hilbert.
\end{proposition}

\begin{remark}
	$\Cov\,\colon (X,Y)\mapsto \IE\left[(X-\IE[X])(Y-\IE[Y])\right] = \IE[XY] - \IE[X]\IE[Y]$ est un semi-produit scalaire (\emph{i.e.} un produit scalaire ne vérifiant pas $\ps{x}{x} = 0 \implies x = 0$) sur $L^2(\Omega,\A,\IP)$.
	Sa semi-norme associée est $X \mapsto \sigma_X = \sqrt{\IV[X]}$. On dispose de l'inégalité de \textsc{Cauchy-Schwarz} : $\vert\Cov(X,Y)\vert \leq \sigma_X\sigma_Y$.
\end{remark}

\begin{remark}
	On dit que $X$ et $Y$ sont \emph{non corrélées} si $\Cov(X,Y) = 0$, \emph{i.e.} si $X$ et $Y$ sont orthogonales pour $\Cov$. Si $X$ et $Y$ sont indépendantes, alors elles sont non corrélées, mais la réciproque est fausse en général (elle est cependant vraie si $X$ et $Y$ sont des vecteurs gaussiens).
\end{remark}

\begin{definition}[\textnormal{[CR] 77}]
	L'\emph{espérance conditionnelle de $X$ sachant $\B$} est le projeté de $X$ sur $L^2(\B)$.
	On la note $\IE[X\mid \B]$, et elle est caractérisée par $\forall z\in L^2(\B)$, $\IE[XZ] = \IE\left[\IE[X\mid \B]Z\right]$.
\end{definition}

\begin{remark}
	Si on note $\ps{X}{Y}=\IE[XY]$, $F = L^2(\B)$ et $\IE[X\mid \B]=P_F(X)$, cette caractérisation dit que $P_F(X)$ est l'unique vecteur de $F$ tel que $\forall z\in F,\, \ps{X}{Z} = \ps{P_F(X)}{Z}$, \emph{i.e.} $\forall z\in F,\, \ps{X-P_F(X)}{Z}=0$ \emph{i.e.} $X -P_F(X)\in F^{\perp}$ : on retombe sur nos pattes !
\end{remark}

\subsection*{C. Opérateurs de \textsc{Hilbert-Schmidt}}

\textcolor{paragraphtext}{Soit $(\Omega, \A,\mu)$ un espace mesuré tel que $H := L^2(\Omega, \A, \mu)$ est séparable. Soit $T\in \mathcal{L}(H)$.}

\begin{definition}[\textnormal{[LM] 114-122}]
	On dit que $T$ est un \emph{opérateur de \textsc{Hilbert-Schmidt}} s'il existe une base hilbertienne $\left(e_n\right)_{n\in\IN}$ de $H$ telle que $\sum_{n=0}^{+\infty} \|Te_n\|^2 < +\infty$.
	On note $\mathcal{HS}(H)$ l'ensemble des opérateurs de \textsc{Hilbert-Schmidt} de $H$.
\end{definition}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}
	\label{213dev21}
	$T \in\mathcal{HS}(H) \iff T^*\in \mathcal{HS}(H)$, et la valeur de $\sum_{n=0}^{+\infty} \|Te_n\|^2$ (finie ou non) ne dépend pas du choix de $\left(e_n\right)_{n\in\IN}$. On la note $\|T\|_2$.
\end{theorem}

\begin{proposition}
	\label{213dev22}
	$\mathcal{HS}(H)$ est un espace de Hilbert pour le produit scalaire défini par :
	\begin{align*}
		\forall (S,T)\in \mathcal{HS}(H)^2,\, \ps{S}{T}_2 := \sum_{n=0}^{+\infty} \ps{Se_n}{T_en}
	\end{align*}
\end{proposition}

\begin{lemma}
	\label{213dev23}
	L'ensemble des opérateurs de rang fini est dense dans $\mathcal{HS}(H)$.
\end{lemma}

\begin{theorem}
	\label{213dev24}
	$T\in\mathcal{HS}(H)\iff \exists K\in L^2(\Omega\times\Omega, \mu\otimes\mu)\,\colon T=T_K$, 
	où $T_K\,\colon f\in H \mapsto \int_{\Omega} K(x,\cdot)f(x)d\mu(x)$.
\end{theorem}
\end{tcolorbox}

\section*{Développements}
\begin{itemize}
	\item Développement 1 : Théorème \ref{213dev1a} et Théorème \ref{213dev1b}
	\item Développement 2 : Tout de \ref{213dev21} à \ref{213dev24}
\end{itemize}

\section*{Références}
\begin{itemize}
	\item[HL] \emph{Éléments d'analyse fonctionnelle}, Francis Hirsch, Giles Lacombe
	\item[G] \emph{Les maths en tête - Analyse}, Xavier Gourdon, 3e édition 
	\item[EA] \emph{Analyse de Fourier dans les espaces fonctionnels}, Mohamed El Amrani
	\item[LM] \emph{Analyse fonctionnelle}, Gilles Lacombes, Pascal Massat
	\item[B] \emph{Algèbre et géométrie: CAPES et Agrégation}, Pierre Burg
	% \item[BP] \emph{Théorie de l'intégration}, Marc Briane, Filles Pagès, 7e édition
	\item[CR] \emph{Probabilités et statistiques pour l'épreuvre de modélisation à l'agrégation de mathématiques}, Chabanol, Ruch
\end{itemize}
\begin{figure}[!htb]
	\centering
	\includegraphics[trim={0 0 0 0},clip,width=1\linewidth]{img/213.pdf}
	\caption{s}
\end{figure}

\chapter*{214 : Théorème d’inversion locale, théorème des fonctions implicites. Illustrations en analyse et en géométrie.}
\textcolor{paragraphtext}{IMPASSE}


\chapter*{215 : Applications différentiables définies sur un ouvert de $\IR^n$. Exemples et applications.}
\setcounter{definition}{0}

\textcolor{paragraphtext}{Dans cette leçon, $U\subseteq \IR$ ($n\geq 1$) est ouvert, $f\,\colon U\to \IR^p$ ($p\geq 1$), et $a\in U$.
On note $\ps{\cdot}{\cdot}$ le produit scalaire sur $\IR^n$, $\|\cdot\|$ sur norme sur $\IR^n$, $\B=(e_1,\dots,e_n)$ une base de $\IR^n$, $\B'=(\varepsilon_1,\dots,\varepsilon_p)$ une base de $\IR^p$.
On décompose $f$ dans $\B'\,\colon \forall x\in U,\,f(x) = \sum_{k=1}^{p} f_k(x)\varepsilon_k$.}

\section*{I. Définitions et premières propriétés}
\subsection*{A. Différentielle et dérivée directionnelle}

\begin{definition}[\textnormal{[G] 323}]
	On dit que $f$ est \emph{différentiable en $a$} s'il existe $u_a\in\mathcal{L}(\IR^n,\IR^p)$ telle que $\frac{\|f(a+h)-f(a)-u_a(h)\|}{\|h\|}\longrightarrow_{h\to 0}0$.
	Dans ce cas, $u_a$ est unique : on l'appelle \emph{différentielle de $f$ en $a$}, et on la note $df(a)$.
	Si $f$ est différentiable en tout point de $U$, alors on dit que $f$ est \emph{différentiable sur $U$}, et on sidpose de $df\,\colon U\to \mathcal{L}(\IR^n,\IR^p)$, $a\mapsto df(a)$.
\end{definition}

\begin{example}[\textnormal{[G] 323}]
	Si $f\,\colon \IR\to\IR^p$, alors $f$ est différentiable en $a$ si, et seulement si, $f$ est dérivable en $a$.
	Le cas échéant, $df(a)\,\colon h\mapsto h\cdot f'(a)$.
\end{example}

\begin{definition}[\textnormal{[G] 324}]
	On dit que $f$ admet une \emph{dérivée directionnelle suivant $h\in\IR^n$} si $D_hf(a) := \lim_{t\to D} \frac{f(a+th) - f(a)}{t}$ existe.
\end{definition}

\begin{proposition}[\textnormal{[G] 324}]
	Si $f$ est différentiable en $a$, alors $f$ admet une dérivée directionnelle en $a$ suivant tout vecteur. Plus précisément, $\forall h\in \IR^n$, $D_hf(a)=df(a)(h)$.
\end{proposition}

\begin{proposition}[\textnormal{[G] 324}]
	Si $f$ est différentiable en $a$, alors $f$ est continue en $a$.
\end{proposition}

\begin{theorem}[inégalité des accroissements finies - \textnormal{[G] 327}]
	Soit $(a,b)\in U^2$ tel que $[a,b]\subseteq U$. Si $f$ est continue sur $[a,b]$ et différentiable sur $]a,b[$, alors :
	$$\|f(a)-f(b)\|\leq \sup_{x\in ]a,b[} \vertiii{df(c)\cdot \|b-a\|}$$
\end{theorem}

\begin{example}
	$f\,\colon (x,y)\mapsto x^2 + y^2$ est en tout point différentiable, et $\forall \underline{a}\in\IR^2,\, df(\underline{a}) = 2\ps{a}{\cdot}$.
\end{example}

\subsection*{B. Opérations sur les applications différentiables, exemples}

\begin{proposition}
	Si $B\,\colon \IR^n\times\IR^m\to\IR^p$ est bilinéaire, alors elle est différentiable en tout point, et $\forall(a,b)\in\IR^n\times\IR^m$, $\forall (h,k)\in\IR^n\times\IR^m$, $dB(a,b)(h,k) = B(h,b) + B(a,k)$.
\end{proposition}

\begin{example}
	$\varphi\,\colon (x,y)\in \IR^2 \mapsto xy$ est bilinéaire, et $d\varphi(a,b)(h,k) = hb+ak$.
\end{example}

\begin{example}
	Soit $A\in\M_n(\IR)$. L'application $u\,\colon (x,y)\in\IR^n\times\IR^n\mapsto \ps{Ax}{y}$ est bilinéaire, et $\forall(a,b)\in\IR^n\times\IR^n,\, \forall (h,k)\in\IR^n\times\IR^n,\, du(a,b)(h,k) = \ps{Ah}{b} + \ps{Aa}{k}$.
\end{example}

\begin{proposition}
	Si $f$ et $g\,\colon U\to \IR^p$ sont différentiables en $a$, alors pour tout $(\alpha, \beta)\in\IR^2$, $\alpha f + \beta g$ est différentiable en $a$, et $d(\alpha f + \beta g)(a) = \alpha df(a) + \beta dg(a)$.
\end{proposition}

\begin{proposition}[\textnormal{[G] 324}]
	Soient $V\subseteq f(U)$ ouvert et $g\,\colon V\to \IR^d$. Si $f$ est différentiable en $a$ et $g$ en $f(a)$, alors $g\circ g$ est différentiable en $a$, et $d(g\circ f)(a) = df(f(a))\circ dg(a)$.
\end{proposition}

\begin{example}
	Si $f,g\,\colon \IR^n\to \IR$ sont différentiables en $a$, alors $fg$ est différentiable en $a$, et $d(fg)(a). d(\varphi\circ (f,g))(a) = f\cdot dg(a) + g\cdot df(a)$ ($\varphi$ est donnée en exemple 9).
\end{example}

\subsection*{C. Dérivées partielles d'ordre $1$, classe $C^1$}

\begin{definition}[\textnormal{[G] 325}]
	On dit que $f$ admet en $a$ une \emph{$j$-ième dérivée partielle dans $\B$} si $f$ admet une dérivée suivant $e_j$, que l'on note plutôt $\frac{\partial f}{\partial e_j}(a)$ ou $\partial_jf(a)$.
\end{definition}

\begin{remark}[\textnormal{[G] 325}]
	Si $f$ est différentiable en $a$, alors $f$ admet des dérivées partielles, mais la réciproque est fausse : considérer $f\,\colon (x,y)\in \IR^2\setminus \left\{(0,0)\right\}\mapsto \frac{xy}{x^2+y^2}$, $(0,0)\mapsto 0$.
\end{remark}

\begin{notation*}
	Lorsque $x = \sum_{k=1}^{n}x_ke_k$, on note $\frac{\partial f}{\partial x_j}(x) = \frac{\partial f}{\partial e_j}(x)$, qui se calcule en considérant les $x_i$, $i\neq j$ comme constants, et en dérivant la fonction de $x_j$.
\end{notation*}

\begin{definition}[\textnormal{[G] 327}]
	Si $f$ admet en $a$ des dérivées partielles suivant chaque $e_j$, alors on définit la \emph{(matrice) jacobienne de $f$ en $a$} : 
	\begin{align*}
		\Jac_a(f) = \left(\partial_jf_i(a)\right)_{\substack{1\leq i\leq p \\ 1\leq j, n}}
	\end{align*}

	Pour tout $h\in \IR^n$, $df(a)(h)=\Jac_a(f)\cdot\left(e_i^*(h)\right)_{1\leq i\leq n}$.
\end{definition}

\begin{proposition}[règle de la chaîne - \textnormal{[G] 327}]
	Sous les hypothèses de la propositoin 12, $\Jac_a(g\circ f) = \Jac_{f(a)}(g)\Jac_a(f)$, \emph{i.e.} $\frac{\partial (g\circ f)_i}{\partial e_j}(a) = \sum_{k=1}^{n}\frac{\partial g_i}{\partial \varepsilon_j}(f(a))\times\frac{\partial f_k}{\partial e_j}(a)$.
\end{proposition}

\begin{definition}[\textnormal{[G] 323}]
	On dit que $f$ est \emph{de classe $C^1$ sur $U$} si $f$ est différentiable sur $U$ et si $df$ est continue sur $U$.
\end{definition}

\begin{proposition}[\textnormal{[G] e325}]
	Les dérivées partielles (d'ordre $1$) dans $\B$ existent et sont continues sur $U$ si, et seulement si, $f$ est de classe $C^1$ sur $U$.
\end{proposition}

\section*{II. Ordre supérieur - Étude locale}
\subsection*{A. Différentielle et dérivée partielles d'ordre supérieur}

\begin{definition}[\textnormal{[Rv] 283}]
	On dit que $f$ est \emph{deux fois différentiable en $a$} si $f$ est différentiable sur $U$ et si $df$ est différentiable en $a$.
	On note alors $d^2f(a) := d(df)(a)$. On dit que $f$ est \emph{$k$ fois différentiable en $a$} si $f$ est $k-1$ fois différentiable sur $U$ et si $d^{k-1}f$ est différentiable en $a$.
\end{definition}

\begin{remark}[\textnormal{[Rv] 294}]
	Si $f$ est deux fois différentiable sur $U$, alors on dispose de $d^2f\,\colon U\to \mathcal{L}(\IR^n, \mathcal{L}(\IR^n,\IR^p))\cong \mathcal{L}_2(\IR^n\times\IR^n,\IR^p),\, a\mapsto d^2f(a)$.
	Ainsi, $d^2f(a)$ s'identifie à une forme bilinéaire sur $\IR^n$.
\end{remark}

\begin{definition}[\textnormal{[Rv] 294}]
	Sous réserve d'existence, on appelle \emph{dérivées partielles d'ordre $2$ de $f$ dans $\B$ en $a$} les vecteurs
	$$\frac{\partial^2f}{\partial e_i \partial e_j}(a) := \frac{\partial}{\partial e_i}\left[\frac{\partial f}{\partial e_j}\right](a)$$
	On appelle \emph{dérivées partielles d'ordre $k$ de $f$ dans $\B$ en $a$} les vecteurs $\frac{\partial^2f}{\partial e_{i_1}\dots\partial e_{i_k}}(a) := \frac{\partial}{\partial e_{i_1}}\left[\frac{\partial f}{\partial e_{i_2}\dots\partial e_{i_k}}\right](a)$ ($1\leq k\leq n,\, 1\leq i_1,\dots, i_k\leq n$).
\end{definition}

\begin{remark}[\textnormal{[Rv] 296}]
	En général, $\frac{\partial^2 f}{\partial e_i\partial e_j}(a)\neq \frac{\partial^2 f}{\partial e_j\partial e_i}(a)$ : considérer la fonction de Remarque $15$.
\end{remark}

\begin{proposition}
	Proposition 19 reste vraie en remplaçant $1$ par $k$, pour tout $k\geq 1$.
\end{proposition}

\begin{theorem}[de \textsc{Schwarz} - \textnormal{[Rv] 294}]
	Si $f$ est deux fois différentiable en $a$, alors :
	\begin{align*}
		\forall (i,j)\in\llbracket 1,n\rrbracket^2,\,  \frac{\partial^2 f}{\partial e_i\partial e_j}(a) = \frac{\partial^2 f}{\partial e_j\partial e_i}(a)
	\end{align*}
\end{theorem}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[Différentielle de l'exponentielle matricielle]
	\label{215dev1}
\end{theorem}
\end{tcolorbox}

\subsection*{B. Étude locale}
\begin{theorem}[d'inversion locale - \textnormal{[G] 341}]
	Si $f\in C^1(U,\IR^n)$ et si $df(a)$ est inversible, alors il existe un voisinage $V\subseteq U$ de $a$ tel que $f$ induit une bijection de $V$ dans $f(V)$ de réciproque $C^1$.
\end{theorem}

\begin{example}[\textnormal{[Rv] 208}]
	Définition locale d'un logarithme matriciel.
\end{example}

\begin{theorem}[des fonctions implicites - \textnormal{[Rv] 344}]
	Soient $\Omega\subseteq \IR^n\times\IR^m$ un ouvert, $(a,b)\in \Omega$ et $f\in C^1(\Omega,\IR^p)$.
	Si $f(a,b)=0$ et si $f(a,\cdot)$ est différentiable en $b$, de différentielle inversible, alors il existe des voisinages $U$ de $a$ et $V$ de $b$ tels que $U\times V \subseteq \Omega$,
	et une unique application $\varphi\in C^1(U,V)$ telle que : $\left\{(x,y)\in U\times V\mid f(x,y)=0\right\} = \left( (x,\varphi(x)) \mid x\in U\right)$.
\end{theorem}

\begin{example}[\textnormal{[Rv] 348}]
	Détermination des équations d'était d'un système thermodynamique qui satisfait la loi des gaz parfaits : $f(P,V,T) = PV - nRT = 0$.
\end{example}

\begin{theorem}[formule de \textsc{Taylor} - \textnormal{[Rv] 296}]
	Si $f$ est $k$ fois différentiable en $a$, alors $\forall h\in U$, 
	\begin{align*}
		f(a+h) &= \sum_{j=0}^{k}\frac{1}{j!}d^jf(a)(h)\dots (h)\quad \text{[$(h)$ appliqué $j$ fois]} \\
		&= \sum_{j=0}^{k}\left(\sum_{i=1}^{n} h_i\frac{\partial}{\partial e_i}\right)^k[f](a) + o(\|h\|^k)
	\end{align*}
\end{theorem}

\begin{theorem}[formule de \textsc{Taylor} avec reste intégral - \textnormal{[Rv] 298}]
	Si $f\in C^{k+1}(U,\IR^n)$, alors pour tout $h\in\IR^n$ tel que $[a,a+h]\subseteq U$,
	\begin{align*}
		f(a+h) &= \sum_{j=0}^{k}\frac{1}{j!}d^jf(a)(h)\dots(h) + \int_{0}^{1}\frac{(1-t)^k}{k!}d^{k+1}f(a+th)(h)\dots(h)dt
	\end{align*} 
	NB : sous la somme, il y $j$ fois $(h)$, tandis que sous l'intégral il y a $k+1$ fois $(h)$.
\end{theorem}

\section*{III. Cas des fonctions à valeurs dans $\IR$}
\textcolor{paragraphtext}{Dans ce paragraphe, on suppose que $f\,\colon U\subseteq \IR^n\to \IR$ est différentiable en $a$.}

\subsection*{A. Gradient, hessienne}

\begin{definition}[\textnormal{[G] 324}]
	On appelle \emph{gradient de $f$ en $a$} l'unique vecteur $\nabla f(a)\in\IR^n$ tel que $df(a) = \ps{\cdot}{\nabla f(a)}$.
\end{definition}

\begin{proposition}[\textnormal{[Rv] 325}]
	$df(a) = \sum_{k=1}^{n}\frac{\partial f}{\partial e_k}(a)e_k^*$ et si $\B$ est orthonormale, $\nabla f(a) = \sum_{k=1}^{n} \frac{\partial f}{\partial e_k}(a)e_k$.
\end{proposition}

\textcolor{paragraphtext}{À partir de maintenant, sauf mention contraire, $f\in C^2(U,\IR)$.}

\begin{definition}[\textnormal{[Rv] 294}]
	On appelle \emph{(matrice) hessienne de $f$ en $a$} la matrice
	\begin{align*}
		\Hess_a(f) = \left(\frac{\partial^2 f}{\partial e_i\partial e_j}(a)\right)_{1\leq i,j\leq n}
	\end{align*}
\end{definition}

\begin{remark}
	D'après le théorème de \textsc{Schwarz}, $\Hess_a(f)$ est symétrique. C'est la matrice de la forme bilinéaire $d^2f(a)$ dans $\B$. Pour tout $(h,k)\in\IR^n\times\IR^n$, $d^2f(a)(h)(k) = {}^t\left(e_i^*(h)\right)_{1\leq i\leq n}\cdot \Hess_a(f)\cdot \left(e_i^*(k)\right)_{1\leq i\leq n}$.
\end{remark}

\begin{example}
	Expression du laplacien en coordonées polaires $[\varphi\,\colon (r,\theta)\mapsto (r\cos(\theta), r\sin(\theta))]$ :
	\begin{align*}
		\Delta f = \frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2} = \frac{\partial^2(f\circ \varphi)}{\partial r^2} + \frac{1}{r}\frac{\partial(f\circ\varphi)}{\partial r} + \frac{1}{r^2}\frac{\partial^2(f\circ \varphi)}{\partial \theta^2}
	\end{align*}
\end{example}

\subsection*{B. Optimisation}
\begin{definition}[\textnormal{[G] 336}]
	On dit que $a$ est un \emph{point critique} si $df(a) = 0_{\mathcal{L}(\IR^n,\IR)}$.
\end{definition}

\begin{theorem}[FIGURE - \textnormal{[G] 335-336}]
	\begin{itemize}
		\item Si $f$ admet un maximum (resp. un minimum) local en $a$, alors $a$ est un point critique, et $\Hess_a(f)$ est négative (resp. positive).
		\item La réciproque est vraie si on suppose en plus $\Hess_a(f)$ définie.
		\item Si $a$ est un point critique et si $\Hess_a(f)$ admet deux valeurs propres de signes strictement opposés, alors $a$ est un \emph{point-selle}.
	\end{itemize}
\end{theorem}

\begin{example}
	Si $f\,\colon \IR \to \IR$, alors on retrouve un résultat bien connu :
	\begin{itemize}
		\item Si $f'(a) = 0$ et $f''(a) > 0$ (resp. $f''(a)< 0$), alors $f$ admet un minimum (resp. un maximum) local en $a$.
		\item Si $f'(a) = f''(a)$ et $f'''(a) \neq 0$, alors $a$ est un point d'inflexion.
	\end{itemize}
\end{example}

\begin{example}[\textnormal{[BMP] 24-32}]
	Soient $A\in \mathcal{S}_n^{++}(\IR)$ et $b\in\IR^n$. La solution de $Ax= b$ est le minimum global de $J\cdot x \mapsto \frac{1}{2}\ps{Ax}{x} = \ps{b}{x}$.
\end{example}

\begin{theorem}[des extrema liés - \textnormal{[Rv] 372}]
	Soit $(f, g_1,\dots, g_r)\in C^1(U, \IR)^{r+1}$, posons $\Gamma = \left\{x\in U \mid g_1(x)=\cdots=g_r(x)=0\right\}$.
	Si $f_{\mid \Gamma}$ admet un extremum local en $a\in \Gamma$, et si $(dg_1(a),\dots,dg_r(a))$ est libre, alors il existe des réels $\lambda_1,\dots,\lambda_r$, appelés \emph{multiplicateurs de \textsc{Lagrange}}, tels que :
	$$df(a) = \sum_{k=1}^{r} \lambda_kdg_k(a)$$
\end{theorem}


\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{application*}[\textnormal{[Rv] 413}]
	\label{215dev2}
	Existence d'une trajectoire fermée à 3 rebonds sur un billard elliptique.
\end{application*}
\end{tcolorbox}

\begin{remark}
	Ce théorème permet de ramener la recherche d'un extremum local en dimension $n$ sous $r$ contraintes à la résolution du système carré $n+r$ :
	$$\{ \forall i\in\llbracket 1,n\rrbracket,\, \frac{\partial f}{\partial e_i}(a) = \sum_{k=1}^{r}\lambda_k\frac{\partial g_k}{\partial e_i}(a)\quad g_1(a) = \cdots = g_r(a) = 0$$
\end{remark}

\begin{proposition}[\textnormal{[Rv] 127}]
	Supposons $U$ convexe. 
	\begin{itemize}
		\item Si $f$ est différentiable sur $U$, alors $f$ est convexe si, et seulement si : $$\forall(x,y)\in U^2,\, f(y)-f(x)\geq df(x)(y-x)$$
		\item Si $f$ est deux fois différentiable sur $U$, alors $f$ est convexe si, et seulement si, pour tout $a\in U$, $\Hess_a(f)$ est (symétrique) positive.
	\end{itemize}
\end{proposition}

\begin{proposition}[\textnormal{[Rv] 381}]
	Si $U$ est convexe, si $f$ est convexe, et si $a$ est un point critique, alors $f$ admet en $a$ un minimum global sur $U$.
\end{proposition}

\section*{IV. Cas des fonctions du plan : holomorphie}
\textcolor{paragraphtext}{On suppose que $f\,\colon \IR^2\to \IR^2$. On note $u$ et $v$ les applications coordonées de $f$ dans la base canonique : $f=(u,v)$. Soit $z_0\in\IR^2$.}

\begin{definition}[\textnormal{[T] e59}]
	On dit que $f$ est \emph{holomorphe en $z_0$} si $f$ est différentiable en $z_0$ et vérifie la condition de \textsc{Cauchy-Riemann} :
	\begin{align*}
		\frac{\partial u}{\partial x}(z_0) = \frac{\partial v}{\partial y}(z_0)\quad\text{et}\quad \frac{\partial u}{\partial y}(z_0) = -\frac{\partial v}{\partial x}(z_0)
	\end{align*}

	Le cas échéant, on pose $f'(z_0) := \frac{\partial f}{\partial x}(z_0) = \left(\frac{\partial u}{\partial x}(z_0), \frac{\partial v}{\partial x}(z_0)\right)$.
\end{definition}

\begin{proposition}[\textnormal{[T] e60-61}]
	Si $f$ est différentiable en $z_0$, alors $\forall h=(h_x,h_y)\in\IR^2$, $df(z_0)(h) = \ps{\partial_z f(z_0)}{h} + \ps{\partial_{\overline{z}} f(z_0)}{\overline{h}}$
	où $\overline{h} = (h_x, -h_y)$, $\partial_z f(z_0) = \frac{1}{2}\left(\frac{\partial f}{\partial x}(z_0), -\frac{\partial f}{\partial y}(z_0)\right)$ et $\partial_{\overline{z}} f(z_0) = \frac{1}{2}\left(\frac{\partial f}{\partial x}(z_0), \frac{\partial f}{\partial y}(z_0)\right)$.
\end{proposition}

\begin{proposition}[\textnormal{[T] e61}]
	$f$ est holomorphe en $z_0$ si, et seulement si, $f$ est différentiable en $z_0$ et $\partial_{\overline{z}}f(z_0) = 0$. Le cas échéant, $f'(z_0) = \partial_z f(z_0)$.
\end{proposition}

\begin{definition}[\textnormal{[T] e69}]
	Soit $\gamma = (\gamma_x, \gamma_y)\,\colon [a,b]\to \IR^2$ un arc paramétré de classe $C^1$.
	On définit l'\emph{intégrale de $f$ le long de $\gamma$} comme :
	\begin{align*}
		\int_{\gamma} f(z)dz = \int_{a}^{b} (f\circ \gamma)(t)\times \gamma'(t)dt
	\end{align*}
\end{definition}

\begin{theorem}[formule de \textsc{Cauchy} - \textnormal{[T] e77}]
	Soient $U\subseteq \IR^2$ ouvert, $a\in \IR^2$ et $R> 0$ tels que $\overline{\B}(a,r)\subseteq U$. Supposons $f$ holomorphe sur $U$. Alors,
	\begin{align*}
		f(a) = \frac{1}{2\pi}\int_{\gamma} \frac{f(z)}{z-a}dz
	\end{align*}
	pù $\gamma\,\colon [0,2\pi]\to \IR^2$, $t\mapsto a+R(\cos(t), \sin(t))$.
\end{theorem}

\begin{theorem}[\textnormal{[T] 78}]
	Si $f$ est holomorphe en $z_0$, alors $f$ est infiniment différentiable en $z_0$.
\end{theorem}

\section*{Développements}
\begin{itemize}
	\item Développement 1 : Théorème \ref{215dev1}
	\item Développement 2 : Application \ref{215dev2}
\end{itemize}

\section*{Références}
\begin{itemize}
	\item[G] \emph{Les maths en tête - Analyse}, Xavier Gourdon, 3e édition 
	\item[Rv] \emph{Petit guide du calcul différentiel}, François Rouvière, 4e édition
	\item[BMP] \emph{Objectif Agrégation}, Vincent Beck, Jérôme Malick, Gabriel Peyré, 2e édition
	\item[T] \emph{Analyse complexe pour la licence 3}, Patrice Tauvel, 2e édition
\end{itemize}

\begin{figure}[!htb]
	\centering
	\includegraphics[trim={0 0 0 0},clip,width=1\linewidth]{img/215.pdf}
	\caption{s}
\end{figure}


\chapter*{219 : Extremums : existence, caractérisation, recherche. Exemples et applications.}
\setcounter{definition}{0}

\textcolor{paragraphtext}{Soient $(E,\|\cdot\|)$ un $\IR$-espace vectoriel normé, $U\subseteq E$ non vide et $f\,\colon U\to \IR$.}

\section*{I. Existence et unicité d'extrema}
\begin{definition}
	On dit que $f$ admet un \emph{maximum local} (resp. un \emph{minimum local}) en $a\in U$ s'il existe un voisinage $V$ de $a$ tel que $\forall x\in V\cap Y,\, f(x)\leq f(a)$ (resp. $f(x) \geq f(a)$).

	Si cette inégalité est vraie pour tout $x\in U$, alors $f(a)$ est un \emph{maximum global} (resp. un \emph{minimum global}) de $f$.
\end{definition}

\begin{remark}
	Un extremum global est local, mais la réciproque est fausse ! Considérer $x\mapsto (x-2)x(x+2)$ sur $\IR$.
\end{remark}

\subsection*{A. Optimisation des fonctions continues sur un compact}
\begin{theorem}[des bornes atteintes - \textnormal{[G] 31}]
	Si $U$ est compact, alors $f$ est bornée et atteint ses bornes.
\end{theorem}

\begin{remark}
	\begin{itemize}
		\item $\IR$ n'est pas compact, $\arctan$ est continue et bornée sur $\IR$ mais n'atteint pas ses bornes.
		\item $f\,\colon x\neq 0\mapsto 1/x$, $0\mapsto 0$ n'est pas continue sur le compact $[-1,1]$, et n'est pas bornée.
	\end{itemize}
\end{remark}

\begin{corollary}[\textnormal{[G] e33}]
	Si $U = E\cong \IR^n$, $f$ est continue sur $U$ et $\lim_{\|x\|\to +\infty} f(x) = +\infty$, alors $f$ admet et atteint un minimum global.
\end{corollary}

\begin{corollary}[\textnormal{[BMP] 30}]
	Soit $F\subseteq E$ fermé non vide. Pour tout $x\in E$, il existe $y\in F$ tel que
	\begin{align*}
		\|x-y\| = d(x,F) = \inf_{z\in F} \|x-z\|
	\end{align*}
\end{corollary}

\subsection*{B. Optimisation et convexité}
\textcolor{paragraphtext}{Supposons $U$ convexe, \emph{i.e.} $\forall(x,y)\in U^2,\,\forall \lambda\in[0,1],\, \lambda x + (1-\lambda)y \in U$.}

\begin{definition}[\textnormal{[BMP] 26}]
	On dit que $f$ est \emph{convexe} si :
	$$\forall (x,y)\in U^2,\,\forall \lambda\in [0,1],\, f(\lambda x + (1-y)y) \leq \lambda f(x) + (1-\lambda)f(y)$$
	On dit que $f$ est \emph{strictement convexe} si cette inégalité est stricte pour $x\neq y$ et $\lambda\notin \left\{0,1\right\}$.
\end{definition}

\begin{example}[\textnormal{[BMP] e32}]
	Soient $E = U = \IR^n$, $A\in\mathcal{S}_n(\IR)$ $f\,\colon x\mapsto \ps{Ax}{x}$.
	Alors $f$ est (strictement) convexe si, et seulement si, $A$ est (définie) positive.
\end{example}

\begin{proposition}[\textnormal{[BMP] 30}]
	Si $f$ est convexe et admet un minimum local, alors c'est un minimum global. Si $f$ est de plus strictement convexe, alors ce minimum est unique.
\end{proposition}

\textcolor{paragraphtext}{Soient $(H,\ps{\cdot}{\cdot})$ un espace de Hilbert, $C\subseteq H$ un convexe fermé non vide, et $F$ un sous-espace vectoriel fermé de $H$.}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{theorem}[de projection sur un convexe fermé - FIG. 1 - \textnormal{[HL] 91}]
	\label{219dev11}
	$\forall x\in H,\, \exists ! P_C(x)\in C\,\colon \|x-P_C(x)\| = d(x,C) =: \inf_{y\in C} \|x-y\|$.

	De plus, $P_C(x)$ est caractérisé par $\forall y\in C,\, \Re(\ps{x-P_C(x)}{x-y})\leq 0$.

	Dans le cas de $F$, le projeté $P_F(x)$ est caractérisé par $P_F(x)\in F$ et $x-P_F(x)\in F^{\perp}$.
\end{theorem}

\begin{theorem}[de \textsc{Riesz} - \textnormal{[HL] 96}]
	\label{219dev12}
	$J\,\colon H\to H'$, $y\mapsto\ps{\cdot}{y}$ est un isomorphisme d'espaces de Hilbert, \emph{i.e.} une isométrie linéaire surjective.
\end{theorem}
\end{tcolorbox}

\subsection*{C. Optimisation et holomorphie}
\textcolor{paragraphtext}{On prend $E =\IC$, $U$ ouvert connexe, et $f$ holomorphe sur $U$.}

\begin{theorem}[\textnormal{[BMP] 72}]
	$\forall a\in U$, $\forall r > 0$, 
	$$\B(a,r)\subseteq U \implies f(a) = \frac{1}{2\pi}\int_{0}^{2\pi} f(a + re^{i\theta})d\theta$$
\end{theorem}

\begin{theorem}[principe du maximum local - \textnormal{[BMP] 72}]
	Si $\vert f\vert$ admet un maximum local, alors $f$ est constant.
\end{theorem}

\begin{theorem}[principe du maximum global - \textnormal{[BMP] 72}]
	Supposons $U$ borné et $f$ continue sur $\overline{U}$. Alors $\sup_U \vert f\vert = \max_{\partial U} \vert f\vert$
	et si ce maximum est atteint en un point de $U$, alors $f$ est constante.
\end{theorem}

\begin{theorem}[de \textsc{Liouville}]
	Si $f$ est holomorphe sur $\IC$ et bornée, alors $f$ est constante.
\end{theorem}

\begin{theorem}[d'\textsc{Alembert-Gauss}]
	$\IC$ est algébriquement clos.
\end{theorem}

\section*{II. Optimisation des fonctions différentiables - caractérisation des extremums.}
\textcolor{paragraphtext}{Dans ce paragraphe, $E = \IR^n$ et $U$ est ouvert.}

\subsection*{A. Conditions de premier ordre}
\begin{definition}[\textnormal{[BMP] 16}]
	On dit que $a$ est un \emph{point critique} si $df(a) = 0_{\mathcal{L}(\IR^n, \IR)}$.
\end{definition}

\begin{theorem}[\textnormal{[BMP] 18}]
	Si $f$ admet un maximum (resp. un minimum) local en $a$, alors $a$ est un point critique, et $\Hess_a(f)$ est négative (resp. positive).
\end{theorem}

\begin{remark}
	$x\mapsto x^3$ admet un point critique qui n'est pas un extremum.
\end{remark}

\begin{theorem}[de \textsc{Rolle} - \textnormal{[R] 251}]
	Si $f$ est continue sur $[a,b]$, dérivable sur $]a,b[$, et si $f(a) = f(b)$, alors il existe $c\in ]a,b[$ tel que $f'(c) = 0$.
\end{theorem}

\begin{theorem}[des accroissements finis - \textnormal{[R] 258}]
	Si $f$ est continue sur $[a,b]$ et dérivable sur $]a,b[$, alors il existe $c\in ]a,b[$ tel que $f(b)-f(a) = f'(c)(b-a)$.
\end{theorem}

\begin{corollary}[\textnormal{[R] 205-238}]
	\begin{itemize}
		\item Si $f$ est dérivable sur un intervalle de dérivée positive, alors $f$ est croissante.
		\item Si $f$ est deux fois dérivable sur un intervalle de dérivée seconde positive, alors $f$ est convexe.
	\end{itemize}
\end{corollary}

\subsection*{B. Conditions de second ordre}
\begin{theorem}[FIGURE 2 - \textnormal{[BMP] e18}]
	\begin{itemize}
		\item Si $f$ admet un maximum (resp. un minimum) local en $a$, alors $a$ est un point critique, et $\Hess_a(f)$ est négative (resp. positive).
		\item La réciproque est vraie si on suppose en plus $\Hess_a(f)$ définie.
		\item Si $a$ est un point critique et si $\Hess_a(f)$ admet deux valeurs propres de signes strictement opposés, alors $a$ est un \emph{point-selle}.
	\end{itemize}
\end{theorem}

\begin{remark}[\textnormal{[Rv] 371}]
	$x\mapsto x^4$ admet un minimum global en $0$, mais sa hessienne (sa dérivée seconde) est nulle en $0$.
\end{remark}


\begin{example}[\textnormal{[BMP] 24-32}]
	Soient $A\in\mathcal{S}_n^{++}(\IR)$, $b\in\IR^n$ et $J\,\colon x\mapsto \frac{1}{2}\langle AX\mid X\rangle - \langle b\mid x\rangle$.
	Alors $\forall x\in \IR^n$, $\nabla J(x)=Ax-b$ et $\Hess_J(x) = A\in\mathcal{S}_n^{++}(\IR)$.
	En particulier, $J$ admet un unique minimum (global) qui est la solution de $Ax= b$.
\end{example}

\subsection*{C. Optimisation sous contrainte}


\begin{theorem}[des extrema liés - \textnormal{[Rv] 372}]
	Soient $U$ un ouvert de $\IR^n$ et $(f,g_1,\dots, g_R)\in C^1(U,\IR)^{r+1}$. 
	Posons $\Gamma = \bigcap_{i=1}^r g_i^{-1}(\left\{0\right\})$.
	Si $f_{\mid \Gamma}$ admet un extremum local en $a\in \Gamma$, et si $(dg_1(a),\dots, dg_r(a))$ est libre, alors il existe des réels (uniques) $\lambda_1,\dots, \lambda_n$ appelées \emph{multiplicateurs de \textsc{Lagrange}},
	tels que $df(a) = \lambda_1dg_1(a)+\cdots + \lambda_r dg_r(a)$.
\end{theorem}

 \begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{application}[\textnormal{[Rv] 413}]
	\label{219dev2}
	Sur un billard elliptique, il existe une trajectoir fermée à 3 rebonds.
\end{application}
\end{tcolorbox}

\begin{remark}
	Ce théorème permet de ramener la recherche d'un extremum local en dimension $n$ sous $r$ contraintes à la résolution du système carré $n+r$ :
	$$\{ \forall i\in\llbracket 1,n\rrbracket,\, \frac{\partial f}{\partial e_i}(a) = \sum_{k=1}^{r}\lambda_k\frac{\partial g_k}{\partial e_i}(a)\quad g_1(a) = \cdots = g_r(a) = 0$$
\end{remark}

\begin{example}[\textnormal{[Rv] 411, 412}]
Soient $a_1,\dots, a_n,a$ des réels deux à deux distincts, et posons $\Sigma = \left\{(p_1,\dots,p_n)\in \left(\IR^{+*}\right)^n \mid \sum_{k=1}^{n} p_k = 1\text{ et } \sum_{k=1}^{n}a_kp_k = a\right\}$ (qui est non vide).
La fonction :
\begin{align*}
	H\,\colon (p_1,\dots,p_n)\in\Sigma\mapsto -\sum_{k=1}^{n} p_k\ln(p_k)
\end{align*}
admet un unique maximum, en $\frac{1}{n}(1,\dots,1)$.
\end{example}

\section*{III. Optimisation numérique : algorithmes de recherche d'extrema}
\begin{theorem}[méthode de \textsc{Newton} - \textnormal{[R] 345-346}]
	Soient $a < b$ deux réels, $f\,\colon[a,b]\to \IR$ de classe $C^2$ telle que $f(a)< 0 f(b)$ et $f'>0$ sur $[a,b]$.
	soit $\left(x_n\right)_{n\in\IN}$ définie par :
	$$x_0\in [a,b]\quad\text{et}\quad \forall n\in\IN,\, x_{n+1} = x_n - f(x_n)/f'(x_n)$$
	\begin{enumerate}
		\item Pour $x_0$ assez proche de l'unique zéro $\alpha$ de $f$, $\left(x_n\right)_n$ converge vers $\alpha$ à vitesse quadratique.
		\item Si $f''>0$ sur $[a,b]$, alors la convergence (quadratique) de $\left(x_n\right)_n$ ne dépend pas du choix de $x_0$, et $$x_{n+1} - ÷alpha \sim \frac{1}{2}\frac{f''(\alpha)}{f'(\alpha)(x_n-\alpha)^2}$$
	\end{enumerate}
\end{theorem}

\begin{application}
	\begin{itemize}
		\item Recherche de points critiques
		\item Schéma d'\textsc{Euler} implicite
	\end{itemize}
\end{application}

\begin{theorem}[méthode du gradient - \textnormal{[BMP] 22-23}]
	Soit $a\in U$ où $f$ atteint un minimum local, soit $x_0\in U$ proche de $a$.
	La suite définie par $x_0 = x_0$ et $\forall n\in \IN$, $x_{n+1} = x_n - \nabla f(x_n)$ converge (sous certaines hypothèses) vers $a$.
\end{theorem}

\section*{Développements}
\begin{itemize}
	\item Développement 1 : Théorèmes \ref{219dev11} et \ref{219dev12}
	\item Développement 2 : Application \ref{219dev2}
\end{itemize}

\section*{Références}
\begin{itemize}
	\item[BMP] \emph{Objectif Agrégation}, Vincent Beck, Jérôme Malick, Gabriel Peyré, 2e édition
	\item[R] \emph{Éléments d'analyse réelle}, Rombaldi
	\item[Rv] \emph{Petit guide du calcul différentiel}, François Rouvière, 4e édition
	\item[G] \emph{Les maths en tête - Analyse}, Xavier Gourdon, 3e édition 
	\item[HL] \emph{Éléments d'analyse fonctionnelle}, Francis Hirsch, Giles Lacombe
\end{itemize}

\begin{figure}[!htb]
	\centering
	\includegraphics[trim={0 0 0 0},clip,width=1\linewidth]{img/219.pdf}
	\caption{s}
\end{figure}


\chapter*{220 : Illustrer par des exemples la théorie des équations différentielles ordinaires.}
\setcounter{definition}{0}

\section*{I. Solutions d'une EDO : existence, unicité, survie}
\subsection*{A. Définitions et cadre de la leçon}

\begin{definition}[\textnormal{[G] 373}]
	Une \emph{équation différentielle ordinaire} (EDO) est une équation d'inconnue une fonction $y$ liant celle-ci à ses dérivées, \emph{i.e.} de la forme $\forall t\in I,\, g(t,y(t),y'(t),\dots, y^{(n)}(t)) = 0$,
	où $I\subseteq \IR$ est un intervalle ouvert, $y\,\colon I\to\IR^d$ et $g\,\colon I\times\Omega\to\IR^d$.
	On dit que cette équation est \emph{réduite} si elle peut être écrite de manière équivalente sous la forme $y^{(n)}(t) = f(t,y(t),y'(t),\dots,y^{(n-1)}(t))$.
	L'entier $n$ est alors appelé \emph{ordre} de cette EDO.
\end{definition}

\begin{proposition}[\textnormal{[Be] 20}]
	Soit $(E)\,\colon y^{(n)}(t) = f(t,y(y),\dots,y^{(n-1)}(t))$ une EDI où $y \,\colon I\to \IR^d$.
	Posons $Y = {}^t(y, y', \cdots, y^{(n-1)})\,\colon I\to \left(\IR^d\right)^n$ 
	et $F\,\colon I\times \left(\IR^d\right)^n\to \left(\IR^d\right)^n$, 
	$(t,Y)\mapsto {}^t(y',\dots, y^{(n-1)},f(t,y,y',\dots,y^{(n-1)}))$.

	Alors $(E)\iff (E')\,\colon \forall t\in I,\, Y'(t) = F(t,Y)$.
\end{proposition}

\textcolor{paragraphtext}{Dans toute la suite, on considère un intervalle 
ouvert $I\subseteq \IR$, $f\,\colon I\times \Omega\to\IR^d$ avec $\Omega\subseteq \IR^d$ ouvert, et $(E)\,\colon y'(t) = f(t,y(t))$ que l'on notera abusivement $(E)\,\colon y'=f(t,y)$.}

\begin{definition}[\textnormal{[Be] 11}]
	Une \emph{solution de $(E)$} est la donnée d'un intervalle $J\subseteq I$ et d'une fonction $y\in C^1(J,\IR^d)$ satisfaisant $(E)$ pour tout $t\in J$.
\end{definition}

\begin{definition}[\textnormal{[Be] 14-16}]
	Soient $(J_1,y_1)$ et $(J_2,y_2)$ deux solutions de $(E)$.
	\begin{itemize}
		\item On dit que $(J_2,y_2)$ est un \emph{prolongement de $(J_1,y_1)$} si $J_1\subseteq J_2$ et si ${y_2}_{J_1} = y_1$.
		\item On dit que $(J_1, y_1)$ est \emph{maximale} si elle n'admet pas de prolongement (strict).
		\item On dit que $(J_1,y1)$ est \emph{globale} si $J_1 = I$ (en particulier elle est maximale).
	\end{itemize}
\end{definition}

\begin{remark}[\textnormal{[Be] 16}]
	Pour $(E) \,\colon y' = y^2$ sur $\IR$, $(\IR^{-*}, t\mapsto -\frac{1}{t})$ est maximale non globale.
\end{remark}

\begin{definition}[\textnormal{[Be] 12}]
	Soit $(t_0, y_0)\in I\times \Omega$. Un \emph{problème de \textsc{Cauchy}} est la recherche d'une solution satisfaisant une \emph{condition initiale}.
	On notera $(C)\,\colon \begin{cases}
		(E)\,\colon y'=f(t,y) \\
		y(t_0) = y_0
	\end{cases}$ un tel problème de \textsc{Cauchy}.
\end{definition}

\textcolor{paragraphtext}{Dans la suite, on fixe $(t_0,y_0)\in I\times \Omega$ et $(C)\,\colon \begin{cases}
	(E)\,\colon y' = f(t,y)\\ y(t_0)=y_0
\end{cases}$.}

\subsection*{B. Le théorème de \textsc{Cauchy-Lipschitz} et ses conséquences}
\begin{definition}[\textnormal{[Be] 84}]
	On dit que $f$ est \emph{localement lipschitzienne selon sa deuxième variable} si :
	$\forall(t_0,y_0)\in I\times \Omega,\, \forall v\in\mathcal{V}\left((t_0,y_0)\right),\, \exists \lambda > 0\,\colon \forall t\in I,\, \forall (y_1,y_2)\in\Omega^2,\, \left((t,y_1),(t,y_2)\right)\in\mathcal{V}^2\implies \|f(t,y_1) - f(t,y_2)\| \geq \lambda\|y_1-y_2\|$.
\end{definition}

\begin{theorem}[de \textsc{Cauchy-Lipschitz} - \textnormal{[Be] 85}]
	Si $f$ est continue sur $I\times \Omega$ et localement lipschitzienne selon sa deuxième variable, alors $(C)$ admet une unique solution maximale.

	Si $f$ est globalement lipschitzienne selon sa deuxième variable, alors cette solution est globale.
\end{theorem}

\begin{cexample}
	$f\,\colon (t,y)\mapsto 2\sqrt{\vert y\vert}$ n'est pas localement lipschitzienne, et $y'=2\sqrt{\vert y\vert}$ admet plusieurs solutions telles que $y(0)=0$ (ex : $0,\, t\mapsto t\cdot \vert t\vert$).
\end{cexample}

\begin{application}[schéma d'\textsc{Euler} explicite - \textnormal{[Be] 318-319}]
	Soit $\Delta t > 0$ petit. On pose $Y_0 = y(t_0)=y_0$ et pour $n\in\IN$, $Y_{n+1} = Y_n + \Delta t f(t_0 + n\Delta t, Y_n)$.
	La fonction affine par morceaux $Y$ telle que $\forall n\in \IN,\, Y(t_0 + n\Delta t) = Y_n$ approche la solution de $(C)$ lorsque $f$ est $C^1$ et globalement lipschitzienne selon $Y$.	
\end{application}

\subsection*{C. Durée de vie et explosion des solutions}

\begin{lemma}[de \textsc{Grönwall} différentiel - \textnormal{[Be] 18}]
	Soient $w\in C^1(I,\IR)$ et $v\in C^0(I,\IR)$ telles que $w' \leq w\cdot v$ sur $I$. Alors :
	$$\forall t\in I,\quad t\geq t_0\implies w(t)\leq w(t_0)\exp\left(\int_{t_0}^{t} v\right)$$
\end{lemma}

\begin{lemma}[de \textsc{Grönwall} intégral - \textnormal{[Be] 18}]
	Soient $u\in C^0(I,\IR)$, $v\in C^0(I,\IR^+)$ et $a\in \IR$ telles que $\forall t\in I$, $t\geq t_0\implies u(t)\leq a + \int_{t_0}^{t} uv$. Alors :
	$$\forall t\in I,\quad t\geq t_0\implies u(t)\leq a\exp\left(\int_{t_0}^{t}v\right)$$
\end{lemma}

\begin{theorem}[des bouts - \textnormal{[Be] 110}]
	Sous les hypothèses de Théorème 8 : une solution de $(E)$ est maximale si, et seulement si, aux voisinage des bords de $I$, son graphe n'est contenu dans aucun compact.
\end{theorem}

\begin{cexample}[FIG. 1]
	Une solution bornée (dans l'espace) est globale.
\end{cexample}

\begin{cexample}
	Si $f$ est lipschitzienne, alors $(E)$ admet une unique solution globale.
\end{cexample}

\begin{example}
	C'est le cas pour une équation linéaire (\emph{c.f.} II. A.)
\end{example}

\section*{II. Méthodes et exemples de résolution}
\subsection*{A. Cas linéaire}

\textcolor{paragraphtext}{Soient $A\,\colon I\to \M_d(\IR)$ et $b\,\colon I\to \IR^d$ continues. Dans ce paragraphe, $(E)\,\colon y'(t) = f(t,y)=A(t)y(t)+b(t)$.}

\begin{proposition}[\textnormal{[Be] 34-35}]
	L'ensemble $S_I(E)$ des solutions de $(E)$ est un sous-espace affine de $C^1(I,\IR^d)$ de dimension $d$, de direction $S_I(H)$.
\end{proposition}

\begin{example}
	Pour $\omega > 0$, $S_{\IR}(y''+\omega y = \cos) = \frac{\cos}{1-\omega^2} + \IR\sin_{\omega} + \IR\cos_{\omega}$.
\end{example}

\textcolor{paragraphtext}{Soient $p\,\colon I\to \IR$ et $q\,\colon I\to \IR$ continues et $(E)\,\colon y''+py'+qy = 0$.}

\begin{methode}[\textnormal{[Be] 144, [G] 380}]
Si $y_0$ est une solution de $(E)$ qui ne s'annule pas sur $I$, alors
$$y\in S_I(E) \iff z' := \left(\frac{y}{y_0}\right)' \in S_I(x' = A\times \left(2 + \frac{y_0'}{y_0}\right)x)$$
\end{methode}


\begin{methode}[\textnormal{[Be] 149}]
	Si $p$ et $q$ sont développables en série entière, alors $(E)$ admet une solution développable en série entière.
\end{methode}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{example}[\textnormal{[Da] 538}]
	\label{220dev1}
	Pour $\omega > 0$, résolution de $ty''+2y'-\omega^2ty = 0$ sur $\IR$ et $\IR^{\pm*}$.
\end{example}
\end{tcolorbox}

\subsection*{B. Cas non linéaire}
\textcolor{paragraphtext}{Soient $a,b,\,\colon I\to \IR$ continues.}

\begin{proposition}[équations de \textsc{Bernoulli} - \textnormal{[G] 391, [Be] 138}]
	Soit $m\geq 2$. En faisant le changement de variable $z=y^{1-m}$, on ramène léquation $(E)\,\colon y'=ay + by^m$ à l'équation équivalente $(E')\,\colon z' = (1-m)a + (1-m)b$.
\end{proposition}

\begin{proposition}[équation de \textsc{Ricatti} - \textnormal{[G] 391, [Be] 139}]
	Si $y_0$ est une solution de $(E)\,\colon y'=ay^2 + by + c$, 
	alors on ramène $(E)$ à une équation de \textsc{Bernoulli} par le changement de variables $z=y-y_0$.
\end{proposition}

\begin{example}
	??
\end{example}

\subsection*{C. Équations à variables séparées}
[\textnormal{[Be] 130}]
\textcolor{paragraphtext}{Dans ce paragraphe, on considère un intervalle $J$, $h\in C^0(I, \IR)$, $g\in C^0(J,\IR)$, $(t_0, y_0)\in I\times J$, et $(C)\,\colon \begin{cases}
	(E)\,\colon y'=h(t)g(y) \\ y(t_0) = y_0
\end{cases}$. On dit que $(E)$ est à \emph{variables séparées}.}

\begin{theorem}
	Supposons que $g$ ne s'annule jamais. Posons $H\,\colon t\in I\mapsto \int_{t_0}^{t} h$ et $G\,\colon y\in J\mapsto \int_{y_0}^{y}\frac{1}{g}$.
	Si $K$ est un intervalle tel que $H(K)\subseteq G(J)$, alors $(C)$ admet une unique solution. Celle-ci vérifie $\forall t\in K,\, G(y(t)) = H(t)$.
\end{theorem}

\begin{remark}
	En pratique, on écrit abusivement $\frac{dy}{ds} = g(y)h(s)\implies \frac{dy}{g(y)} = h(s)ds \implies \int_{t_0}^{t}h(s)ds = \int_{t_0}^{t}\frac{dy}{g(y)} = \int_{y_0}^{y(t)}\frac{1}{g(s)}ds$.
\end{remark}

\begin{example}
	$(E)\,\colon y' = -\frac{1}{t}y^2 \longrightarrow -\frac{dy}{y^2} = \frac{ds}{s} = \int_{1}^{t}\frac{ds}{s} = \int_{1}^{t}-\frac{dy}{y^2} = \int_{y(1)}^{y(t)}-\frac{1}{s^2}ds$
	$\longrightarrow \ln(t) = \frac{1}{y(t)} - \frac{1}{y(1)} \longrightarrow y(t) = \left(\ln(t) + {y(-1)^{-1}}^{-1}\right)^{-1}$.
\end{example}

\section*{III. Étude qualitative des solutions}
\begin{definition}[\textnormal{[G] 433}]
	Un \emph{système autonome} est une EDO dont la variation ne dépend pas du temps, \emph{i.e.} de la forme $y'=f(y)$ où $f\,\colon \Omega\to \IR^d$ est un champ de vecteurs.
\end{definition}

\textcolor{paragraphtext}{Dans toute la suite, $(E)\,\colon y'=f(y)$ est un système autonome de $\IR^2$. On décompose $f$ selon la base canonique $f=(f_1,f_2)$ et on suppose $f$ continue et localement lipschitzienne.}

\subsection*{A. Points d'équilibre, isoclines, intégrales premières}

\begin{definition}[\textnormal{[Be] 187 ? ?}]
	On définit les éléments suivants :
	\begin{itemize}
		\item Un \emph{point d'équilibre de $(E)$} est un point $y_*$ tel que $f(y_*) = 0$.
		\item On dit que $y_*$ est \emph{stable} si, $(\IR^{+*}, y)$ étant solution de $(E)$, $$\forall \varepsilon > °,\, \exists \delta > 0\,\colon \|y(0)-y_*\|\leq \delta \implies \forall t\geq 0,\, \|y(t) - y_*\|\leq \varepsilon$$ On dit que $y_*$ est \emph{instable} sinon.
		\item On dit que $y_*$ est \emph{asymptotiquement stable} si, $(\IR^{+*}, y)$ étant solution de $(E)$, $$\exists \delta > 0\,\colon \|y(0) - y_*\|\leq \delta\implies \lim_{t\to +\infty} \|y(t)-y_*\| = 0$$
	\end{itemize}
\end{definition}

\begin{example}[pendule - FIG. 2 - \textnormal{[Be] 401-410}]
	Soient $\gamma \geq 0$ et $\omega \geq 0$. On considère $(E)\,\colon \theta''=-\gamma\theta' - \omega^2\sin \theta$,
	qui se réécrit $(E')\,\colon \begin{pmatrix}
		\theta \\ \theta'
	\end{pmatrix}' = \begin{pmatrix}
		\theta' \\ -\gamma\theta'-\omega^2\sin \theta
	\end{pmatrix}$. Alors :
	\begin{itemize}
		\item Les $(\pi+2k\pi, 0)$ pour $k\in \IZ$ sont des points d'équilibre instables ;
		\item Si $\gamma = 0$, les $(2k\pi, 0)$ pour $k\in\IZ$ sont des points d'équilibre stables non asymptotiquement stables ;
		\item Si $\gamma > 0$, les $(2k\pi, 0)$ pour $k\in\IZ$ sont des points d'équilibre stables asymptotiquement stables.
	\end{itemize}
\end{example}

\begin{definition}[\textnormal{[Be] 186}]
	On définit :
	\begin{itemize}
		\item L'\emph{isocline verticale} (resp. \emph{horizontale}) de $f$ par l'ensemble : $I_{\infty} = \left\{\underline{x}\in \Omega\mid f_1(\underline{x}) = 0\right\}$ (resp. $I_0 = \left\{\underline{x}\in\Omega \mid f_2(\underline{x}) = 0\right\}$)
		\item L'\emph{isocline d'inclinaison $\alpha\in \IR$ de $f$} est l'ensemble $I_{\alpha} = \left\{\underline{x}\in\Omega\mid f_2(\underline{x}) = \alpha f_1(\underline{x})\right\}$.
	\end{itemize}
\end{definition}

\begin{proposition}[\textnormal{[Be] 186}]
	Soit $\alpha\in [0,+\infty]$. Si $\underline{x}\in I_{\alpha}$, alors $f(\underline{x})$ dirige une doite de pente $\alpha$.
	Cela servira plus bas à tracer des portraits de phase, car $y'(t) = f(y(t))$ est tangent à la courbe décrite par $y$ en $t$.
\end{proposition}

\begin{proposition}[\textnormal{[Be] 189}]
	L'ensemble des points d'équilibre de $(E)$ est $I_0\cap I_{\infty}$.
\end{proposition}

\begin{definition}[\textnormal{[Be] 191-193}]
	\begin{itemize}
		\item Les \emph{courbes intégrales de $f$} sont les trajectoires des solutions maximales de $(E)$ ;
		\item L'\emph{orbite de $(E)$ issue de $y_0\in\Omega$} est la courbe intégrale de $f$ passant par $y_0$ (qui est bien unique d'après le théorème de \textsc{Cauchy-Lipschitz}) ;
		\item Une \emph{intégrale première de $(E)$} est une fonction $H\in C^1(\Omega,\IR)$ telle que pour toute solution $(J,y)$ de $(E)$, on a $\forall t\in J,\, \frac{d}{dt}\left[H(y(t))\right] = 0$.
	\end{itemize}
\end{definition}

\begin{example}[\textnormal{[Be] 403}]
	L'énergie mécanique est une intégrale première en dynamique du point.
	Aussi, $\theta'' + \omega^2\sin \theta = 0 \longrightarrow 2\theta''\theta + 2\omega^2\theta'\sin\theta = 0\longrightarrow H\left(\begin{pmatrix}
		\theta\\\theta'
	\end{pmatrix}\right) = \left(\theta'\right)^2 - 2\omega^2\cos\theta$.
\end{example}

\subsection*{B. Portraits de phase d'un système autonome en dimension / degré $2$}
\begin{definition}[\textnormal{[Be] 191}]
	Un \emph{portrait de phase} est une représentatino géométrique de la rtajectoire d'un système dynamique dans l'espace (dit \emph{de phase}) où il prend ses valeurs.
\end{definition}

\begin{remark}[\textnormal{[Gr] 434}]
	Par unicité dans le théorème de \textsc{Cauchy-Lipschitz}, chaque point de l'espace de phase appartient à une unique trajectoire : en particulier, les différentes trajectoires ne s'intersectent pas. Cela correspond donc à la partition de $\Omega$ en orbites.
\end{remark}

\begin{example}[FIG. 3 - \textnormal{[Be] 187-188}]
	$(E)\,\colon\begin{cases}
		x'=y^2-x \\ y' = x^2+y^2 - 1
	\end{cases}$
\end{example}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\textcolor{red}{Système proie-prédateur de \textsc{Lotka-Volterra}. DEV 2}

\textcolor{paragraphtext}{Soit $(a,b,c,d)\in\left(\IR^{+*}\right)^4$. On considère $(E)\,\colon\begin{cases}
	x' = ax - bxy \\ y' = -cy' + dxy
\end{cases}$.}
\begin{proposition}
	\label{220dev21}
	$H\,\colon\begin{pmatrix}
		x \\ y
	\end{pmatrix}\mapsto dx + by - c\ln(x) - a\ln(y)$ est une intégrale première de $(E)$ sur $\left(\IR^{+*}\right)^2$.
\end{proposition}
\begin{proposition}
	\label{220dev22}
	Soient $t_0\in \IR$, $x_0> 0$ et $y_0>0$. Le problème de \textsc{Cauchy} $\begin{cases}
		(E) \\ x(t_0) = x_0 \\ y(t_0) = y_0
	\end{cases}$ admet une unique solution définie sur $\IR$. Celle-ci est périodique.
\end{proposition}
\textcolor{paragraphtext}{\emph{c.f.} FiGURE 4 pour le portrait de phase de $(E)$.}
[\textnormal{[Be] 204}]
\end{tcolorbox}

\section*{Développements}
\begin{itemize}
	\item Développement 1 : Résolution \ref{220dev1}
	\item Développement 2 : Propositions \ref{220dev21} et \ref{220dev22}
\end{itemize}

\section*{Références}
\begin{itemize}
	\item[Be] \emph{Équations différentielles}, Florent Berthelin
	\item[Gr] \emph{Algèbre linéaire}, Joseph Grifone, 6e édition, 2e version
	\item[G] \emph{Les maths en tête - Analyse}, Xavier Gourdon, 3e édition 
\end{itemize}

\begin{figure}[!htb]
	\centering
	\includegraphics[trim={0 0 0 0},clip,width=1\linewidth]{img/220.pdf}
	\caption{s}
\end{figure}


\chapter*{223 : Suites réelles et complexes. Convergence, valeurs d’adhérence. Exemples et applications.}
\setcounter{definition}{0}

\textcolor{paragraphtext}{Dans cette leçon, $\IK$ désigne $\IR$ ou $\IC$ et $\left(u_n\right)_{n\in\IN}\in\IK^{\IN}$ une suite.}

\section*{I. Comportement asymptotique des suites numériques}
\subsection*{A. Convergence et limites}

\begin{definition}[\textnormal{[EA] 12-13}]
	On dit que $\left(u_n\right)_{n\in\IN}$ :
	\begin{itemize}
		\item \emph{converge vers $l\in\IK$} si $\forall \varepsilon >0,\, \exists N\in\IN\,\colon \forall n\geq N,\, \vert u_n - l\vert \leq \varepsilon$. On note alors $\lim_{n\to +\infty} u_n = l$ ou $u_n\longrightarrow_{n\to +\infty} l$, et $l$ est appelée \emph{limite de $\left(u_N\right)_{n\in\IN}$.}
		\item \emph{diverge} sinon.
	\end{itemize}
\end{definition}

\begin{example}[\textnormal{[EA] ? 3 3}]
	\begin{itemize}
		\item $\left(n\right)_{n\in\IN}$ diverge, $\left(1+\frac{1}{n}\right)_{n\in\IN}$ converge vers $1$.
		\item Une \emph{suite arithmétique de raison $r$}, vérifiant $\forall n\in\IN,\, u_{n+1} = u_n + r$, s'explicite $\forall n/in \IN$, $u_n = u_0+nr$. Si $r \neq 0$n alors $\left(u_n\right)_{n\in \IN}$ diverge.
		\item Une \emph{suite géométrique de raison $q$}, vérifiant $\forall n\in \IN$, $u_{n+1} = qu_n$, s'explicite $\forall n\in\IN$, $u_n = u_0q^n$. Si $\vert q\vert < 1$, alors $\left(u_n\right)_{n\in\IN}$ converge vers $0$.
	\end{itemize}
\end{example}

\begin{theorem}[\textnormal{[EA] 12}]
	Si $\left(u_n\right)_{n\in\IN}$ converge, alors sa limite est unique.
\end{theorem}

\begin{proposition}[\textnormal{[EA] 13}]
	Toute suite convergente est bornée.
\end{proposition}

\begin{cexample}[\textnormal{[EA] 13}]
	$\left((-1)^n\right)_{n\in\IN}$ est bornée divergente.
\end{cexample}

\begin{proposition}[\textnormal{[EA] 16}]
	Si $u_n\to u_n$, $v_n\to v$, et $w_n\to w$, alors $u_n+v_nw_n\to u+vw$.
\end{proposition}

\begin{proposition}[\textnormal{[R] 165}]
	Soient $a\in\IK$ et $f\,\colon \IK\to\IK$. Alors $f$ est continue en $a \iff$
	$$\forall \left(u_n\right)_{n\in\IN} \in \IK^{\IN},\,\lim_{n\to +\infty} u_n = a \implies \lim_{n\to +\infty} f(u_n) = f(a)$$
\end{proposition}

\begin{definition}[\textnormal{[EA] 34}]
	On dit que $\left(u_n\right)_{n\in\IN}$ est \emph{de \textsc{Cauchy}} si :
	$$\forall \varepsilon > 0,\, \exists N\in \IN\,\colon \forall n\geq N,\, \forall p\geq N,\, \vert u_n - u_m\vert \leq \varepsilon$$
\end{definition}

\begin{theorem}[\textnormal{[EA] e35+34}]
	$\left(u_n\right)_{n\in\IN}$ converge si, et seulement si, elle est de \textsc{Cauchy}.
\end{theorem}

\begin{theorem}[de \textsc{Cesàro} - \textnormal{[EA] 53}]
	Si $u_n\longrightarrow_{n\to +\infty} l$, alors $\frac{1}{n}\sum_{k=1}^{n} u_k \longrightarrow_{n\to +\infty} l$. (Contre-exemple :  $(-1)^n$)
\end{theorem}

\subsection*{B. Valeurs d'adhérence}
\begin{definition}[\textnormal{[EA] 14}]
	Une \emph{suite extraite de $\left(u_n\right)_{n\in\IN}$} est une suite $\left(u_{\varphi(n)}\right)_{n\in\IN}$ où $\varphi\,\colon\IN\to\IN$ est strictement croissante.
\end{definition}

\begin{definition}[\textnormal{[EA] 15}]
	Une \emph{valeur d'adhérence} de $\left(u_n\right)_{n\in\IN}$ est la limite d'une suite extraite de $\left(u_n\right)_{n\in\IN}$ convergente.
\end{definition}

\begin{proposition}
	Si $u_n\longrightarrow_{n\to +\infty} l$, alors pour toute suite $\left(u_{\varphi(n)}\right)_{n\in\IN}$ extraite de $\left(u_n\right)_{n\in\IN}$, $\left(u_{\varphi(n)}\right)\longrightarrow_{n\to +\infty} l$.
\end{proposition}

\begin{remark}[\textnormal{[EA] 15}]
	Une suite convergente admet sa limite comme unique valeur d'adhérence. Réciproquement,
	la suite $\left(n(1+(-1)^n)\right)_{n\in\IN}$ a une unique valeur d'adhérence, mais ne converge pas.
\end{remark}

\begin{proposition_def}[\textnormal{[G] 19}]
	Soit $a\in\IK$. On dit que $a$ est \emph{une valeur de répétition de $\left(u_n\right)_{n\in \IN}$} si $\left\{n\in \IN \mid u_n = a\right\}$ est infini.
	
	Alors $a$ est une valeur d'adhérence de $\left(u_n\right)_{n\in\IN}\iff \forall \varepsilon > 0,\,\forall N\in\IN,\, \exists n\geq N\,\colon \left\{n\in\IN\mid u_n=a\right\}\text{ est infini}\implies\vert u_n - a\vert \leq \varepsilon$.
\end{proposition_def}

\begin{cexample}
	La dernière implication est stricte : $\left(\frac{1}{n}\right)_{n\geq 1}$.
\end{cexample}

\begin{example}
	Soit $\mu > 0$. La suite définie par $u_0\in]0,1]$ et $\forall n\in\IN,\, u_{n+1} = \mu u_n(1-u_n)$.
	Si $\mu \leq 3$, alors $\left(u_n\right)_{n\in\IN}$ converge. Si $3 < \mu < 3.55$, alors $\left(u_n\right)_{n\in\IN}$ a $2^k$, $k\geq 1$ valeurs d'adhérence. Si $\mu > 3.56$... c'est compliqué.
\end{example}

\subsection*{C. Cas des suites réelles}

\textcolor{paragraphtext}{Soient $\left(u_n\right)_{n\in\IN}\in\IR^{\IN}$, $\left(v_n\right)_{n\in\IN}\in\IR^{\IN}$ et $\left(w_n\right)_{n\in\IN}\in\IR^{\IN}$.}

\begin{definition}[\textnormal{[EA] 20}]
	On dit que $\left(u_n\right)_{n\in\IN}$ \emph{diverge vers $+\infty$} si $\forall A > 0,\,\exists N\in\IN\,\colon \forall n\geq N,\, u_n \geq A$.
	On note alors $\displaystyle{\lim_{n\to +\infty} u_n = +\infty}$ ou $u_n\xrightarrow[n\to +\infty]{}+\infty$.
\end{definition}

\begin{proposition}[\textnormal{[EA] 19}]
	Si $u_n\xrightarrow[n\to +\infty]{} u$, $v_n\xrightarrow[n\to +\infty]{} v$ et si $\forall n\in \IN$, $u_n\leq v_n$, alors $u\leq v$.
\end{proposition}

\begin{theorem}[des gendarmes / d'encadrement - \textnormal{[EA] 19}]
	Si $\forall n\in\IN$, $u_n\leq v_n\leq w_n$ et si $\displaystyle{\lim_{n\to +\infty} u_n = \lim_{n\to +\infty} w_n = l \in \overline{\IR}}$, 
	alors $\left(u_n\right)_{n\in\IN}$ converge et $\displaystyle{\lim_{n\to +\infty}} = l$.
\end{theorem}

\begin{theorem}[de la limite monotone - \textnormal{[EA] 32}]
	Si $\left(u_n\right)_{n\in\IN}$ est croissante et majorée (resp. non majorée), alors $\left(u_n\right)_{n\in\IN}$ converge vers $l\in\IR$ (resp. vers $l = +\infty$).
	Plus précisément, $\displaystyle{l = \sup_{n\in\IN} u_n}$.
\end{theorem}

\begin{application}
	\begin{itemize}
		\item Si $u_0\in [0,\frac{\pi}{2}]$ et $\forall n\in \IN,\, u_{n+1}=\sin(u_n)$, alors $\left(u_n\right)_{n\in\IN}$ converge.
		\item $\left(W_n\right)_{n\in\IN}$ où $W_n = \int_{0}^{\pi/2}\sin^n$ converge.
	\end{itemize}
\end{application}

\begin{definition}[\textnormal{[EA] 33}]
	On dit que $\left(\left(u_n\right)_{n\in\IN},\left(v_n\right)_{n\in\IN}\right)$ est un \emph{couple de suites adjacentes} si $\left(u_n\right)_{n\in\IN}$ est croissante, $\left(v_n\right)_{n\in\IN}$ est décroissante et $\displaystyle{\lim_{n\to +\infty} u_n-v_n = 0}$.
\end{definition}

\begin{theorem}[des suites adjacentes - \textnormal{[EA] 33}]
	Si $\left(\left(u_n\right)_{n\in\IN},\left(v_n\right)_{n\in\IN}\right)$ est un couple de suites adjacentes, alors $\left(u_n\right)_{n\in\IN}$ et $\left(v_n\right)_{n\in\IN}$ convergent vers un $l\in\IR$.
	De plus, $\forall n\in\IN,\, u_n\leq l\leq v_n$.
\end{theorem}

\begin{example}[\textnormal{[EA] 33}]
	$u_n = 1 - \frac{1}{n}$, $v_n = 1+\frac{1}{n^2}$, et $\displaystyle{\lim_{n\to +\infty} u_n = \lim_{n\to +\infty} v_n = 0}$.
\end{example}

\begin{theorem}[de \textsc{Bolzano-Weierstrass} - \textnormal{[EA] 36, [R] 94}]
	Toute suite réelle bornée admet une valeur d'adhérence.
\end{theorem}

\begin{corollary}[\textnormal{[R] 95}]
	Une suite réelle converge si, et seulement si, elle est bornée et elle a une unique valeur d'adhérence.
\end{corollary}

\begin{remark}[\textnormal{[R] 94 + [EA] 36}]
	Théorème 26 peut être montré en construisant un couple de suites extraites adjacentes et utilise Théorème 24, ou avec Théorème 21 en montrant que de toute suite réelle on peut extraire une suite monotone.
\end{remark}

\begin{definition}[\textnormal{[R] 120}]
	On définit les éléments suivants :
	\begin{itemize}
		\item La \emph{limite supérieure de $\left(u_n\right)_{n\in\IN}$} est $\displaystyle{\limsup_{n\to +\infty} u_n := \lim_{n\to +\infty} \sup_{k\geq n} u_k}$.
		\item La \emph{limite inférieure de $\left(u_n\right)_{n\in\IN}$} est $\displaystyle{\liminf_{n\to +\infty} u_n := \lim_{n\to +\infty} \inf_{k\geq n} u_k}$.
	\end{itemize}
\end{definition}

\begin{proposition}[\textnormal{[R] 120-121}]
	La limite supérieure et inférieure d'une suite $\left(u_n\right)_{n\in\IN}$ à valeurs réelles existent dans $\overline{\IR}$, et pour 
	toute valeur d'adhérence $l$ de $\left(u_n\right)_{n\in\IN}$, on a 
	$$\liminf_{n\to +\infty} u_n \leq l \leq \limsup_{n\to +\infty} u_n$$
\end{proposition}

\begin{theorem}[\textnormal{[R] 122}]
	$$\lim_{n\to +\infty} u_n = l\in\overline{\IR} \iff \liminf_{n\to +\infty} u_n = \limsup_{n\to +\infty} u_n = l$$
\end{theorem}

\begin{application}
	\begin{itemize}
		\item $\displaystyle{\lim_{n\to +\infty} \vertiii{T^n}^{\frac{1}{n}} = \inf_{n\in\IN} \vertiii{T^n}^{\frac{1}{n}}}$
		\item $X_n \xrightarrow{\mathcal{L}} X \iff \forall t\in\IR,\, F_x$ continue en $t\implies F_{X_n}(t)\to F_X(t)$.
	\end{itemize}
\end{application}

\section*{II. Suites particulières}
\subsection{A. Séries numériques}
\textcolor{paragraphtext}{Pour $n\in\IN^*$, posons $S_n = \sum_{k=0}^{n} u_k$.}

\begin{example}
	Si $u_n = q^n$ avec $\vert q\vert < 1$, alors $\left(S_n\right)_{n\in\IN}$ converge vers $\frac{1}{1-q}$.
\end{example}

\begin{proposition}[\textnormal{[G] 209}]
	Si $\forall n\in\IN,\, u_n\geq 0$, alors $\left(S_n\right)_{n\in\IN}$ converge si, et seulement si elle est majorée.
\end{proposition}

\begin{cexample}
	La positivité est capitale : $u_n = (-1)^n$.
\end{cexample}

\begin{proposition}[\textnormal{[G] 209}]
	Si $\left(S_n\right)_{n\in\IN}$ converge, alors $\displaystyle{u_n\xrightarrow[n\to +\infty]{} 0}$.
\end{proposition}

\begin{cexample}
	Ce n'est qu'une implication : $u_n = \frac{1}{n}$.
\end{cexample}

\begin{theorem}[\textnormal{[G] 210}]
	Soient $\left(u_n\right)_{n\in\IN}\in\left(\IR^+\right)^{\IN}$ et $\left(v_n\right)_{n\in\IN}\in\left(\IR^{+*}\right)^{\IN}$ telles que $u_n\sim v_n$ (\emph{i.e.} $\frac{u_n}{v_n}\xrightarrow[n\to +\infty]{} 1$).
	\begin{itemize}
		\item Si $\left(\sum_{k=0}^{n}u_k\right)_{n\in\IN}$ converge, alors $\left(\sum_{k=0}^{n}v_k\right)_{n\in\IN}$ aussi, et $\sum_{k=n+1}^{+\infty}u_k\sim \sum_{k=n+1}^{+\infty}v_k$.
		\item Si $\left(\sum_{k=0}^{n}u_k\right)_{n\in\IN}$ diverge, alors $\left(\sum_{k=0}^{n}v_k\right)_{n\in\IN}$ aussi, et $\sum_{k=0}^{n}u_k\sim \sum_{k=0}^{n}v_k$.
	\end{itemize}
\end{theorem}

\begin{example}[\textnormal{[G] 211}]
	Il existe $\gamma > 0$ telle que $\sum_{k=1}^{n} \frac{1}{k} = \ln(n)+\gamma + \frac{1}{2n} + o(\frac{1}{n})$.
	La constante $\gamma$ est appelée \emph{constante harmonique}.
\end{example}

\subsection*{B. Suites définies par récurrence}

\textcolor{paragraphtext}{Soient $A\subseteq \IR$ non vide, $f\,\colon A\to A$, $a\in A$, et $\left(u_n\right)_{n\in\IN}\in A^{\IN}$ telle que $u_0 = a$ et $\forall n\in\IN,\, u_{n+1} = f(u_n)$.}

\begin{proposition}[\textnormal{[G] 200}]
	Si $f$ est continue, et si $\displaystyle{\lim_{n\to +\infty} u_n =l \in A}$, alors $f(l) = l$ (on dit que $l$ est un \emph{point fixe de $f$}).
\end{proposition}

\begin{example}[\textnormal{[G] 228, 201}]
	\begin{itemize}
		\item Pour $1 = [0,2\pi]$ et $f = \sin$, $u_n \to 0$.
		\item Pour $f\,\colon x\mapsto ax+b$, $a\neq 1$, $b\neq 0$, on obtient une \emph{suite arithmético-géométrique}. Posons $c = \frac{b}{1-a} = f(c)$. On a $\forall n\in \IN,\, u_n = c + (u_0 - c)a^n$. Si $\vert a\vert < 1$, alors $u_n\to c$.
	\end{itemize}
\end{example}

\begin{tcolorbox}[
    breakable, % Allows the theorem to split across pages
    colback=developpement, % The background color
    colframe=gray!0!black, % The frame color
    boxrule=0pt, % The frame thickness
    arc=1mm, % Sharp corners
	boxsep=0pt,
	left=0pt, right=0pt, top=0pt, bottom=0pt
]
\begin{example}[\textnormal{[Be] 145}]
	\label{223dev11}
	Soit $b > 0$, supposons que $A = [0,b]$ et que :
	\begin{itemize}
		\item $f$ est continue et croissante
		\item $f(0) = 0$ et $\forall x\in ]0,b]$, $f(x) < x$
		\item Il existe $\lambda >0$ et $r> 1$ tels que $f(x) = x - \lambda x^r + o_{x\to 0}(x^r)$
	\end{itemize}
	Alors $u_n \sim \left(n\lambda(r-1)\right)^{\frac{1}{1-r}}$
\end{example}

\begin{application}
	\label{223dev12}
	Pour $f\,\colon x\mapsto \ln(1+x)$, on a $u_n = \frac{2}{n} + \frac{2\ln(n)}{3n^2} + o_{n\to +\infty}(\frac{\ln(n)}{n^2})$.
\end{application}
\end{tcolorbox}

\section*{III. Approximation de réels}
\begin{proposition}[\textnormal{[R] 99}]
	Soit $x\in\IR$, pour $n\in\IN$ posons $x_n = 10^{-n}\lfloor 10^nx\rfloor$ et $y_n = x_n + 10^{-n}$.
	Alors $\left(\left(x_n\right)_{n\in\IN}, \left(y_n\right)_{n\in\IN}\right)$ est un couple de suite décimales adjacentes qui tend vers $x$.
\end{proposition}

\begin{proposition}[méthode de \textsc{Héron}]
	Soit $a\geq 0$. La suite $\left(u_n\right)_{n\in\IN}$ définie par $u_0 = 1$ et $\forall n\in \IN,\, u_{n+1} = \frac{1}{2}(u_n + \frac{a}{u_n})$ converge vers $\sqrt{a}$.
\end{proposition}

\begin{theorem}[méthode de \textsc{Newton} - \textnormal{[R] 345-346}]
	Soit $f\in C^2([a,b], \IR)$ telle que $f(a)f(b) < 0$ et $\forall x \in [a,b],\, f'(x)f''(x) \neq 0$. L'équation $f(x) = 0$ admet une unique solution $a\in ]a,b[$.
	La suite $\left(x_n\right)_{n\in\IN}$ définie par $x_0\in [a,b[$ tel que $f(x_0)f''(x_0) > 0$ et $\forall n\in \IN,\, x_{n+1} = x_n - f(x_n)/f'(x_n)$ est monotone, converge vers $\alpha$, et $\forall n\in \IN$, 
	$\vert x_n - \alpha\vert \leq (b-a)^{2^n}\left(\frac{M}{2m}\right)^{2^n-1}$ où $M = \|f''\|_{\infty}$ et $m = \min_{[a,b]} \vert f'\vert$.
\end{theorem}

\begin{example}[\textnormal{[R] 115}]
	Soit $(a,b)\in\left(\IR^*\right)^2$ tel que $\frac{a}{b}\neq \IQ$. Tout réel est limite d'une suite d enombres de la forme $na + mb$ avec $(n,m)\in \IZ^2$.
\end{example}

\begin{example}[\textnormal{[R] 132}]
	\begin{itemize}
		\item L'ensemble des valeurs d'adhérence de $\left(e^{in}\right)_{n\in\IN}$ est $\left\{z\in\IC\mid \vert z\vert =1\right\}$.
		\item L'ensemble des valeurs d'adhérence de $\left(\cos(n)\right)_{n\in\IN}$ et $\left(\sin(n)\right)_{n\in\IN}$ est $[-1,1]$.
	\end{itemize}
\end{example}

\begin{theorem}[\textnormal{[R] 114}]
	Si $G$ est un sous-groupe de $(\IR,+)$ 
	non réduit à $\left\{0 \right\}$, alors $\alpha := \inf G\cap \IR^{+*}$ est bien défini, et :
	\begin{itemize}
		\item Si $\alpha > 0$, alors $G = \alpha\IZ$
		\item Si $\alpha = 0$, alors $G$ est dense.
	\end{itemize}
\end{theorem}


\textcolor{paragraphtext}{Soit $\left(u_n\right)_{n\in\IN}\in\IR^{\IN}$.}
\begin{definition}[\textnormal{[FGN] 47}]
	On dit que $\left(u_n\right)_{n\in\IN}$ est \emph{équirépartie modulo $1$} si :
	$\forall (a,b)\in[0,1[^2,\, a<b\implies \frac{1}{N}\#\left\{n\in \llbracket 1,n \rrbracket \mid a\leq \left\{u_n\right\} < b\right\}\xrightarrow[N\to +\infty]{} b-a$
	où $\left\{x\right\} = x - \lfloor x \rfloor$ désigne la partie fractionnaire de $x\in\IR$.
\end{definition}

\begin{theorem}[critère de \textsc{Weyl} - \textnormal{[FGN] 47}]
	\label{223dev2}
	Les assertions suivantes sont équivalentes :
	\begin{enumerate}
		\item $\left(u_n\right)_{n\in\IN}$ est équidistribuée modulo $1$
		\item Si $f\,\colon \IR\to \IR$ est continue et $1$-périodique, alors $\frac{1}{N}\sum_{n=1}^{N}f(u_n)\xrightarrow[N\to +\infty]{} \int_{0}^{1} f$
		\item Pour tout $k\in\IZ^*$, $\frac{1}{N}\sum_{n=1}^{N} e^{2i\pi ku_n}\xrightarrow[N\to +\infty]{} 0$
	\end{enumerate}
\end{theorem}

\begin{example}
	\begin{itemize}
		\item Soit $\gamma > 0$. La suite $\left(n\gamma\right)_{n\in\IN}$ est équidistribuée modulo $1$ si, et seulement si, $\gamma\notin \IQ$.
		\item $\left(\left\{\text{log}(n)\right\}\right)_{n\geq 1}$ n'est pas équirépartie.
	\end{itemize}
\end{example}

\begin{proposition}
	Si $\left(u_n\right)_{n\in\IN}$ est équirépartie modulo $1$, alors $\left\{\left\{u_n\right\} \mid n\in \IN\right\}$ est dense dans $[0,1]$, autrement dit l'ensemble des valeurs d'adhérence de $\left(\left\{u_n\right\}\right)_{n\in\IN}$ est $[0,1]$.
\end{proposition}

\section*{Développements}
\begin{itemize}
	\item Développement 1 : Exemple \ref{223dev11} et Application \ref{223dev12}
	\item Développement 2 : Théorème \ref{223dev2}
\end{itemize}

\section*{Références}
\begin{itemize}	
	\item[R] \emph{Éléments d'analyse réelle}, Jean-Etienne Rombaldi, 2e édition
	\item[EA] \emph{Suites et séries numériques. Suites et séries de fonctions}, Mohamed El Amrani
	\item[G] \emph{Les maths en tête - Analyse}, Xavier Gourdon, 3e édition 
	\item[FGN] \emph{Oraux X-ENS, Analyse 2}, Francinou, Gianella, Nicolas
	\item[Be] \emph{Analyse pour l'agrégation de mathématiques, 40 développements}, Julien Bernis et Laurent Bernis
\end{itemize}

\begin{figure}[!htb]
	\centering
	\includegraphics[trim={0 0 0 0},clip,width=1\linewidth]{img/223.pdf}
	\caption{s}
\end{figure}

\end{document}

% \begin{figure}[!htb]
% 	\centering
% 	\includegraphics[trim={0 0 0 0},clip,width=1\linewidth]{img/149.pdf}
% 	\caption{s}
% \end{figure}
% \begin{tcolorbox}[
%     breakable, % Allows the theorem to split across pages
%     colback=developpement, % The background color
%     colframe=gray!0!black, % The frame color
%     boxrule=0pt, % The frame thickness
%     arc=1mm, % Sharp corners
% 	boxsep=0pt,
% 	left=0pt, right=0pt, top=0pt, bottom=0pt
% ]
% \end{tcolorbox}